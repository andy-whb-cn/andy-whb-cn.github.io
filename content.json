{"meta":{"title":"Andy's Note","subtitle":"","description":"","author":"Andy","url":"https://andy-whb-cn.github.io","root":"/"},"pages":[{"title":"404 Not Found：该页无法显示","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":false,"path":"/404.html","permalink":"https://andy-whb-cn.github.io/404.html","excerpt":"","text":""},{"title":"书单","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":false,"path":"books/index.html","permalink":"https://andy-whb-cn.github.io/books/index.html","excerpt":"","text":""},{"title":"关于","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":false,"path":"about/index.html","permalink":"https://andy-whb-cn.github.io/about/index.html","excerpt":"","text":"个人详细介绍"},{"title":"分类","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":false,"path":"categories/index.html","permalink":"https://andy-whb-cn.github.io/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":true,"path":"links/index.html","permalink":"https://andy-whb-cn.github.io/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2024-08-22T09:40:49.988Z","updated":"2024-08-22T09:40:49.988Z","comments":false,"path":"repository/index.html","permalink":"https://andy-whb-cn.github.io/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2024-08-22T09:40:49.989Z","updated":"2024-08-22T09:40:49.989Z","comments":false,"path":"tags/index.html","permalink":"https://andy-whb-cn.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringBoot: 审计日志","slug":"SpringBoot/SpringBoot：审计日志","date":"2025-11-04T16:00:00.000Z","updated":"2025-11-05T05:40:55.606Z","comments":true,"path":"2025/11/05/SpringBoot/SpringBoot：审计日志/","permalink":"https://andy-whb-cn.github.io/2025/11/05/SpringBoot/SpringBoot%EF%BC%9A%E5%AE%A1%E8%AE%A1%E6%97%A5%E5%BF%97/","excerpt":"","text":"背景在企业级业务系统中，审计日志记录非常重要。特别是涉及到用户操作一些关键业务数据的新增、修改、删除时，系统应追踪操作人、操作对象和操作时间等关键数据。这不仅对运维、合规有帮助，同时也能提高系统的可审计性和安全性。 审计日志实现方式目前审计日志的主流实现方式多数是通过AOP或是增加Springboot拦截器，对http接口请求进行拦截打印日志或者记录到数据库表中。（注：JPA&#x2F;Mybatis这类框架支持拦截数据库的操作记录） AOP实现1.添加依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; 2.定义注解 12345678910111213@Target(ElementType.METHOD) @Retention(RetentionPolicy.RUNTIME)public @interface AuditLog &#123; String value() default &quot;&quot;; // 操作描述 String operator() default &quot;#userContext.username&quot;; // 操作人 String operatorId() default &quot;#userContext.userId&quot;; // 操作人ID String params() default &quot;&quot;; // 参数SpEL表达式 String result() default &quot;&quot;; // 结果SpEL表达式 LogLevel level() default LogLevel.INFO; // 日志级别 GdprMaskType maskType() default GdprMaskType.DEFAULT; // GDPR脱敏类型 &#125; public enum GdprMaskType &#123; NONE, DEFAULT, SENSITIVE, EXTREME_SENSITIVE &#125; 3.AOP实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Aspect @Component public class AuditLogAspect &#123; private static final Logger logger = LoggerFactory.getLogger(AuditLogAspect.class); @Autowired private AuditLogRepository auditLogRepository; @Autowired private GdprMaskService maskService; @Autowired private UserContext userContext; @Around(&quot;@annotation(auditLog)&quot;) public Object logAround(ProceedingJoinPoint joinPoint, AuditLog auditLog) throws Throwable &#123; // 1. 构建日志对象 AuditLogEntity logEntity = new AuditLogEntity(); logEntity.setOperationTime(new Date()); logEntity.setTargetClass(joinPoint.getTarget().getClass().getName()); logEntity.setTargetMethod(joinPoint.getSignature().getName()); logEntity.setRequestIp(IpUtils.getClientIp()); // 2. 解析SpEL表达式 EvaluationContext context = createEvaluationContext(joinPoint); parseSpEL(auditLog, logEntity, context); // 3. 执行目标方法 Object result = null; try &#123; result = joinPoint.proceed(); logEntity.setIsSuccess(true); logEntity.setResult(maskService.maskData( evaluateSpEL(auditLog.result(), context), auditLog.maskType() )); &#125; catch (Throwable e) &#123; logEntity.setIsSuccess(false); logEntity.setException(e.getMessage()); throw e; &#125; // 4. 保存日志 auditLogRepository.save(logEntity); return result; &#125; private EvaluationContext createEvaluationContext(ProceedingJoinPoint joinPoint) &#123; DefaultEvaluationContext context = new DefaultEvaluationContext(userContext); for (int i = 0; i &lt; joinPoint.getArgs().length; i++) &#123; context.setVariable(&quot;arg&quot; + i, joinPoint.getArgs()[i]); &#125; return context; &#125; private void parseSpEL(AuditLog auditLog, AuditLogEntity logEntity, EvaluationContext context) &#123; // 解析操作描述 if (!auditLog.value().isEmpty()) &#123; logEntity.setDescription(evaluateSpEL(auditLog.value(), context)); &#125; // 解析操作人 if (!auditLog.operator().isEmpty()) &#123; logEntity.setOperator(evaluateSpEL(auditLog.operator(), context)); &#125; // 解析操作人ID if (!auditLog.operatorId().isEmpty()) &#123; logEntity.setOperatorId(evaluateSpEL(auditLog.operatorId(), context)); &#125; // 解析参数 if (!auditLog.params().isEmpty()) &#123; logEntity.setParams(evaluateSpEL(auditLog.params(), context)); &#125; &#125; private String evaluateSpEL(String expression, EvaluationContext context) &#123; return parser.parseExpression(expression).getValue(context, String.class); &#125; &#125; 4.使用示例 1234567891011@RestController public class UserController &#123; @AuditLog(value = &quot;用户注册&quot;, operator = &quot;#userContext.username&quot;, params = &quot;#args[0].toString()&quot;) public User register(User user) &#123; return userService.save(user); &#125; @AuditLog(value = &quot;用户登录&quot;, operator = &quot;#userContext.username&quot;) public String login(String username, String password) &#123; // 登录逻辑 return &quot;登录成功&quot;; &#125; &#125; 拦截器实现1.实体定义 1234567891011121314151617181920212223242526272829303132333435package com.xxx.biz.model.common.access;import lombok.Data;import lombok.experimental.Accessors;import java.util.Date;@Data@Accessors(chain = true)public class AccessLog &#123; /**访问用户*/ private String username = &quot;unknown&quot;; /**uri*/ private String uri; /**访问时长*/ private Long duration; /**请求方式*/ private String method; /**客户端IP*/ private String ip; /**状态码*/ private int status; /**时间*/ private Date createTime;&#125; 2.拦截器实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.xxx.biz.config.log;import com.xxx.biz.model.common.access.AccessLog;import lombok.extern.slf4j.Slf4j;import org.springframework.lang.Nullable;import org.springframework.stereotype.Component;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.Date;@Slf4jpublic class AccessLogInterceptor implements HandlerInterceptor &#123; /**访问开始时间*/ private static final String KEY_REQUEST_START_TIME = &quot;KEY_REQUEST_START_TIME&quot;; /**访问请求日志对象*/ private static final String KEY_ACCESS_LOG = &quot;KEY_ACCESS_LOG&quot;; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; AccessLog accessLog = new AccessLog(); accessLog.setIp(SpringUtils.getIpAddr()) .setMethod(request.getMethod()) .setUri(request.getRequestURI()); //将信息绑定在request中 request.setAttribute(KEY_REQUEST_START_TIME, System.currentTimeMillis()); request.setAttribute(KEY_ACCESS_LOG, accessLog); return true; &#125; @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception &#123; AccessLog accessLog = (AccessLog) request.getAttribute(KEY_ACCESS_LOG); Long startTime = (Long) request.getAttribute(KEY_REQUEST_START_TIME); if (accessLog != null) &#123; Date createTime = new Date(); AuthContext context = AuthContextHolder.getContext(); accessLog.setCreateTime(createTime) .setDuration(createTime.getTime() - startTime) .setStatus(response.getStatus()) .setUsername(context == null ? null : context.getUsername()); log.debug(accessLog.toString()); &#125; &#125;&#125; 3.拦截器注册 1234567891011121314151617181920package com.xxx.biz.config;import com.xxx.biz.config.log.AccessLogInterceptor;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ResourceHandlerRegistry;import org.springframework.web.servlet.config.annotation.ViewControllerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; // 添加拦截器，配置拦截地址 registry.addInterceptor(new AccessLogInterceptor()) .addPathPatterns(&quot;/**&quot;); &#125;&#125; 4.log4j配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657&lt;!--访问日志--&gt; &lt;RollingFile name=&quot;accessAppender&quot; fileName=&quot;$&#123;FILE_PATH&#125;/$&#123;FILE_NAME&#125;/log_access.log&quot; filePattern=&quot;$&#123;FILE_PATH&#125;/$&#123;FILE_NAME&#125;/access/log-access-%d&#123;yyyy-MM-dd&#125;_%i.log.gz&quot; append=&quot;true&quot;&gt; &lt;!--设置日志格式--&gt; &lt;PatternLayout pattern=&quot;$&#123;ACCESS_LOG_PATTERN&#125;&quot; charset=&quot;UTF-8&quot;/&gt; &lt;Filters&gt; &lt;ThresholdFilter level=&quot;debug&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;Policies&gt; &lt;!-- 基于时间的触发策略。该策略主要是完成周期性的log文件封存工作。有两个参数： interval，integer型，指定两次封存动作之间的时间间隔。单位:以日志的命名精度来确定单位， 比如yyyy-MM-dd-HH 单位为小时，yyyy-MM-dd-HH-mm 单位为分钟 modulate，boolean型，说明是否对封存时间进行调制。若modulate=true， 则封存时间将以0点为边界进行偏移计算。比如，modulate=true，interval=4hours， 那么假设上次封存日志的时间为00:00，则下次封存日志的时间为04:00， 之后的封存时间依次为08:00，12:00，16:00--&gt; &lt;TimeBasedTriggeringPolicy interval=&quot;1&quot;/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;10MB&quot;/&gt; &lt;/Policies&gt; &lt;!-- DefaultRolloverStrategy 属性如不设置，则默认为最多同一文件夹下当天 7 个文件后开始覆盖--&gt; &lt;DefaultRolloverStrategy max=&quot;30&quot;&gt; &lt;!-- 删除处理策略，在配置的路径中搜索，maxDepth 表示往下搜索的最大深度 --&gt; &lt;Delete basePath=&quot;$&#123;FILE_PATH&#125;/$&#123;FILE_NAME&#125;/&quot; maxDepth=&quot;2&quot;&gt; &lt;!-- 文件名搜索匹配，支持正则 --&gt; &lt;IfFileName glob=&quot;*.log.gz&quot;/&gt; &lt;!--!Note: 这里的 age 必须和 filePattern 协调, 后者是精确到 dd, 这里就要写成 xd, xD 就不起作用 另外, 数字最好 &gt;2, 否则可能造成删除的时候, 最近的文件还处于被占用状态,导致删除不成功!--&gt; &lt;!--7天--&gt; &lt;IfLastModified age=&quot;7d&quot;/&gt; &lt;/Delete&gt; &lt;/DefaultRolloverStrategy&gt; &lt;/RollingFile&gt;&lt;!--变量配置--&gt; &lt;properties&gt; &lt;!-- 格式化输出：%date 表示日期，%thread 表示线程名，%-5level：级别从左显示 5 个字符宽度 %msg：日志消息，%n 是换行符--&gt; &lt;!-- %logger&#123;36&#125; 表示 Logger 名字最长 36 个字符 --&gt; &lt;property name=&quot;LOG_PATTERN&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%t] %-5level [%logger&#123;50&#125;:%L] - %msg%n&quot;/&gt; &lt;property name=&quot;LOG_CONSOLE_PATTERN&quot; value=&quot;%style&#123;%d&#123;ISO8601&#125;&#125;&#123;bright,green&#125; %highlight&#123;%-5level&#125; [%style&#123;%t&#125;&#123;bright,blue&#125;] %style&#123;%C&#123;&#125;&#125;&#123;bright,yellow&#125;: %msg%n%style&#123;%throwable&#125;&#123;red&#125;&quot;/&gt; &lt;property name=&quot;ACCESS_LOG_PATTERN&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; - %msg%n&quot;/&gt; &lt;!-- 定义日志存储的路径 --&gt; &lt;property name=&quot;FILE_PATH&quot; value=&quot;logs&quot;/&gt; &lt;property name=&quot;FILE_NAME&quot; value=&quot;newframe&quot;/&gt; &lt;/properties&gt; &lt;AsyncLogger name=&quot;com.xxx.biz.config.log.AccessLogInterceptor&quot; level=&quot;debug&quot; includeLocation=&quot;true&quot; additivity=&quot;false&quot;&gt; &lt;AppenderRef ref=&quot;accessAppender&quot;/&gt; &lt;AppenderRef ref=&quot;consoleAppender&quot;/&gt; &lt;/AsyncLogger&gt;","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"}]},{"title":"","slug":"架构设计/设计秒杀服务的限流策略","date":"2025-10-21T07:55:18.846Z","updated":"2025-10-21T08:31:43.760Z","comments":true,"path":"2025/10/21/架构设计/设计秒杀服务的限流策略/","permalink":"https://andy-whb-cn.github.io/2025/10/21/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E8%AE%BE%E8%AE%A1%E7%A7%92%E6%9D%80%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%99%90%E6%B5%81%E7%AD%96%E7%95%A5/","excerpt":"","text":"层层限流策略 合法性限流首先需要知道哪些请求是非法的，并针对场景进行限制。比如需要限制机器人或刷单行为，解决方法有： 1、验证码，有效规避机器人且拉长用户访问时间； 2、IP限制，使用网络监测技术监控相同IP的访问频率，或者反复购买同一件商品，加入到黑明单； 3、隐藏秒杀入口，秒杀之前不开放。 负载限流负载限流是指对网络请求，进行网络流量的负载均衡，通常配置如nginx进行请求的负载均衡。根据网络7层模型，对网络请求可以在多层设备上进行负载均衡，也就是级联负载。 级联负载并不是越多越好，原因是每增加一个负载，就增加了一次转发路径，可能会带来网络延迟问题。 常见的软负载主要是用Nginx或LVS（四层）+Nginx，可以满足绝大多数应用。 还可以利用一些硬件负载工具进行硬负载。 服务限流服务器限流1、容器设置最大连接数2、服务进行算法限流：令牌桶、漏斗， guava 队列限流用户请求加入临时队列，每个子系统按照最大承载性能进行拉取消费处理。 缓存限流静态资源，浏览器缓存网站静态页面资源，较大的图片可以缓存在nginx或oss，更大的视频资源可以缓存到CDN服务器（底层可以是OSS）。 动态二级缓存 缓存也不是越多越好，因为缓存多就会导致一致性问题 监控限流线程监控CPU&#x2F;内存利用率，采用服务降级或拒绝策略","categories":[],"tags":[]},{"title":"","slug":"小工具/Python小工具","date":"2025-04-25T02:29:12.878Z","updated":"2025-04-25T02:30:09.423Z","comments":true,"path":"2025/04/25/小工具/Python小工具/","permalink":"https://andy-whb-cn.github.io/2025/04/25/%E5%B0%8F%E5%B7%A5%E5%85%B7/Python%E5%B0%8F%E5%B7%A5%E5%85%B7/","excerpt":"","text":"一、 PDF压缩12345678910111213141516171819202122232425262728293031323334import fitz def compress_pdf(input_pdf_path, output_pdf_path): try: pdf = fitz.open(input_pdf_path) writer = fitz.open() for page_num in range(len(pdf)): page = pdf[page_num] pix = page.get_pixmap() # 压缩图片 img = fitz.open(&quot;png&quot;, pix.tobytes()) # 压缩图片质量 img_pix = img[0].get_pixmap() new_image_bytes = img_pix.tobytes(output=&quot;jpeg&quot;, jpg_quality=30) width = pix.width height = pix.height new_page = writer.new_page(width=width, height=height) # new_page = writer.new_page(width=rect.width, height=rect.height) new_page.insert_image((0, 0, width, height), stream=new_image_bytes) writer.save(output_pdf_path, deflate=True, garbage=4) writer.close() pdf.close() print(f&quot;PDF 压缩完成，保存至 &#123;output_pdf_path&#125;&quot;) except Exception as e: print(f&quot;压缩过程中出现错误: &#123;e&#125;&quot;) if __name__ == &quot;__main__&quot;: input_pdf = &quot;/Users/xx/Downloads/xx.pdf&quot; output_pdf = &quot;/Users/xx/Downloads/xx-1.pdf&quot; compress_pdf(input_pdf, output_pdf)","categories":[],"tags":[]},{"title":"","slug":"大模型/探究 PIKE-RAG","date":"2025-02-17T05:18:52.109Z","updated":"2025-02-24T06:02:57.292Z","comments":true,"path":"2025/02/17/大模型/探究 PIKE-RAG/","permalink":"https://andy-whb-cn.github.io/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E6%8E%A2%E7%A9%B6%20PIKE-RAG/","excerpt":"","text":"参考：https://blog.csdn.net/qq_41739364/article/details/145655874 是什么PIKE-RAG是微软亚洲研究院推出的检索增强型生成框架。 解决什么问题传统RAG方案很难从冗长、多格式乃至图表混杂的数据中，高效且准确地抽取并理解“专业领域知识”以及“多步推理逻辑”，具体需要解决的问题： 知识来源多样，检索难以兼容：数据格式复杂（PDF、图表、数据库等），致使简单文本分块失效； 缺乏领域专业化：现有LLMs对专业名词、物理&#x2F;法律原理的理解不充分； 一刀切式处理，不支持多层次任务：简单问题与多跳复杂问题混为一谈，缺少对任务复杂度的量化或分级机制。 PIKE-RAG因此提出，针对不同“难度等级”（从简单事实检索到多跳推理、预测、创意规划），分阶段优化系统，使之在“知识抽取”、“推理逻辑”、“问题分解”方面更适配实际工业应用。 它不仅检索文本，而且会将原文中蕴含的关键领域知识进行更深入的结构化提炼（如“原子化知识”或“多层异构图”），并采用“分步式”或“多回合式”推理策略去解决复杂问题。 核心研究论点1、提出“专业知识与推理增益”的 RAG 新范式： 主张在传统检索增强式生成（RAG）中，不仅要“检索”文本片段，也要有效地抽取和运用专业化知识，并借助合乎逻辑的推理轨迹来支撑回答的准确性。2、分级问题分类与分层系统划分： 将工业领域常见问题从易到难分为四类（事实类、链式推理类、预测类、创造类）；并据此将 RAG 系统的能力分为四级（L1–L4），指导系统由浅入深迭代开发。3、提出“PIKE-RAG”框架： 通过知识原子化（Knowledge Atomizing）和知识感知式的任务分解（Knowledge-Aware Task Decomposition）显著提升复杂多跳推理、预测以及创造类问题的可解性与准确度。 创新点1、避免单个子问题“问错”后就彻底走偏；通过多原子问题候选，可以更灵活地匹配文本里多样的表达方式。 面对需要跨多文档、多跳、多方面对比&#x2F;分析的复杂问题，单轮检索 + LLM 生成方式往往不足。 现有的一些多跳方法（Self-Ask 等）尽管引入了“自问自答”的思路，但若每步检索的查询本身就错了或遗漏了关键子问题，也容易造成最终回答错误。 作者的观察：多跳问题常常需要在推理时“边看已有上下文，边决定下一个子问题”——如果问错了子问题，就会将检索带偏。因此需要一个更精细的“任务分解+动态检索+逐步推理”的框架，以便在每一步根据已获取的知识来生成更合理的下一个子问题或检索请求。在回答复杂问题时，不再单步生成子问题，而是生成多条潜在原子问题候选，并根据知识库中实际能检索到的答案碎片，再选取合适的子问题继续； 2、创新的框架 多层异构图谱式知识库（Multi-layer Heterogeneous Graph）：通过信息资源层、语料层、精炼知识层的多层次建模，将长文本、图表、引用关系等纳入整体图结构，方便后续检索与推理。 知识原子化（Knowledge Atomizing）：在对文本分块（chunk）基础上，利用大模型生成的“原子问题”标签，更精细地标注和切分文本片段，使每个 chunk 内部的核心要点以问答式的原子知识展示。 任务分解与多轮协同（Knowledge-Aware Task Decomposition）：通过让系统“感知”到知识库中已经存在哪些原子问题，来引导下一步更精准的拆解；多轮获取新的支撑证据，逐步构建答案的推理链。 分级系统架构（L1–L4 分阶部署）：从能回答单一事实问答（L1）到支持多跳推理（L2），再到可做预测（L3）和可提供创造性建议（L4），逐步扩展功能模块与算法复杂度。 针对需要预测或创意类问题（如 Level-3&#x2F;4），需要先完成对历史数据&#x2F;结构化信息的“收敛”，再启动 “高阶推理” 要点：预测&#x2F;创意问题往往没有现成的答案，需要先把相关知识或数据按时间序列、对比列表等形式组织好，才能在下一步推理里进行规律&#x2F;趋势发现或大胆推断；引入带有 “知识归纳抽象出更高层规律 knowledge induction &#x2F; 收集数据预测 forecasting &#x2F; 多智能体规划 multi-agent planning”等扩展模块，在已有原子知识上作更高级别合成。 预期效果：把问题拆成“先收集与结构化 → 再归纳出趋势或提出创意”，从而使 RAG 系统在专业预测和创造任务上也能形成可解释的推理链。 可能的反驳和应对可能的反驳：构建异构图知识库成本高应对：提供自动化文档解析、表格提取工具及模块化方法，后期更新维护也相对易于管理；分级部署可先在 L1&#x2F;L2 低门槛场景试点。 可能的反驳：多轮分解的效率是否下降应对：多数工业问题无需无限轮迭代，一般 2–5 轮内即可锁定核心信息；且可通过并行检索和评分机制减少不必要的轮次。 可能的反驳：在创造类问题无法验证答案正确性应对：针对创造类问题（L4），评估可以纳入专家评分、启发性、可行性等维度；并非追求唯一正确解，而是看是否提供有价值的思路。 相关参考文档：https://zhuanlan.zhihu.com/p/23796240431","categories":[],"tags":[]},{"title":"","slug":"大模型/知识库构建","date":"2025-02-17T02:44:55.561Z","updated":"2025-02-17T05:18:49.405Z","comments":true,"path":"2025/02/17/大模型/知识库构建/","permalink":"https://andy-whb-cn.github.io/2025/02/17/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%9E%84%E5%BB%BA/","excerpt":"","text":"知识库的管理 检索：PIKE-RAG COZE&#x2F;DIFY 的源码研究","categories":[],"tags":[]},{"title":"SpringData: JPA","slug":"SpringBoot/SpringData：JPA","date":"2025-01-02T07:15:57.918Z","updated":"2025-01-20T05:01:52.207Z","comments":true,"path":"2025/01/02/SpringBoot/SpringData：JPA/","permalink":"https://andy-whb-cn.github.io/2025/01/02/SpringBoot/SpringData%EF%BC%9AJPA/","excerpt":"","text":"前言Mybatis已经2年没有更新了，虽然业界还在普遍使用，但新项目已经不推荐了。对于习惯了batis这种ORM框架的开发团队，从流行度和稳定性上来说，新项目使用国内baomidou团队的Mybatis-Plus是较好的选择。当然针对mybatis-plus，国内也有一些号称更好用的ORM框架，截几个有意思的图看下，不做评论。 作为java程序员，是时候捡起业界比较火热的JPA来研究研究了。我印象中的JPA还停留在hibernate时代级联多表操作复杂、性能差等负面印象中，但据说最新的JPA 3.0 和Hibernate 6.0已经解决了这类难用的问题。","categories":[],"tags":[]},{"title":"","slug":"架构设计/企业架构设计","date":"2024-12-31T02:51:55.120Z","updated":"2024-12-31T03:04:04.271Z","comments":true,"path":"2024/12/31/架构设计/企业架构设计/","permalink":"https://andy-whb-cn.github.io/2024/12/31/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E4%BC%81%E4%B8%9A%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"埃森哲国内企业架构咨询案例：“四横五纵”架构设计“四横五纵”架构设计通过四个层次（策略层、管理层、设计层、实施层）和五个领域（业务架构、应用架构、数据架构、技术架构、架构管控）的系统化设计，确保企业IT系统与业务战略高度一致。通过自上而下的目标驱动和自下而上的实现反馈，构建出一个科学、合理的企业信息化蓝图，优化资源配置，提升企业灵活性和运营效率。 “四横”聚焦架构的分层设计，从战略到实施逐层细化；“五纵”涵盖架构的五大核心领域，形成互补协同的整体架构生态。 “四横”分层设计详解 第一层：策略层视图策略层是架构的宏观指导层，决定信息化建设的目标与方向。该层强调全局性和整体性。 主要任务： 信息化战略规划：与企业业务战略深度对接，确定长期目标和短期目标。 制定政策规范：如数据治理、信息安全、技术选型等，为架构设计提供政策框架。 规划信息化蓝图：结合业务需求与技术趋势，绘制企业信息化的总体规划。 输出成果： 信息化战略规划报告 信息化政策文件 第二层：管理层视图管理层进一步细化策略层目标，形成具体的架构蓝图。 主要任务： 业务架构规划：定义业务域、职能、流程及其关联关系。 应用架构规划：设计支撑业务的应用系统及其功能模块。 数据架构设计：明确数据主题、数据模型及流转关系。 技术架构规划：配置支持应用和数据的技术平台。 输出成果： 业务架构图 应用架构图 数据架构图 技术架构图 第三层：设计层视图设计层聚焦架构的具体实现性，提供详细的解决方案。 主要任务： 应用系统设计：功能模块、界面、数据库详细设计。 数据模型设计：包括概念、逻辑、物理数据模型。 技术平台细化：明确技术组件、接口和部署方案。 安全体系规划：设计全面的信息安全方案。 输出成果： 详细设计文档（应用、数据、技术、安全） 第四层：实施层视图实施层是架构设计的落地和执行阶段。 主要任务： 软件开发：按照设计文档进行开发、测试和调试。 系统集成：实现应用系统间的数据交换与业务协同。 部署与运维：将系统部署到生产环境，并提供持续支持。 持续优化：根据反馈调整和改进系统。 输出成果： 软件系统 集成后的应用系统 运维文档 “五纵”架构设计详解 1. 业务架构业务架构是企业架构的基础，聚焦企业的核心业务流程和价值链。 关键要素： 业务域与职能：划分业务领域（如财务、人力资源等）及具体职能。 组织单元：定义部门、团队等具体执行实体及其协作关系。 业务流程：梳理起点、终点及活动逻辑，优化端到端流程。 输出成果： 业务架构图 端到端流程图 2. 应用架构应用架构支撑业务逻辑的信息化实现，规划应用系统的功能与交互。 关键要素： 应用域和功能模块：明确每个应用的功能范围及模块划分。 接口与交互：定义数据交换接口和交互协议，确保系统集成。 应用分布与部署：规划应用在组织单元中的使用和分布。 输出成果： 应用架构图 接口规范文档 3. 数据架构 数据架构确保企业数据资源的一致性和高效利用。 关键要素： 数据主题与实体：明确数据主题（如客户数据、财务数据）和数据实体。 数据模型：设计概念、逻辑和物理数据模型。 数据流转与治理：规划数据在系统间的流转及数据质量、安全管理策略。 输出成果： 数据架构图 数据模型设计文档 4. 技术架构技术架构描述支撑业务和数据的技术平台及基础设施。 关键要素： 技术平台与组件：选择操作系统、数据库、中间件等组件。 系统集成与接口：确保不同技术平台和系统间的无缝连接。 基础设施与安全：规划数据中心、网络和安全体系。 输出成果： 技术架构图 集成方案 安全设计文档 5. 架构管控架构管控是保障架构设计一致性和持续优化的关键。 关键要素： 架构原则：明确业务导向、技术先进、安全可靠等基本准则。 管理规范：制定评审机制、变更管理流程。 架构资产：构建蓝图、模式、标准等资产库。 评审与改进：定期评估架构成果，确保动态优化。 输出成果： 管控规范文档 架构评审报告","categories":[],"tags":[]},{"title":"","slug":"架构思维/年终工作汇报","date":"2024-12-20T05:12:04.151Z","updated":"2024-12-26T10:12:38.766Z","comments":true,"path":"2024/12/20/架构思维/年终工作汇报/","permalink":"https://andy-whb-cn.github.io/2024/12/20/%E6%9E%B6%E6%9E%84%E6%80%9D%E7%BB%B4/%E5%B9%B4%E7%BB%88%E5%B7%A5%E4%BD%9C%E6%B1%87%E6%8A%A5/","excerpt":"","text":"写作思路思维导图（有思考的汇报）12345678910111213141516171819202122232425262728293031323334353637@startmindmap&lt;style&gt;mindmapDiagram&#123; :depth(1)&#123; BackgroundColor lightGreen &#125;&#125;&lt;/style&gt;* 年终工作汇报**:==工作框架给概念;***_ 1、岗位职责包括几个板块?***_ 2、各板块几年的重点工作是什么？***_ 3、总体的完成情况如何？**:==核心项目看好戏;***_ 1、今年最关键的项目是什么？***_ 2、具体怎么做的，遇到什么问题？***_ 3、问题怎么解决的，有哪些收获？**:==价值影响讲价值;***_ 1、短期价值，给业务的影响？***_ 2、长期影响，给组织的价值？***_ 3、个人的知识更新和能力沉淀？***_ 4、总结出来的方法论和工具？**:==明年计划谈规划;***_ 1、对业务的观察是什么，长期趋势；***_ 2、对组织的理解是什么，重点工作；***_ 3、对细节的困惑是什么，请教解答；***_ 4、对挑战的预估是什么，提出需求；@endmindmap 投顾平台：1、投顾平台3.9.0详设和代码评审，12&#x2F;27发布；2、意见反馈需求沟通，待低代码反馈接口和排期；3、生产问题排查：a) 用户老机器卡顿导致多次加载请求，考虑后台加入全局防重；b) 当日绩效关系的问题；4、支持信创验收材料准备；5、投顾平台VPN旧入口调整问题 企微SCRM：1、持续跟踪四步法对接CDP客群的进展：客户中心统计接口已提供，联调时间延期到下周；2、生产问题排查：a) 员工OA发起离职流程仍在通讯录的问题；a) 服务记录关联已停用的线索问题；b) 当日到期线索不展示的问题；3、企微SCRM 2.6.1 版本发布支持：下线非信创； 资配中心：1、本周版本进度跟踪：对接内容中心，页面文字调整，去掉全市场私募，预计12&#x2F;27发布； 其他：1、年终述职2、北斗场景需求分析：客群&#x2F;线索策略对接CIO栏目自动化展示； 1、客群&#x2F;线索策略对接CIO栏目场景架构方案评审；2、持续跟踪四步法对接CDP客群的进展；3、MOT工单接口评审；","categories":[],"tags":[]},{"title":"Claude构建有效的智能体","slug":"大模型/Claude构建有效的智能体","date":"2024-12-19T16:00:00.000Z","updated":"2025-01-17T02:37:49.109Z","comments":true,"path":"2024/12/20/大模型/Claude构建有效的智能体/","permalink":"https://andy-whb-cn.github.io/2024/12/20/%E5%A4%A7%E6%A8%A1%E5%9E%8B/Claude%E6%9E%84%E5%BB%BA%E6%9C%89%E6%95%88%E7%9A%84%E6%99%BA%E8%83%BD%E4%BD%93/","excerpt":"","text":"在过去的一年里，我们与数十个团队合作，在各个行业构建大型语言模型（LLM）智能体。一直以来，最成功的实现并不是使用复杂的框架或专门的库。相反，他们使用简单、可组合的模式进行构建。 在这篇文章中，我们分享了从与客户合作以及自己构建智能体中学到的东西，并为开发人员提供了构建有效智能体的实用建议。 什么是智能体？“Agent” 可以有几种定义方式。一些客户将Agent定义为完全自主的系统，能够在较长时间内独立运行，使用各种工具来完成复杂任务。另一些客户则用这个术语来描述更具规定性的实现，即遵循预定义的工作流。在 Anthropic，我们将所有这些变体都归类为具有Agent性质的系统，但在工作流和Agent之间做出了重要的架构区分： 工作流是通过预定义的代码路径来编排大型语言模型和工具的系统。 智能体是大语言模型动态地指导自身的流程和工具，并保持对如何完成任务进行控制的系统。 下面，我们将详细探讨这两种具有Agent性质的系统。在附录 1（“实践中的智能体”）中，我们描述了两个领域，在这些领域中，客户发现使用这类系统具有特别的价值。 何时（以及何时不使用）Agent在使用大语言模型构建应用程序时，我们建议找到尽可能简单的解决方案，并且仅在需要时增加复杂性。这可能意味着根本不构建具有自主性的系统。具有自主性的系统通常以延迟和成本为代价来换取更好的任务性能，你应该考虑这种权衡何时才有意义。 当需要更高的复杂性时，工作流可为定义明确的任务提供可预测性和一致性，而当需要大规模的灵活性和模型驱动的决策时，智能体是更好的选择。然而，对于许多应用程序来说，通过检索和上下文示例优化单个大型语言模型调用通常就足够了。 何时以及如何使用框架有许多框架使智能体系统更容易实现，包括： 来自 LangChain 的 LangGraph; Amazon Bedrock 的人工智能Agent框架； Rivet，一个可拖放的图形用户界面大语言模型工作流生成器; Vellum，另一个用于构建和测试复杂工作流的图形用户界面工具。 这些框架通过简化诸如调用语言模型、定义和解析工具以及将调用链接在一起等标准的低级任务，使得入门变得容易。然而，它们通常会创建额外的抽象层，这可能会掩盖底层的提示和响应，使得调试更加困难。它们还可能会让人在简单的设置就足够的情况下倾向于增加复杂性。 我们建议开发人员从直接使用大语言模型 API 开始：许多模式可以用几行代码实现。如果你确实使用了一个框架，请确保你理解底层代码。对底层情况的错误假设是客户错误的常见来源。 有关一些示例实施，请参阅我们的说明书。 模块、工作流和智能体在本节中，我们将探讨在生产中看到的智能体系统的常见模式。我们将从基础模块 —— 增强型语言模型开始，并逐步增加复杂性，从简单的组合工作流到自主智能体。 模块：增强的 LLM具有Agent性质的系统的基本模块是一个经过检索、工具和记忆等增强功能强化的大语言模型。我们当前的模型可以积极地使用这些能力 —— 生成自己的搜索查询、选择合适的工具，并确定要保留哪些信息。图1 增强的LLM 我们建议重点关注实现的两个关键方面：根据您的特定用例调整这些功能，并确保它们为您的大型语言模型提供一个简单、有良好文档记录的接口。虽然有很多方法可以实现这些增强功能，但一种方法是通过我们最近发布的模型上下文协议，该协议允许开发人员通过简单的客户端实现与不断增长的第三方工具生态系统集成。 在本文的其余部分，我们将假设每个大型语言模型调用都可以访问这些增强功能。 工作流：提示链提示链将一个任务分解为一系列步骤，在每个步骤中，语言模型的调用处理前一个步骤的输出。你可以在任何中间步骤添加编程检查（见下图中的 “门”），以确保流程仍在正轨上。 图2 提示链工作流 何时使用： 适合任务可以轻松、清晰地分解为固定子任务的情况。主要目标是通过使每个 LLM 调用成为更简单的任务，以延迟为代价换取更高的准确性。 适用场景示例： 生成营销文案，然后将其翻译成另一种语言。 撰写文档大纲，检查大纲是否符合特定标准，然后根据大纲撰写文档。 工作流：路由路由对输入进行分类并将其定向到专门的后续任务。这种工作流程允许分离关注点，并构建更专门的提示。如果没有这种工作流，针对一种输入进行优化可能会损害对其他输入的性能。 图3 路由工作流 何时使用： 对于复杂任务，路由很有效，在这些任务中，存在不同的类别，最好分别处理，并且可以通过大型语言模型或更传统的分类模型 &#x2F; 算法准确地进行分类。 适用场景示例： 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。 将简单 &#x2F; 常见问题路由到较小的模型（如 Claude 3.5 Haiku），将困难 &#x2F; 不寻常的问题路由到更强大的模型（如 Claude 3.5 Sonnet），以优化成本和速度。 工作流：并行化大型语言模型有时可以同时处理一项任务，并通过编程方式聚合其输出。这种工作流即并行化，表现在两个关键变体中： 分段：将任务分解为并行运行的独立子任务。 投票：多次运行同一任务以获得不同的输出。图4 并行化工作流 何时使用：当划分的子任务可以并行化以提高速度时，或者当需要多个视角或尝试以获得更高置信度结果时，并行化是有效的。对于具有多种考虑因素的复杂任务，当每个考虑因素由单独的 LLM 调用处理时，大型语言模型通常表现更好，从而可以专注于每个特定方面。 适用场景示例： 分段 实施防护机制，即一个模型实例处理用户查询，而另一个模型实例筛查其中不适当的内容或请求。这往往比让同一个大语言模型（LLM）调用同时处理防护检查和核心响应的效果更好 。 用于评估大型语言模型的性能的自动化评估，每个大型语言模型调用会基于给定提示评估模型性能的不同方面。 投票 审查一段代码是否存在漏洞，基于不同的提示词审查，并在发现问题时标记代码。 评估给定内容是否不适当，有多个提示词评估不同方面，或者需要不同的投票阈值来平衡误报和漏报。 工作流：编排器 - 工作者在编排器 - 工作者工作流中，一个中央大型语言模型动态地分解任务，将它们委派给工作者大型语言模型，并汇总它们的结果。 编排器-工作者工作流 何时使用：此工作流非常适合无法预测所需子任务的复杂任务（例如在编码中，需要更改的文件数量以及每个文件中的更改性质可能取决于任务）。虽然它在拓扑结构上相似，但与并行化的关键区别在于其灵活性 —— 子任务不是预先定义的，而是由编排器根据特定输入确定。 适用场景示例： 对多个文件每次进行复杂更改的代码产品。 搜索涉及从多个来源收集和分析信息以查找可能相关信息的任务。 工作流：评估者 - 优化者在评估者-优化者工作流中，一个大型语言模型调用生成一个响应，而另一个在循环中提供评估和反馈。评估者-优化者工作流 何时使用：当我们有明确的评估标准，并且迭代改进能提供可衡量的价值时，此工作流特别有效。良好适配的两个标志是，首先，当人类明确表达他们的反馈时，大型语言模型的响应可以明显得到改善；其次，大型语言模型可以提供这样的反馈。这类似于人类作家在制作精良文档时可能经历的迭代写作过程。 适用场景示例： 文学翻译中存在一些细微差别，翻译语言模型可能最初无法捕捉到这些差别，但评估语言模型可以提供有用的批评。 复杂的搜索任务需要多轮搜索和分析以收集全面的信息，由评估者决定是否需要进一步搜索。 智能体随着大型语言模型在关键能力方面逐渐成熟 —— 理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复，智能体正在生产中崭露头角。智能体的工作始于人类用户的命令或与之进行的交互式讨论。一旦任务明确，智能体就会进行规划并开展行动。 独立地进行，可能会返回给人类以获取更多信息或进行判断。在执行过程中，智能体在每一步都从环境中获取 “真实情况”（例如工具调用结果或代码执行结果）以评估其进展至关重要。然后，智能体可以在检查点或遇到阻碍时暂停以获取人类反馈。任务通常在完成时终止，但通常也会包括停止条件（例如最大迭代次数）以保持控制。 智能体可以处理复杂的任务，但它们的实现通常很直接。它们通常只是基于环境反馈在循环中使用工具的大语言模型。因此，清晰且深思熟虑地设计工具集及其文档至关重要。我们在附录 2 中详细阐述了工具开发的最佳实践。 自治Agent 何时使用：智能体可用于难以或无法预测所需步骤数量的开放式问题，以及无法硬编码固定路径的情况。语言模型可能会运行很多轮，并且你必须在一定程度上信任其决策。代理的自主性使其非常适合在受信任的环境中扩展任务。代理的自主性意味着更高的成本以及潜在的错误叠加。我们建议在沙盒环境中进行广泛测试，并设置适当的防护措施。 适用场景示例：以下示例来自我们自己的实现： 一个用于解决 SWE-bench 任务的编码智能体，这些任务涉及根据任务描述对许多文件进行编辑。 我们的 “计算机使用” 参考实现，其中 Claude 使用计算机来完成任务。 编码智能体的高级流程 结合并定制这些模式这些构建模块并非规定性的。它们是开发人员可以塑造和组合以适应不同用例的常见模式。与任何 LLM 功能一样，成功的关键在于衡量性能并对实现进行迭代。重复一遍：只有当复杂性明显改善结果时，你才应该考虑增加复杂性。 总结在大语言模型领域的成功并不在于构建最复杂的系统。而是在于为你的需求构建合适的系统。从简单的提示开始，通过全面评估对其进行优化，只有在更简单的解决方案无法满足需求时才添加多步骤的智能体系统。 在实现智能体时，我们尝试遵循三个核心原则： 保持你的智能体设计的简洁性。 通过明确展示智能体的规划步骤来优先考虑透明度。 通过全面的工具文档和测试精心设计你的代理计算机接口（ACI）。 框架可以帮助你快速上手，但在转向生产环境时，不要犹豫减少抽象层并使用基本组件进行构建。遵循这些原则，你可以创建出不仅强大而且可靠、可维护并受用户信任的智能体。 致谢由埃里克・施伦特兹和巴里・张撰写。这项工作借鉴了我们在 Anthropic 构建智能体的经验以及我们的客户分享的宝贵见解，对此我们深表感激。 附录 1：实践中的智能体我们与客户的合作揭示了人工智能体的两个特别有前景的应用，这些应用展示了上述模式的实际价值。这两个应用都说明了智能体如何在需要对话和行动、有明确的成功标准、支持反馈循环并整合有意义的人工监督的任务中发挥最大价值。 A. 客户支持客户支持将熟悉的聊天机器人界面与通过工具集成增强的功能相结合。对于更具开放性的智能体来说，这是一种自然的契合，原因如下： 支持交互自然地遵循对话流程，同时需要访问外部信息和采取行动。 工具可以集成以提取客户数据、订单历史记录和知识库文章。 诸如发放退款或更新票务等操作可以通过编程方式处理；并且成功可以通过用户定义的解决方案来明确衡量。 几家公司已经通过基于使用情况的定价模式证明了这种方法的可行性，该模式仅对成功的解决方案收费，这显示了他们对其智能体有效性的信心。 B. 编码智能体软件开发领域已展现出对大语言模型（LLM）功能的巨大潜力，其能力从代码补全发展到自主解决问题。智能体特别有效，原因如下： 代码解决方案可通过自动化测试进行验证；智能体可以使用测试结果作为反馈来迭代解决方案。 问题空间是明确界定且结构化的；并且输出质量可以客观地衡量。 在我们自己的实现中，智能体现在可以仅根据拉取请求描述来解决 SWE-bench Verified 基准中的实际 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。 附录 2：对你的工具进行提示工程设计无论您正在构建哪个智能体系统，工具都可能是您智能体的重要组成部分。工具使 Claude 能够通过在我们的 API 中指定它们的确切结构和定义来与外部服务和 API 进行交互。当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含一个工具使用块。工具定义和规范应与总体提示一样受到及时的工程关注。在这个简短的附录中，我们描述了如何对工具进行提示工程。 通常有几种方法可以指定相同的操作。例如，你可以通过编写差异（diff）或重写整个文件来指定文件编辑。对于结构化输出，你可以在 Markdown 中或在 JSON 中返回代码。在软件工程中，像这样的差异是表面的，可以无损地从一种转换为另一种。然而，某些格式对于大语言模型来说比其他格式更难编写。编写差异需要在编写新代码之前知道块头中有多少行正在更改。与 Markdown 相比，在 JSON 中编写代码需要对换行符和引号进行额外的转义。 我们对确定工具格式的建议如下： 在模型逼入绝境前，给它足够的token来 “思考”。 保持格式接近模型在互联网文本中自然看到的格式。 确保没有格式化 “开销”，例如必须准确计算数千行代码的数量，或者对其编写的任何代码进行字符串转义。 一条经验法则是考虑在人机界面（HCI）上投入多少精力，并计划在创建良好的代理 - 计算机界面（ACI）上投入同样多的精力。以下是关于如何做到这一点的一些想法： 设身处地为模型着想。根据描述和参数，使用这个工具是否显而易见，还是需要仔细思考？如果是后者，那么对模型来说很可能也是如此。一个好的工具定义通常包括示例用法、边缘情况等。 案例、输入格式要求以及与其他工具的明确界限。 如何更改参数名称或描述以使其更加明显？可以将此视为为团队中的初级开发人员编写出色的文档字符串。在使用许多类似工具时，这一点尤其重要。 测试模型如何使用你的工具：在我们的工作台中运行许多示例输入，以查看模型会犯哪些错误，并进行迭代。 防错你的工具。更改参数，使其更难出错。 在为 SWE-bench 构建代理时，我们实际上花费了比整体提示更多的时间来优化我们的工具。例如，我们发现，在代理移出根目录后，模型会使用使用相对文件路径的工具出错。为了解决这个问题，我们将工具更改为始终需要绝对文件路径，我们发现该模型完美地使用了这种方法。","categories":[],"tags":[]},{"title":"","slug":"容器化/云原生探究","date":"2024-12-13T02:48:04.453Z","updated":"2024-12-16T05:31:40.752Z","comments":true,"path":"2024/12/13/容器化/云原生探究/","permalink":"https://andy-whb-cn.github.io/2024/12/13/%E5%AE%B9%E5%99%A8%E5%8C%96/%E4%BA%91%E5%8E%9F%E7%94%9F%E6%8E%A2%E7%A9%B6/","excerpt":"","text":"什么是云原生架构定义云原生是一种软件开发理念和方法论，强调在云计算环境中构建、部署和管理应用程序，充分利用云的弹性、可扩展性和分布式特性。云原生架构是一种构建和运行应用程序的架构风格，它充分利用云计算环境的优势，以容器、微服务、不可变基础设施、声明式 API 等技术为基础，实现应用的快速部署、弹性扩展、高效运维和持续交付。 解决什么问题 问题域 传统架构面临的问题 云原生解决方案 示例 应用开发与部署效率 开发周期长，迭代速度慢，各功能模块紧密耦合，整体应用需重新构建测试；部署依赖复杂环境配置，开发与生产环境差异易导致部署失败 采用微服务架构，各微服务独立开发、测试、部署；容器技术将应用及其依赖打包成独立容器，保证环境一致性 电商应用拆分为用户、商品、订单等微服务，分别开发部署；Docker 容器化应用可在不同环境一致运行 应用的可扩展性和弹性 需预先购买大量硬件资源，资源闲置与不足情况并存，单体应用扩展复杂且风险高 基于云计算弹性，自动调整资源分配，微服务可独立扩展 在线教育平台直播时自动增加服务器实例，结束后减少；电商订单服务单独扩展 系统的可靠性和容错性 一个组件故障可能导致整个应用崩溃，故障恢复需人工干预，过程复杂 采用熔断器模式，多实例部署与负载均衡，自动化运维工具与监控系统快速检测故障并恢复 微服务通信中，故障服务被熔断器切断请求；容器编排平台自动重启故障容器 运维管理复杂性 运维需管理硬件、操作系统、中间件和应用，手动操作多，依赖关系复杂；监控分散，数据整合难 不可变基础设施，代码化管理，自动化部署与配置管理工具；集中式监控系统整合数据 通过更新容器镜像更新应用；Prometheus + Grafana 监控容器、微服务和基础设施 概念如何构建云原生","categories":[],"tags":[]},{"title":"","slug":"大模型/提示词设计","date":"2024-12-09T08:54:40.104Z","updated":"2025-02-17T02:44:42.548Z","comments":true,"path":"2024/12/09/大模型/提示词设计/","permalink":"https://andy-whb-cn.github.io/2024/12/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B/%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364## Role: 专业投资顾问## Background: 我是一位经验丰富的基金投资顾问,我会严格学习并运用[Skills]进行工作，结合[Data]数据，给出专业的基金诊断报告。## Preferences: 我会严格按照[Skills]部分进行输出。## Profile: - author: Jerry- version: 1.0- language: 中文- description: 我是一位经验丰富的基金投资顾问,我会对基金数据进行分析并给出基金诊断报告。## Goals:- 给出一句话介绍- 持仓建议- 基金亮点特别注意：用户下达的指令为第一要义## User Command- 原文:用户输入问题，从问题中提取基金代码或名称，或提示用户相近的基金代码或名称。## Skills:- 给出一句话介绍：分析近3年的收益率，同类排名，点评；最大回撤，同类排名，点评；价值风格，点评；- 给出持仓建议：适合的投资者风险等级或者投资偏好- 基金亮点：给出基金表现的亮点，如明星基金、老将掌舵、近3年业绩等；## Text Style- 事实+专业化## Data- &#123;&#123; &quot;attributes&quot;: &#123; &quot;cumulativeProfit&quot;: 4.4176, &quot;dailyIncrease&quot;: 1.27, &quot;fundCode&quot;: &quot;000251&quot;, &quot;fundId&quot;: 24756, &quot;fundName&quot;: &quot;工银瑞信金融地产行业混合型证券投资基金A类&quot;, &quot;inceptionDate&quot;: 1377446400000, &quot;managerName&quot;: &quot;鄢耀&quot;, &quot;net&quot;: &#123; &quot;cumulativeNav&quot;: 4.4176, &quot;netDate&quot;: 1733414400000, &quot;netValue&quot;: 2.712 &#125;, &quot;productCode&quot;: &quot;000251&quot;, &quot;productName&quot;: &quot;工银瑞信金融地产行业混合型证券投资基金A类&quot;, &quot;productType&quot;: 0, &quot;ret1m&quot;: -1.7, &quot;ret1y&quot;: 35.46, &quot;ret3m&quot;: 22.33, &quot;ret6m&quot;: 20.0, &quot;retIncep&quot;: 341.76, &quot;retYtd&quot;: 35.06, &quot;trustName&quot;: &quot;工银瑞信基金管理有限公司&quot; &#125;, &quot;message&quot;: &quot;成功&quot;, &quot;statusCode&quot;: &quot;0000&quot;&#125;&#125;## OutputFormat:- 第一步：仔细分析问题，从问题中提取基金代码或名称，或提示用户相近的基金代码或名称。- 第二步：根据基金代码从[Data]中匹配数据。- 第三步：充分调用[Skills]并在[第二步]的基础上进行工作，确保生成的内容符合[Goals]。- 第四步：生成完内容后,等待用户下一步指示。## Initialization: 作为基金投资顾问,我拥有基金诊断分析的能力,默认使用中文与用户友好对话。现在,请输入您需要分析的基金代码或者名称,我将为您尽心尽力。","categories":[],"tags":[]},{"title":"","slug":"架构思维/金字塔原理","date":"2024-11-28T09:35:40.133Z","updated":"2024-12-03T05:49:36.375Z","comments":true,"path":"2024/11/28/架构思维/金字塔原理/","permalink":"https://andy-whb-cn.github.io/2024/11/28/%E6%9E%B6%E6%9E%84%E6%80%9D%E7%BB%B4/%E9%87%91%E5%AD%97%E5%A1%94%E5%8E%9F%E7%90%86/","excerpt":"","text":"金字塔原理这个原理出自于《金字塔原理》这本书，书中主要帮我们解决两大问题：思维混乱、逻辑不清。 第一部分 表达的逻辑Why观点1: “对文章阐述的思想作出疑问/回答式反应是人类的一种自然反应” 观点2: “如果你的文章结构呈金字塔形，文章的思路自金字塔顶部开始逐渐向下展开，那么读者肯定会觉得你的文章比较容易读懂。” 归类分组 归类分组搭建金字塔，找出逻辑关系，抽象概括。 奇妙的数字“7”：大脑的短期记忆无法一次容纳约7个以上的记忆项目。有的人可能一次能记住9个项目，而有的人则只能记住5个。大脑比较容易记住的是3个项目，当然最容易记住的是1个项目。 一次不要超过7个思想、概念或项目；找出逻辑关系； 结论先行 读者会将读到的思想进行归类分组和总结概括，以便记住。 如果作者传达给读者的思想已经事先进行了归类和概括，并且按自上而下的顺序呈现，读者就能更容易理解作者表达的思想。 条理清晰的文章应当具有金字塔结构，并且不断“自上而下”地向读者传递信息（虽然在开始写作时作者的思路是“自下而上”的）”。 自上而下表达，结论先行 最有效的表达方法是:先提出总的概念，再列出具体项目，即要自上而下地表达思想。 自下而上思考，总结概括 “金字塔中的思想以3种方式互相关联——向上、向下和横向。位于一组思想的上一个层次的思想是对这一组思想的概括，这一组思想则是对其上一层次思想的解释和支持。” 文章中的思想必须符合以下规则： 纵向：任一层次上的思想必须是其下一层次思想的概括。 横向：每组中的思想必须属于同一逻辑范畴。 横向：每组中的思想必须按逻辑顺序组织。” 逻辑顺序（组织思想基本上只可能有4种）： 演绎顺序：大前提、小前提、结论 时间（步骤）顺序：第一、第二、第三 结构（空间）顺序：波士顿、纽约、华盛顿 程度（重要性）顺序：最重要、次重要，等等” What金字塔内部结构 纵向关系 “纵向的疑问&#x2F;回答式对话” 表达“思想”：向受众发出新信息并且引起疑问的语句 你的每一个表述都应当引发读者的疑问，而你也必须在这一表述下的横向结构层次上逐个回答读者的疑问。 横向关系 “横向的演绎或归纳推理” 表述必须具有明确的归纳或演绎关系，但不可同时既具有归纳关系，又具有演绎关系。在组织思想时，归纳和演绎是仅有的两种可能的逻辑关系。 以演绎法回答由某个思想引起的疑问，你就必须进行3段论式的论述。其中，第二个思想是对第一个思想的主语或谓语作出的表述，而第三个思想则从以上两个思想中得出推论。 如果你选择以归纳法回答由某个思想引起的疑问，你就必须保证该组思想在逻辑上具有共同点，并且可以用同一个名词表示。 演绎性思想组合是由几个承前启后的论述组成的。第一个思想是对当今世界上的某种现象的表述；第二个思想是对该句子的主语或谓语所作的表述; 第三个思想则说明了以上两种表述同时在世界上存在时所具有的隐含意义。 因此，演绎性思想组合具有以下形式： 所有的人都会死。 苏格拉底是一个人。 因此苏格拉底会死。 你需要概括演绎性思想组中的论述，以提高一个抽象层次。你的概括主要基于最后一个表述：“因为苏格拉底是一个人，所以苏格拉底会死。” 归纳性思想组合中的思想互相关联，你可以用同一个名词表示组中所有 思想，如支持的原因、反对的原因、步骤、问题，等等。归纳性论述的形式是: 法国坦克已抵达波兰边境。 德国坦克已抵达波兰边境。 俄国坦克已抵达波兰边境。 为了提高一个抽象层次，你需要识别以上句子的共同点（即：都是针对波兰的战争行为），并得出一个推论。你的推论可能是“波兰将受到坦克入侵” 或类似的思想。” 序言（SCQA模型） “讲故事式的序言” 文章需要回答的初始问题（即读者将提出的第一个疑问)。你可以通过讲故事式的序言（前言、 引言）确定初始问题。 问题的起源和发展必然以叙述的形式出现，因此也应当按照典型的叙述模式发展。序言的开头应向读者说明“背景”（situation)的时间和地点。 在这一背景中应当发生了某件事情，可称为“冲突”（complication)，使读者提出（或将使读者提出）你的文章将要“回答”（answer)的“疑问” (question)。 How自上而下法 第二部分 思考的逻辑 重要次要的先后要求：先全局后细节、先结论后原因、先结果后过程三种应用逻辑顺序 时间&#x2F;步骤顺序 空间&#x2F;结构顺序 程度&#x2F;重要性顺序 第三部分 解决问题的逻辑 界定问题 设想问题产生的领域 确定非期望结果（现状 R1） 确定期望结果（目标 R2） 确定是否已经采取了解决问题的行动 。 结构化分析问题 从信息资料入手 设计诊断框架 建立逻辑树 。 第四部分 演示的逻辑 在书面上呈现金字塔 突出显示文章的框架结构 上下文之间要有过渡 。 在PPT演示文稿中呈现金字塔 设计文字PPT幻灯片 设计图表PPT幻灯片 故事梗概 。 在字里行间呈现金字塔 画脑图 把图像复制成文字 。 例子参考 结语使用金字塔原理，能够使你在遇到事情的时候，形成一定的思考逻辑以及一些特定的流程结构，它可以检查你的思想的有效性、一致性和完整性，还能够帮你发现某些遗漏的细节，甚至拓展一些新的创意。","categories":[],"tags":[]},{"title":"分布式系统设计学习","slug":"分布式系统理论/分布式系统设计学习","date":"2024-11-25T05:52:37.665Z","updated":"2024-11-28T09:17:13.085Z","comments":true,"path":"2024/11/25/分布式系统理论/分布式系统设计学习/","permalink":"https://andy-whb-cn.github.io/2024/11/25/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"分布式系统与单体系统的 存储要解决问题主要问题：数据的水平扩展解决方案：1、数据水平拆分：数据分片（范围分片、哈希分片）-&gt;不同的算法；2、分布到多个节点：数据复制（同步、异步），带来可靠性和可用性（数据副本-一致性协议、主一致-分布式锁） 计算并行计算使用多种计算资源同时计算问题的过程，如多线程，多进程（分布到服务集群）。 分布式计算把任务分割到多台服务器进行并行计算，然后得到结果。（与集群计算的区分是集群计算某项任务是具体分到某个机器上执行的）设计思想：MapReduce流式计算框架：Storm、Spark、Flink 云计算通过API开发应用，然后上传到云上托管，是属于分布式计算和虚拟技术的综合技术。 输入输出网络协议网络IO模型通信技术（序列化&#x2F;反序列化、RPC、MQ）控制器系统调度设计，调度算法与负载策略 流量调度负载均衡、服务路由、熔断、降级、限流 资源调度Mesos、Yarn 基于计算资源的调度；HDFS、GlusterFS、Ceph 基于存储资源的调度；Kubernetes、Mesos 基于容器资源的调度（包括计算、存储、网络等综合性的资源调度）；","categories":[],"tags":[]},{"title":"探究CAP、PACELC、BASE理论","slug":"分布式系统理论/探究CAP、PACELC、BASE理论","date":"2024-11-06T09:22:10.177Z","updated":"2024-12-17T07:35:08.224Z","comments":true,"path":"2024/11/06/分布式系统理论/探究CAP、PACELC、BASE理论/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%90%86%E8%AE%BA/%E6%8E%A2%E7%A9%B6CAP%E3%80%81PACELC%E3%80%81BASE%E7%90%86%E8%AE%BA/","excerpt":"","text":"CAPCAP 理论是由加州大学伯克利分校的 Eric Brewer 教授在 2000 年提出的，当时他在分布式计算原理研讨会（PODC）上提出了这一猜想。在 2002 年，经过 Seth Gilbert 和 Nancy Lynch 通过反证法从理论上证明了 CAP 猜想后，CAP 理论正式成为了分布式系统理论的基石之一。这一证明发表在ACM SIGACT News上，文章标题为“Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services”。 这个理论即在一个分布式系统中，不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）这三个条件。实际上在分布式环境下，必须选择P。因此，分布式系统理论不可能选择CA，只能选择CP或AP。 C（一致性）：对于指定客户端而言，保证读操作能够返回最新的写操作结果。在分布式系统中，这意味着所有节点在同一时间具有相同的数据副本。 A（可用性）：非故障的节点在合理的时间内返回系统的正常响应(不是错误和超时的响应)。 P（分区容错性）：当系统中某个节点或网络分区出现后，整个系统仍然能对外提供满足一致性或可用性的服务(即，部分故障不影响整体使用)。 CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但放弃P的同时也就意味着放弃了系统的扩展性，也就是分布式节点受限，没办法部署子节点，这是违背分布式系统设计的初衷的。单机数据库或共享存储数据库，满足ACID的事务特性，符合CA。 CP without A：如果不要求A（可用），相当于每个请求都需要在服务器之间保持强一致，而P（分区）会导致同步时间无限延长(也就是等待数据同步完才能正常访问服务)，一旦发生网络故障或者消息丢失等情况，就要牺牲用户的体验，等待所有数据全部一致了之后再让用户访问系统。设计成CP的系统其实不少，最典型的就是分布式数据库，如Redis、HBase等。对于这些分布式数据库来说，数据的一致性是最基本的要求，因为如果连这个标准都达不到，那么直接采用关系型数据库就好，没必要再浪费资源来部署分布式数据库。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。典型的应用就如秒杀活动，可能前几秒你浏览商品的时候页面提示是有库存的，当选择完商品准备下单时，系统提示下单失败，商品已售完。这其实就是先在 A（可用性）方面保证系统可以正常的服务，然后在数据的一致性方面做了些牺牲，虽然多少会影响一些用户体验，但也不至于造成用户购物流程的严重阻塞。 注： CAP关注的粒度是数据，并不是系统。系统可能即存在CP又存在AP。 CAP是忽略网络延迟的，网络延迟是客观存在的，分布式下完美的数据一致性实际是不存在的。 正常运行情况下，没有发生网络分区，不存在CP和AP的选择，可同时满足CA。 CAP中牺牲掉一个，并不意味着什么都不做，例如分区期间记录日志，以用于分区故障解决后，重新使得系统得到CA状态。 PACELC理论PACELC理论是由Seth Gilbert 和 Nancy Lynch 于2012年提出的，最初发表在IEEE Computer Magazine上，具体的文章标题是“Perspectives on the CAP Theorem”。 CAP理论主要关注在网络分区发生时，系统如何在一致性和可用性之间做出选择，但并没有考虑到在实际应用中的一些局限性，特别是在没有网络分区的情况下，系统如何在延迟（Latency）和一致性（Consistency）之间做出权衡的问题。 PACELC理论的核心思想即在网络分区发生时，系统设计者需要在一致性、可用性之间做出选择；而在没有网络分区的情况下，系统需要在延迟和一致性之间做出选择。 P（Partition tolerance）：分区容错性，指分布式系统在遇到网络分区时，仍然能够对外提供服务。 A（Availability）：可用性，指系统能够始终提供服务，即使在面对故障或网络分区时也能保持服务可用。 C（Consistency）：一致性，指所有节点在同一时间的数据完全一致。 E（Else）：在没有网络分区的情况下，系统需要在延迟（Latency）与一致性（Consistency）之间做出权衡。 L（Latency）：延迟，指数据的读写操作产生的延迟，直接影响系统的性能和用户体验。 PACELC理论的应用需要根据不同的业务场景和需求来选择合适的分布式系统架构和技术方案。例如一些需要快速响应的应用（如在线游戏、实时通讯），低延迟相对较为关键，那么就意味着用户可能看到稍微过时的数据；对于数据高度一致性要求高的应用（如金融交易、数据库同步），高一致性是必要的，即使会增加响应时间。 在实际的系统设计中，延迟和一致性的权衡也并不都是二选一的问题，而是需要根据具体的业务需求和场景来调整。系统设计者可以通过配置和优化来找到一个平衡点，以满足特定的性能和一致性要求。例如，可以通过设置不同的一致性级别、使用缓存、数据分区等技术来平衡延迟和一致性。 BASE理论BASE理论的提出者是eBay的架构师Dan Pritchett。这个理论最初在1997年由Eric Brewer和他的学生们提出概念，但Dan Pritchett在2008年的ACM上发表的文章《Base: An Acid Alternative》中将其发扬光大。 BASE理论的提出场景是基于对大规模分布式系统的实践总结，因为在分布式系统中实现强一致性的代价太大，因此提出了一种只需要各应用分区在提供高可用服务的基础上，尽最大能力保证数据一致性，也就是保证数据的最终一致性。 BASE理论的核心思想是：即使无法做到强一致性，但应用可以采用适合的方式达到最终一致性。 BASE理论的核心思想包括三个方面： 基本可用（Basically Available）：系统在出现故障时，允许损失部分可用性，即保证核心可用。比如服务降级。 软状态（Soft State）：允许系统存在中间状态，而该中间状态不会影响系统的整体可用性。分布式存储中一般一份数据至少存三个副本，允许不同节点间副本同步的延迟就是软状态的体现。 最终一致性（Eventually Consistent）：系统中的所有数据副本经过一段时间后，最终能够达成一致状态。 BASE理论的实际应用场景包括需要高可用性和可扩展性的分布式系统，如互联网应用、金融系统、大数据处理和实时分析等。在这些场景中，由于网络环境的不确定性和用户请求的高并发性，系统经常面临数据不一致的问题。BASE理论提供了一种有效的解决方案，通过放宽对一致性的要求来提高系统的可用性和实时性。例如，在电商购物车系统中，BASE理论可以通过合理的设计来确保数据的最终一致性。","categories":[],"tags":[]},{"title":"","slug":"设计原则/探究企业架构","date":"2024-11-06T07:54:50.869Z","updated":"2024-11-06T08:26:40.957Z","comments":true,"path":"2024/11/06/设计原则/探究企业架构/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E6%8E%A2%E7%A9%B6%E4%BC%81%E4%B8%9A%E6%9E%B6%E6%9E%84/","excerpt":"","text":"TOGAF&amp; Zaash投顾服务体系 1、需求提不出来2、厂商能力也不行 如何搞出业务架构，实现什么业务价值？资产配置的能力 应用架构（技术学习业务），各种学习，掌握。。资配体系研究清楚。 我们做的东西对业务的帮助有多大作用。 公司的投顾服务，投顾社区很挣钱，十月份一天收入20万？投顾社区做的是股票、ETF类的，场内的管理，场外基金需要资配的业务。。三大类资产配置模型，风险等级是中高低，做不同的资产配置模型，做动态的调整，资产配置的跟踪。。 1、业务理论的研究2、资配的源代码的研究（各类指标怎么计算） 14%没有，20年资产增长了14倍，雪球一本书。。择时，择物，90%来自于资产配置。风险预警。 投顾平台、进入常态化建设，让开发承担","categories":[],"tags":[]},{"title":"探究架构理论的演进（领域驱动架构）","slug":"设计原则/探究架构理论的演进（领域驱动架构）","date":"2024-11-06T03:23:04.498Z","updated":"2024-11-21T01:47:13.123Z","comments":true,"path":"2024/11/06/设计原则/探究架构理论的演进（领域驱动架构）/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E6%8E%A2%E7%A9%B6%E6%9E%B6%E6%9E%84%E7%90%86%E8%AE%BA%E7%9A%84%E6%BC%94%E8%BF%9B%EF%BC%88%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8%E6%9E%B6%E6%9E%84%EF%BC%89/","excerpt":"","text":"分层架构（Layered Architecture）： 提出者：不详 提出时间：最早应用于1960年代的网络协议设计，软件架构中广泛应用则是后来随着软件工程的发展逐渐形成的。 特点：将软件系统划分为多个逻辑层，每一层具有特定的职责和功能。 MVC 架构： 提出者：Trygve Reenskaug 提出时间：1979年 提出方式：用于解决桌面图形用户界面（GUI）的设计 特点：MVC 将应用程序分为三个主要部分，使得逻辑、数据和界面分开，便于管理和维护，在现代的web程序开发中被广泛应用。 EIC（Entity-Interface-Control）： 提出者：Ivar Jacobson 提出时间：1992年 特点：Robert C. Martin在做整洁架构演讲时，避免和其他概念混淆，将其调整为EBI（Entity-Boundary-Interacter，名词调整）。EBI模式相比MVC模式更加关注后端，两者可以融合，融合后就变成了View-Controller-Interacter-Entity。EBI 架构通过职责的封装将系统的变化控制在局部，最好是一个对象，符合单一职责原则。EBI的矩形边界为4，若修改为6，即可演进为2005年的六边形架构。 领域驱动设计（Domain-Driven Design, DDD）： 提出者：埃里克·埃文斯（Eric Evans） 提出时间：2003年 著作：在《领域驱动设计》中引入分层架构，希望分离领域。这意味着该模式本身是作用在整个系统层次。 核心理念：重视将实际业务问题映射到软件设计中，以解决复杂业务场景带来的软件开发问题。 六边形架构（Hexagonal Architecture）： 提出者：Alistair Cockburn 提出时间：2005年 著作：Vaughn Vernon 在《实现领域驱动设计》一书中，将 Alistair Cockburn 提出的六边形架构（Haxagonal Architecture）引入到领域驱动设计中，并将其与限界上下文结合在一起，清晰地体现了它内部的视图。这一模式的引入，实际上代表着限界上下文在架构中的核心地位。限界上下文改变了系统架构的逻辑视图，领域层的抽取则意味着领域对设计的驱动力，二者的结合可以形成一种新的架构风格，既“领域驱动架构（Domain Driven Architecture）” 特点：基于EIC，几边形不是重点，重点是提出端口&amp;适配器的概念。 核心理念：将应用程序分为内六边形和外六边形两层，内六边形实现应用的核心业务逻辑。外六边形完成外部应用、基础资源等的交互和访问。 洋葱架构（Onion Architecture）： 提出者：Jeffrey Palermo 提出时间：2008年 特点：基于六边形架构，结合DDD对内层进一步划分，形成Adapters和Application Core，且明确了依赖方向。 核心理念：通过同心圆的方式将应用程序划分为多个层次，强调依赖关系向内指向领域模型。外层依赖于内层，内层不需要知道外层的情况。 CQRS（Command Query Responsibility Segregation）设计模式： 提出者：Greg Young 提出时间：2010 年 特点：这种模式将系统中的命令（写入操作）和查询（读取操作）的职责分离开来。其核心理念来源于 Bertrand Meyer 的 CQS（Command Query Separation）设计模式，它建议将对象的方法分为两类：一类是改变对象状态但不返回任何内容的命令（Command），另一类是返回信息但不改变对象状态的查询（Query）。适用CQRS需要慎重考虑，对于只具有简单域的简单项目，其UI模型与域模型紧密联系的，使用CQRS会增加项目的复杂度和冗余度，无疑是过度设计。另外，对于数据量较少或者性能要求较低的项目实施CQRS模式不会带来显著的性能提升。 优点： 可扩展性：CQRS 允许独立扩展读写操作，这在读写负载差异较大的系统中尤其有用 灵活性：命令和查询是分开的，因此可以独立优化数据存储和检索策略 可维护性：通过分离关注点来简化代码库，使得命令和查询不会相互干扰 安全性：可以对读写操作应用不同的安全机制，确保只有授权用户才能进行更改 缺点： 复杂性：需要管理命令模型和查询模型之间的数据流 学习曲线：不熟悉 CQRS 的开发人员在采用该模式时可能会面临重新学习的问题 最终一致性：可能会导致最终的一致性，即查询模型可能无法立即反映命令所做的最新更改 ES(Event Sourcing) 设计模式: 提出者：并没有一个明确的“提出者”，因为它是一个逐渐发展起来的概念。 提出时间：Event Sourcing 的概念与实现随着领域驱动设计（Domain-Driven Design, DDD）的流行而得到更广泛的关注。 适用场合： 复杂业务逻辑：当应用程序的业务逻辑非常复杂，需要详细记录每个业务操作的历史时。 审计和合规性：需要能够追溯和审计业务操作的历史，以满足合规性要求。 分布式系统：在分布式系统中，事件 Sourcing 可以帮助保持不同服务之间的数据一致性 微服务架构：在微服务架构中，每个服务可以维护自己的事件日志，从而解耦服务并提高系统的可维护性。 缺点： 开发思维的转变：面向对象思维转变为基于事件的响应式编程思维 没有成熟完善的框架：没有一个大而一统的框架来实现 Event Sourcing 模式 事件结构的改变：业务的变化可能需要修改事件的结构，这可能会带来兼容性问题 领域模型角度设计系统：需要以领域模型为基础设计系统，而不是以数据库表为基础 架构组件 事件存储（Event Store）：事件被保存在一个不可变的、追加的、按时间顺序排列的存储库或数据存储中。 事件处理（Event Processor）：处理事件并更新系统状态。 事件消费者（Event Consumer）：消费事件并执行基于事件内容的逻辑 ES的实现： 事件存储：事件被保存在一个不可变的、追加的、按时间顺序排列的存储库或数据存储中。 事件重放：通过按时间顺序重放事件日志中的事件来重构应用程序的当前状态。 事件版本控制：随着服务的演变，事件的结构（模式）可以变化，需要实现事件版本控制策略以确保向后和向前兼容。 关联参考：Revo，EventStoreDB，Axon Framework，Lagom， Apache Kafka，PostgreSQL 整洁架构（Clean Architecture）： 提出者：Robert C. Martin（Uncle Bob） 提出时间：2012年 著作：《整洁架构之道》 特点：整合EBI（Entity-Boundary-Interacter，Robert C. Martin基于EIC提出）、六边形架构、洋葱架构成为一个可以实际落地的架构。与洋葱架构相比，整洁架构将Application Services调整为Use Cases， Domain Services, Domain Model调整为Entities。整洁架构并没有带来突破性的概念或模式，但是它带澄清了概念、规则和模式，并构建了复杂应用并保持可维护性的标准套路。整洁架构适用于需要长期维护和频繁更新的复杂项目，如腾讯文档、VS Code 内核、低代码引擎等。对于业务逻辑简单、业务生命周期较短的项目，直接使用整洁架构可能会导致开发效率降低 核心理念：围绕独立的对象模型构建应用，内层定义接口，外层实现接口。依赖的方向指向圆心。 菱形架构（Rhombic Symmetric Architecture）： 提出者：张逸 提出时间：2017年 著作：《解构领域驱动设计》 网站：http://zhangyi.xyz/rhombic-symmetric-architecture/ 核心理念：结合了六边形架构、分层架构、整洁架构的知识，并结合了领域驱动设计的元模型，使其能够更好地运用到限界上下文的架构设计中。 清晰架构（Explicit Architecture） 提出者：Herberto Graca 提出时间：2017年 著作：《软件架构编年史》 特点：清晰架构融合了领域驱动设计（DDD）、六边形架构、洋葱架构、整洁架构和CQRS等概念。它强调明确的职责和依赖关系，将系统划分为不同的职责区域，并明确它们之间的交互方式和依赖关系。这种架构有助于减少代码的耦合度，提高系统的可维护性和可扩展性，适用于对可维护性、可测试性和可扩展性有高度要求的复杂应用程序。 优点： 可维护性：分离核心业务逻辑与外部框架、数据库和 UI，修改测试各组件更容易。 模块化：分层使得代码库更易于维护和扩展。 独立性：业务逻辑与外部框架或库的独立性允许开发者替换或升级框架而不影响应用程序的核心功能。 测试覆盖率：鼓励编写隔离的单元测试，便于测试覆盖率和早期捕捉错误。 可扩展性：模块化设计简化了新功能的添加或现有功能的移除。 缺点： 过度工程：引入过多的复杂性，对于小型工程或原型项目不适用。 学习曲线：团队成员可能需要时间来理解和适应架构原则。 开发成本：清晰架构可能比传统方法需要更多的开发时间和工作量。 性能影响：通过接口和依赖注入实现松散耦合可能会引入轻微的性能影响。 灵活性：严格遵循架构原则有时可能限制灵活性和适应性。 领域驱动架构理论发展演进路径图：","categories":[],"tags":[]},{"title":"探究KISS原则","slug":"设计原则/探究KISS原则","date":"2024-11-06T02:34:35.950Z","updated":"2024-11-21T01:46:14.971Z","comments":true,"path":"2024/11/06/设计原则/探究KISS原则/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E6%8E%A2%E7%A9%B6KISS%E5%8E%9F%E5%88%99/","excerpt":"","text":"KISS 原则，即 “Keep It Simple and Stupid” 或 “Keep It Simple, Stupid”，翻译成中文就是：尽量保持简单，有时也被称作懒人法则，设计理念：简单就是美。 KISS原则的来源众说纷纭： 追溯到14世纪英格兰的逻辑学家奥卡姆的威廉提出的“奥卡姆剃刀原理”，即“如无必要，勿增实体”，强调简单有效‌。 美国海军飞行器工程师凯利·约翰逊（Kelly Johnson）。 David Mamet（大卫·马麦特）的电影理论。 Unix和C语言的发明者Dennis Ritchie（丹尼斯·里奇）在1969年将Unix的设计原则定为”保持简单和直接”（Keep it simple stupid），也即KISS原则。 KISS 原则在软件开发中主张在设计和实现过程中追求简单性，避免不必要的复杂性，以提高代码的可读性、可维护性和可扩展性，如少用复杂的算法、避免冗余和重复代码、遵循标准和惯例。 KISS原则的优点在于提高可读性和可维护性，提高开发效率，降低成本，但过度的简化又可能会限制创新，在实际应用中需要做好平衡。 什么是代码简单并不是代码行数越少就越“简单”，还要考虑逻辑复杂度、实现难度、代码的可读性等。 &#x2F;&#x2F; 第一种实现方式: 使用正则表达式public boolean isValidIpAddressV1(String ipAddress) { if (StringUtils.isBlank(ipAddress)) return false; String regex &#x3D; “^(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|[1-9])\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)$”; return ipAddress.matches(regex);}&#x2F;&#x2F; 第二种实现方式: 使用现成的工具类public boolean isValidIpAddressV2(String ipAddress) { if (StringUtils.isBlank(ipAddress)) return false; String[] ipUnits &#x3D; StringUtils.split(ipAddress, ‘.’); if (ipUnits.length !&#x3D; 4) { return false; } for (int i &#x3D; 0; i &lt; 4; ++i) { int ipUnitIntValue; try { ipUnitIntValue &#x3D; Integer.parseInt(ipUnits[i]); } catch (NumberFormatException e) { return false; } if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) { return false; } if (i &#x3D;&#x3D; 0 &amp;&amp; ipUnitIntValue &#x3D;&#x3D; 0) { return false; } } return true;}&#x2F;&#x2F; 第一种实现方式: 使用正则表达式public boolean isValidIpAddressV1(String ipAddress) { if (StringUtils.isBlank(ipAddress)) return false; String regex &#x3D; “^(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|[1-9])\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.” + “(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)$”; return ipAddress.matches(regex);}&#x2F;&#x2F; 第二种实现方式: 使用现成的工具类public boolean isValidIpAddressV2(String ipAddress) { if (StringUtils.isBlank(ipAddress)) return false; String[] ipUnits &#x3D; StringUtils.split(ipAddress, ‘.’); if (ipUnits.length !&#x3D; 4) { return false; } for (int i &#x3D; 0; i &lt; 4; ++i) { int ipUnitIntValue; try { ipUnitIntValue &#x3D; Integer.parseInt(ipUnits[i]); } catch (NumberFormatException e) { return false; } if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) { return false; } if (i &#x3D;&#x3D; 0 &amp;&amp; ipUnitIntValue &#x3D;&#x3D; 0) { return false; } } return true;}&#x2F;&#x2F; 第三种实现方式: 不使用任何工具类public boolean isValidIpAddressV3(String ipAddress) { char[] ipChars &#x3D; ipAddress.toCharArray(); int length &#x3D; ipChars.length; int ipUnitIntValue &#x3D; -1; boolean isFirstUnit &#x3D; true; int unitsCount &#x3D; 0; for (int i &#x3D; 0; i &lt; length; ++i) { char c &#x3D; ipChars[i]; if (c &#x3D;&#x3D; ‘.’) { if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) return false; if (isFirstUnit &amp;&amp; ipUnitIntValue &#x3D;&#x3D; 0) return false; if (isFirstUnit) isFirstUnit &#x3D; false; ipUnitIntValue &#x3D; -1; unitsCount++; continue; } if (c &lt; ‘0’ || c &gt; ‘9’) { return false; } if (ipUnitIntValue &#x3D;&#x3D; -1) ipUnitIntValue &#x3D; 0; ipUnitIntValue &#x3D; ipUnitIntValue * 10 + (c - ‘0’); } if (ipUnitIntValue &lt; 0 || ipUnitIntValue &gt; 255) return false; if (unitsCount !&#x3D; 3) return false; return true;} 上面这段检查输入的字符串 ipAddress 是否是合法的 IP 地址的代码，第一种实现方式利用的是正则表达式，第二种实现方式使用了 StringUtils 类、Integer 类提供的一些现成的工具函数，来处理 IP 地址字符串。第三种实现方式，不使用任何工具函数，而是通过逐一处理 IP 地址中的字符，来判断是否合法。 第一种方式不符合KISS原则，虽然代码行数最少，看似最简单，实际上却很复杂，因为它使用了正则表达式，复杂的正则表达式会导致代码的可读性和可维护性变差 第三种方式不符合KISS原则，第三种虽然和第二种代码行数了类似，但实现起来要比第二种更加有难度，更容易写出 bug，也就是逻辑复杂度较高 只有第二种方式使用了现成的工具类，代码逻辑不复杂，易读也易维护，满足KISS原子。但即使这样也需要看适配场景，如果本身问题比较复杂，那如果一段代码的逻辑复杂、实现难度大、可读性也不太好，但能解决这样复杂的问题，也满足KISS原则。例如用KMP算法解决字符串匹配问题，本身就复杂的问题，用复杂的方法解决，并不违背 KISS 原则 如何写出满足KISS的代码KISS原则其实本来就比较主观，不过还是有一些验证方式的： 不要使用同事可能不懂的技术来实现代码。比如前面例子中的正则表达式，还有一些编程语言中过于高级的语法等。如果想用，培训一下大家。 不要重复造轮子，要善于使用已经有的工具类库。经验证明，自己去实现这些类库，出 bug 的概率会更高，维护的成本也比较高。 不要过度优化。不要过度使用一些奇技淫巧（比如，位运算代替算术运算、复杂的条件语句代替 if-else、使用一些过于底层的函数等）来优化代码，牺牲代码的可读性。","categories":[],"tags":[]},{"title":"设计模式之六大设计原则（SOLID原则）","slug":"设计原则/设计模式之六大设计原则（SOLID原则）","date":"2024-11-06T01:38:49.403Z","updated":"2024-11-21T01:47:23.763Z","comments":true,"path":"2024/11/06/设计原则/设计模式之六大设计原则（SOLID原则）/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%85%AD%E5%A4%A7%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99%EF%BC%88SOLID%E5%8E%9F%E5%88%99%EF%BC%89/","excerpt":"","text":"为什么会有六大原则面向过程编程到面向对象编程是软件设计的一大步，封装、继承、多态是面向对象的三大特征，本来这些都是面向对象的好处，但是一旦有人滥用了，就有了坏味道，代码的坏味道导致系统的可维护性和复用性等变低，所以面向对象需要遵循一些原则make the code better。如：一个servlet干所有事情可以改为MVC，每一层的类做自己负责的事情，遵循单一职责原则。 为了提高系统的可维护性、复用性和高内聚低耦合等， 2000 年Robert C. Martin（也被称为 Uncle Bob）在他的论文《设计原则和设计模式》中首次提出了SOLID 原则（注：SOLID 这个缩写是后来由 Michael Feathers 概括确定的）。因为设计模式是面向对象实践出来的经验，所以这六大原则既是面向对象的六大原则，也是设计模式的六大原则。 六大设计原则主要是指： 单一职责原则（Single Responsibility Principle）； 开闭原则（Open Closed Principle）； 里氏替换原则（Liskov Substitution Principle）； 迪米特法则（Law of Demeter），又叫“最少知道法则”； 接口隔离原则（Interface Segregation Principle）； 依赖倒置原则（Dependence Inversion Principle）。 把这 6 个原则的首字母（里氏替换原则和迪米特法则的首字母重复，只取一个）联合起来就是：SOLID（稳定的），其代表的含义也就是把这 6 个原则结合使用的好处：建立稳定、灵活、健壮的设计。 单一职责原则单一职责原则的定义是：应该有且仅有一个原因引起类的变更。 没错，单一职责原则就这一句话，不懂没关系，我们举个例子。 我们以打电话为例，电话通话的时候有 4 个过程发生：拨号、通话、回应、挂机。那我们写一个接口，类图如下： 代码为： 我们看这个接口有没有问题？相信大部分同学会觉得没问题，因为平常我们就是这么写的。没错，这个接口接近于完美，注意，是“接近”。单一职责原则要求一个接口或一个类只能有一个原因引起变化，也就是一个接口或者类只能有一个职责，它就负责一件事情，看看上面的接口只负责一件事情吗？明显不是。 IPhone这个接口包含了两个职责：协议管理和数据传送。dial 和 hangup 这两个方法实现的是协议管理，分别负责拨号接通和挂机，chat 方法实现的是数据传送。不管是协议接通的变化还是输出传送的变化，都会引起这个接口的变化。所以，IPhone这个接口并不符合单一职责原则。若要让IPhone满足单一职责原则，我们就要对其进行拆分，拆分后的类图如下： 这样设计就完美了，一个类实现了两个接口，把两个职责融合在一个类中。你会觉得这个Phone有两个原因引起变化了啊，是的，但是别忘了我们是面向接口编程，我们对外公布的是接口而不是实现类。 另外，单一职责原则不仅适用于接口和类，也适用于方法。一个方法尽可能只做一件事，比如一个修改用户密码的方法，不要把这个方法放到“修改用户信息”方法中。 单一职责的好处 类的复杂性降低，实现什么职责都有清晰明确的定义； 可读性高，复杂性降低，可读性自然就提高了； 可维护性提高，可读性提高了，那自然更容易维护了； 变更引起的风险降低，变更是必不可少的，如果接口的单一职责做得好，一个接口修改只对相应的实现类有影响，对其他的接口无影响，这对系统的扩展性、维护性都有非常大的帮助。 里氏替换原则在面向对象的语言中，继承是必不可少的、非常优秀的语言机制，它有如下优点： 代码共享，减少创建类的工作量，每个子类都拥有父类的属性和方法； 提高代码的重用性； 子类可以形似父类，但又异于父类； 提高代码的可扩展性； 提高产品或项目的开放性。 有优点就必然存在缺点： 继承是侵入性的。只要继承，就必须拥有父类的属性和方法。 降低代码的灵活性。子类会多一些父类的约束。 增强了耦合性。当父类的常量、变量、方法被修改时，需要考虑子类的修改。 为了让“利”的因素发挥最大的作用，同时减少“弊”带来的麻烦，引入了里氏替换原则（LSP）。 历史替换原则最正宗的定义是：如果对每一个类型为S的对象o1，都有类型为T的对象o2，使得以T定义的所有程序P在所有的对象o1都代替o2时，程序P的行为没有发生变化，那么类型S是类型T的子类型。 通俗点讲，就是只要父类能出现的地方，子类就可以出现，而且替换为子类也不会产生任何错误或异常。 里氏替换原则为良好的继承定义了一个规范，一句简单的定义包含了4层含义。 1. 子类必须完全实现父类的方法。 我们在做系统设计的时候，经常会定义一个接口或抽象类，然后编码实现，调用类则直接传入接口或抽象类，其实这里就已经使用了里氏替换原则。我们以打CS举例，来描述一下里面用到的枪。类图如下： 枪的主要职责是射击，如何射击在各个具体的子类中实现，在士兵类Soldier中定义了一个方法 killEnemy，使用枪来kill敌人，具体用什么枪，调用的时候才知道。 AbstractGun类源码如下： 手枪、步枪、机枪的实现类代码如下： 士兵类的源码为： 注意，士兵类的killEnemy方法中使用的gun是抽象的，具体时间什么枪需要由客户端（Client）调用Soldier的构造方法传参确定。 客户端Client源码如下： 注意：在类中调用其他类时务必要使用父类或接口，如果不能使用父类或接口，则说明类的设计已经违背了LSP原则。 2. 孩子类可以有自己的个性。 孩子类当然可以有自己的属性和方法了，也正因如此，在子类出现的地方，父类未必就可以代替。 还是以上面的关于枪支的例子为例，步枪有 AK47、SKS狙击步枪等型号，把这两个型号的枪引入后的Rifle的子类图如下： SKS狙击步枪可以配一个8倍镜进行远程瞄准，相对于父类步枪，这就是SKS的个性。源码如下： 狙击手Spinner类的源码如下： 狙击手因为只能使用狙击枪，所以，狙击手类中持有的枪只能是狙击类型的，如果换成父类步枪Rifle，则传递进来的可能就不是狙击枪，而是AK47了，而AK47是没有zoomOut方法的，所以肯定是不行的。这也验证了里氏替换原则的那一句话：有子类出现的地方，父类未必就可以代替。 3. 覆盖或实现父类的方法时，输入参数可以被放大。 来看一个例子，我们先定义一个Father类： 然后定义一个子类： 子类方法与父类方法同名，但又不是覆写父类的方法。你加个@Override看看，会报错的。像这种方法名相同，方法参数不同，叫做方法的重载。你可能会有疑问：重载不是只能在当前类内部重载吗？因为Son继承了Father，Son就有了Father的所有属性和方法，自然就有了Father的doSomething这个方法，所以，这里就构成了重载。 接下来看场景类： 根据里氏替换原则，父类出现的地方子类就可以出现，我们把上面的父类替换为子类： 我们发现运行结果是一样的。为什么会这样呢？因为子类Son继承了Father，就拥有了doSomething(HashMap map)这个方法，不过由于Son没有重写这个方法，当调用Son的这个方法的时候，就会自动调用其父类的这个方法。所以两次的结果是一致的。 举个反例，如果父类的输入参数类型大于子类的输入参数类型，会出现什么问题呢？我们直接看代码执行结果即可轻松看出问题： 扩大父类方法入参： 缩小子类方法入参： 场景类： 根据里氏替换原则，有父类的地方就可以有子类，我们把Father替换为Son看看结果： 两次运行结果不一致，违反了里氏替换原则，所以子类中方法的入参类型必须与父类中被覆写的方法的入参类型相同或更宽松。 4. 覆盖或实现父类的方法时，输出结果可以被缩小。 这句话的意思就是，父类的一个方法的返回值是类型T，子类的相同方法（重载或重写）的返回值为类型S，那么里氏替换原则就要求S必须小于等于T。为什么呢？因为重写父类方法，父类和子类的同名方法的输入参数是相同的，两个方法的范围值S小于等于T，这时重写父类方法的要求。 依赖倒置原则依赖倒置原则在Java语言中的表现是： 模块间的依赖通过抽象发生，实现类之间不直接发生依赖关系，其依赖关系是通过接口或抽象类产生的； 接口或抽象类不依赖于实现类； 实现类依赖接口或抽象类。 说白了，就是“面向接口编程”。 依赖倒置原则可以减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。 我们以汽车和司机举例，画出类图： 奔驰车源代码： 司机源代码： 客户端源代码： 通过以上的代码，完成了司机开动奔驰车的场景。可以看到，这个场景并没有引用依赖倒置原则，司机Driver类直接依赖奔驰车Benz类，这样会有什么隐患呢？试想，后期业务变动，司机又买了一辆宝马车，源代码如下： 由于司机现在只有开奔驰的方法，所以他是开不了宝马的。一个拿有C驾照的司机能开奔驰，不能开宝马？太不合理了。所以，这就暴露出上面的设计问题了。我们对上面的功能重新设计，首先新建两个接口。 汽车接口ICar： 司机接口IDriver： IDriver中，通过传入ICar接口实现了抽象之间的依赖关系。 接下来创建汽车实现类：奔驰和宝马。 然后创建司机实现类： 最后是场景类调用： Client属于高层业务逻辑，它对低层模块的依赖都建立在抽象上，driver的表面类型是IDriver，benz的表面类型是ICar。 依赖倒置原则的使用建议： （1）每个类尽量都有接口或抽象类，或者接口和抽象类两者都具备。 （2）变量的表面类型尽量是接口或抽象类。 （3）任何类都不应该从具体类派生。 （4）尽量不要重写基类的方法。如果基类是一个抽象类，而且这个方法已经实现了，子类尽量不要重写。 （5）结合里氏替换原则使用。 接口隔离原则接口隔离原则就是客户端不应该依赖它不需要的接口，或者说类间的依赖关系应该建立在最小的接口上。 我们以搜索美女为例，设计了如下的类图： 源代码如下。美女及其实现类： 搜索程序及其子类源代码如下： 最后是场景调用类： 上面实现了一个搜索美女的小程序。我们想象这个程序有没有问题？IPettyGirl接口是否做到了最优化？并没有。 每个人的审美观不一样，张三认为颜值高就是美女，即使身材和气质一般；李四认为身材好就行，不在乎颜值和气质；而王五则认为颜值和身材都是外在，只要有气质，那就是美女。这时，IPettyGirl接口就满足不了了，因为IPettyGirl的要求是颜值、身材、气质兼具才是美女。所以为了满足各种人的口味，我们需要重新设计接口的结构。把IPettyGirl拆分为3个接口，分别表示颜值高、身材好、气质佳。修改后的类图如下： 源代码如下。美女及其实现类： 搜索类及其子类如下： 通过重构以后，不管以后需要颜值美女，还是需要身材美女，抑或气质美女，都可以保持接口的稳定性。 以上把一个臃肿的接口拆分为三个独立的接口所依赖的原则就是接口隔离原则。接口隔离原则是对接口进行规范约束。 迪米特法则迪米特法则（LoD）也叫最少知道法则：一个对象应该对其他对象有最少的了解。 1.只和朋友交流 迪米特法则还有一个英文解释是：Only talk to your immediate friends(只和直接的朋友交流)。每个对象都必然会与其他对象耦合，两个对象的耦合就成为朋友关系。下面我们通过体育课老师让班长清点女生人数为例讲解。 首先设计程序的类图： 编码实现： 场景类： 程序开发完了，我们首先看下Teacher类有几个朋友类，首先要知道朋友类的定义：出现在成员变量、方法的输入输出参数中的类称为成员朋友类。所以Teacher类只有一个GroupLeader朋友类。根据迪米特法则，一个类只能和朋友类交流，上面的Teacher类内部却与非朋友类Girl发生了交流，这就不符合迪米特法则，破坏了程序的健壮性。 我们对类图做下修改： 修改后的代码： 再看场景类调用： 总之，就是类与类之间的关系是建立在类间的，而不是方法间，因此一个方法尽量不引入一个类中不存在的对象。 2.朋友间也是有距离的 我们在开发中经常有这种场景：调用一个或多个类，先执行第一个方法，然后是第二个方法，根据返回结果再看是否执行第三个方法。我们以安装某个软件为例，其类图为： 代码如下： 场景类： 程序很简单，但也存在一些问题：Wizard类把太多方法暴露给InstallSoftware类了，两者的朋友关系太亲密了，耦合关系变的异常牢固，如果要把Wizard中first方法的返回值改为Boolean类型，则要同时修改InstallSoftware类，增加了风险。因此，这种耦合是不合适的，我们需要对其优化。重构后的类图如下： 代码如下。导向类： 我们把安装步骤改为私有方法，只向外暴露一个安装方法，这样，即使修改步骤的逻辑，也只是对Wizard自己有影响，只需要修改自己的安装方法逻辑即可，其他类不会受到影响。 安装类： 一个类公开的public属性或方法越多，修改时涉及的面也就越大，变更引起的风险扩散也就越大。所以，我们开发中尽量不要对外公布太多public方法和非静态的public变量，尽量内敛。 3.是自己的就是自己的 在实际开发中经常会出现这样一种情况：一个方法放在吧本类中也可以，放在其他类中也没有错。那这时，我们只需要坚持一个原则：如果一个方法放在本类中，既不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 总之，迪米特法则的核心观念就是类间解耦，弱耦合，只有弱耦合了以后，类的复用率才可以提升上去。 开闭原则开闭原则是指一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。也就是说一个软件实体应该通过扩展来实现变化，而不是通过修改已有的代码来实现变化。我们以书店销售书籍为例来说明什么是开闭原则。 其类图如下： 书籍及其实现类代码如下： 书店类代码： 项目开发完了，开始正常卖书了。假如到了双十一，要搞打折活动，上面的功能是不支持的，所以需要修改程序。有三种方法可以解决这个问题： （1）修改接口 在IBook接口里新增getOffPrice()方法，专门用于进行打折，所有的实现类都实现该方法。但这样修改的后果就是，实现类NovelBook要修改，书店类BookStore中的main方法也要修改，同时，IBook作为接口应该是稳定且可靠的，不应该经常发生变化，因此，该方案被否定。 （2）修改实现类 修改NovelBook类中的方法，直接在getPrice()方法中实现打折处理，这个方法可以是可以，但如果采购书籍的人员要看价格怎么办，由于该方法已经进行了打折处理，因此采购人员看到的也是打折后的价格，会因信息不对称出现决策失误的情况。因此，该方案也不是一个最优的方案。 （3）通过扩展实现变化 增加一个子类OffNovelBook，覆写getPrice方法，高层次的模块（也就是BookStore中static静态块中）通过OffNovelBook类产生新的对象，完成业务变化对系统的最小开发。这样修改也少，风险也小，修改后的类图如下： OffNovelBook源码如下： 然后修改BookStore中的书籍类为OffNovelBook： 为什么要用开闭原则 开闭原则非常著名，只要是做面向对象编程的，在开发时都会提及开闭原则。 开闭原则是最基础的一个原则，前面介绍的5个原则都是开闭原则的具体形态，而开闭原则才是其精神领袖。 开闭原则提高了复用性，以及可维护性。 总结六大设计原则 单一职责原则：一个类或接口只承担一个职责。 里氏替换原则：在继承类时，务必重写（override）父类中所有的方法，尤其需要注意父类的protected方法（它们往往是让你重写的），子类尽量不要暴露自己的public方法供外界调用。 依赖倒置原则：高层模块不应该依赖于低层模块，而应该依赖于抽象。抽象不应依赖于细节，细节应依赖于抽象。 接口隔离原则：不要对外暴露没有实际意义的接口。 迪米特法则：尽量减少对象之间的交互，从而减小类之间的耦合。 开闭原则：对软件实体的改动，最好用扩展而非修改的方式。 结语六大设计原则虽好，但要熟练掌握和应用他们还是不那么容易的，需要在熟记于心的同时在编码工作中不断的实践和积累经验。","categories":[],"tags":[]},{"title":"探究DRY、YANGI、三次法则","slug":"设计原则/探究DRY、YANGI、三次法则","date":"2024-11-06T01:19:05.933Z","updated":"2024-11-21T01:46:47.976Z","comments":true,"path":"2024/11/06/设计原则/探究DRY、YANGI、三次法则/","permalink":"https://andy-whb-cn.github.io/2024/11/06/%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99/%E6%8E%A2%E7%A9%B6DRY%E3%80%81YANGI%E3%80%81%E4%B8%89%E6%AC%A1%E6%B3%95%E5%88%99/","excerpt":"","text":"在日常开发工作中，我们常常会遇到一些使得代码变得冗余、复杂甚至难以维护的情况。为了应对这些问题，软件工程界提出了许多原则和方法来指导我们的编程实践。 其中，DRY原则、YAGNI原则和三次法则是我们编程过程中常常需要用到的三个重要原则。那么，这些原则具体是什么含义，又应该如何在实际开发中运用呢？下面就让我们一起来探讨。 DRY原则：追求高效，摒弃重复软件工程名著《The Pragmatic Programmer | 程序员修炼之道:从小工到专家》首先提出这一原则。 DRY，全称”Don’t Repeat Yourself”，翻译为中文就是”不要重复自己”，这个原则有时也称作“一次且仅一次“原则（Once and Only Once)。这是一种追求高效、优雅的编程原则。根据DRY原则，任何形式的信息重复都应当被消除。在实际的编程中，如果同一个逻辑出现在两个或更多的地方，那么我们就需要考虑将这部分逻辑抽象出来，避免重复代码。 DRY原则的优点在于，它能提高代码的可读性和可维护性，降低代码的复杂度，从而提高整个软件的质量。比如，当我们需要修改某一逻辑时，只需要在一个地方修改即可，无需在多个地方做同样的修改，大大提高了代码的维护性。 YAGNI原则：聚焦现在，摒弃过度设计这是“极限编程”提倡的原则, 指导思想，就是尽可能快、尽可能简单地让软件运行起来（do the simplest thing that could possibly work）。 YAGNI，全称”You Aren’t Gonna Need It”，翻译为中文就是”你不会需要它”。这个原则鼓励我们抵制过度设计的诱惑，只关注当前真正需要的功能，而不是那些”可能”在未来会用到的功能。 在软件开发过程中，我们常常会受到”可能会用到”这种假设的诱惑，这导致我们花费大量的时间和精力去实现那些实际上并不需要的功能，而这些功能反而增加了代码的复杂度，降低了软件的可维护性。因此，YAGNI原则告诉我们，除非确定需要某个功能，否则就不要去实现它。 DRY原则和YAGNI原则并非完全兼容。前者追求”抽象化”，要求找到通用的解决方法；后者追求”快和省”，意味着不要把精力放在抽象化上面，因为很可能”你不会需要它”。于是就有了第三个原则”三次法则“。 三次法则：提炼抽象，追求优雅Rule of three 称为”三次原则”，指的是当某个功能第三次出现时，才进行”抽象化”。这是软件开发大家Martin Fowler在《Refactoring | 重构》一书中提出的。 三次法则，是一种关于何时应该重构或抽象代码的原则。它告诉我们，如果你做了一次相同的事情，那就继续；如果你做了两次相同的事情，那就稍微有点耐心；如果你做了三次相同的事情，那么你应该重构或抽象它。 实际上，这个法则是DRY原则的一个具体实践。当我们在代码中发现重复的逻辑时，可能是时候考虑进行抽象了。这样，当我们需要修改这部分逻辑时，只需要在一个地方进行修改即可，而不需要在多个地方进行相同的修改。 结语软件开发是一项复杂的工作，需要我们不断学习和实践。DRY原则、YAGNI原则和三次法则，都是我们在编程实践中需要掌握的重要原则。通过运用这些原则，我们可以写出更高质量的代码，构建出更优秀的软件。","categories":[],"tags":[]},{"title":"常用软件清单","slug":"推荐/常用软件清单","date":"2024-09-03T06:11:58.004Z","updated":"2024-09-03T06:31:27.693Z","comments":true,"path":"2024/09/03/推荐/常用软件清单/","permalink":"https://andy-whb-cn.github.io/2024/09/03/%E6%8E%A8%E8%8D%90/%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%B8%85%E5%8D%95/","excerpt":"","text":"软件名称 下载地址 用途 winscp https://winscp.net/eng/index.php scp远程连接上传下载文件 Another-Redis-Desktop-Manager https://goanother.com/cn/#download Redis客户端工具 NoSQLBooster for MongoDB https://www.nosqlbooster.com/ MongoDB客户端","categories":[],"tags":[]},{"title":"SOA架构vs微服务架构","slug":"架构设计/SOA架构 vs 微服务架构","date":"2024-09-03T01:30:00.000Z","updated":"2024-09-03T02:29:16.772Z","comments":true,"path":"2024/09/03/架构设计/SOA架构 vs 微服务架构/","permalink":"https://andy-whb-cn.github.io/2024/09/03/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/SOA%E6%9E%B6%E6%9E%84%20vs%20%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/","excerpt":"","text":"SOA架构和微服务架构最主要的区别：面向的范围不同。SOA架构主要面向企业级服务，微服务架构主要面向应用级服务典型的微服务架构：基础原则： 服务自治：每个服务都拥有独立的数据库和功能，可以独立开发和部署。 去中心化的数据管理：强调服务的数据自主性，减少数据耦合，解决在单体应用中可能出现的数据一致性问题。 技术的异质性：每个服务可以选择最适合的技术栈开发，提升效率和创新。挑战： 分布式服务的复杂性：服务发现、负载均衡、网络延迟、调试和测试。 跨服务数据一致性问题：每个服务都有自己的数据库，数据的完整性和一致性变得复杂，分布式事务比较麻烦且有潜在的性能影响。 业务处理的复杂性：依赖于微服务的良好设计和实现。 监控的必要性：依赖于监控解决方案发现性能瓶颈、错误、异常。 典型的SOA架构： SOA架构可以认为是一种强调模块化和互用性的基础方法。SOA架构图描绘的是互相连接的组件组成系统的结构： Servcie: 完成特定业务功能的服务 Service Repository: 中心化的服务目录，便于服务发现和使用 FrontEnd: 用户接口层，通过契约(Contracts)和服务交互 Service Bus: 用于服务间通讯，建立消息交换。 Contract: 定义服务的交互契约，促使松耦合 Interface: 对外暴露服务功能基本原则： 复用性：模块化的服务，并且可以被多个应用复用。 可发现性：服务注册。 可组合性：可以支持任意方法进行服务的组合。 松耦合：服务之间互相独立，通过标准接口进行通信。挑战： 服务的版本和兼容性 数据的完整性和一致性 业务处理的复杂性 其他差异：SOA 与微服务 SOA 微服务 实施 共享资源的不同服务。 独立且针对特定用途的小型服务。 交流 ESB 使用多种消息协议，例如 SOAP、AMQP 和 MSMQ。 API、Java 消息服务、发布&#x2F;订阅 数据存储 共享数据存储。 独立的数据存储。 部署 具有挑战性。细微更改也需要全面重构。 易于部署。每个微服务都可以容器化。 可重用性 通过共享公共资源提供可重复使用的服务。 每项服务都有自己的独立资源。您可以通过微服务的 API 重复使用微服务。 速度 速度会随着服务增多而减慢。 可在流量增长时保持稳定的速度。 治理灵活性 跨所有服务进行一致的数据治理。 针对每种存储采用不同的数据治理策略。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"SpringBoot 扩展点","slug":"SpringBoot/SpringBoot：扩展点","date":"2024-09-02T11:02:01.624Z","updated":"2024-09-03T02:34:56.218Z","comments":true,"path":"2024/09/02/SpringBoot/SpringBoot：扩展点/","permalink":"https://andy-whb-cn.github.io/2024/09/02/SpringBoot/SpringBoot%EF%BC%9A%E6%89%A9%E5%B1%95%E7%82%B9/","excerpt":"","text":"背景Spring的核心思想就是容器，当容器refresh的时候，外部看上去风平浪静，其实内部则是一片惊涛骇浪，汪洋一片。Springboot更是封装了Spring，遵循约定大于配置，加上自动装配的机制。很多时候我们只要引用了一个依赖，几乎是零配置就能完成一个功能的装配。 我非常喜欢这种自动装配的机制，所以在自己开发中间件和公共依赖工具的时候也会用到这个特性。让使用者以最小的代价接入。想要把自动装配玩的转，就必须要了解spring对于bean的构造生命周期以及各个扩展接口。当然了解了bean的各个生命周期也能促进我们加深对spring的理解。业务代码也能合理利用这些扩展点写出更加漂亮的代码。 在网上搜索Spring扩展点，发现很少有博文说的很全的，只有一些常用的扩展点的说明。 所以在这篇文章里，我总结了几乎Spring &amp; Springboot所有的扩展接口，以及各个扩展点的使用场景。并且整理出了一个bean在spring内部从被加载到最后初始化完成所有可扩展点的顺序调用图。从而我们也能窥探到bean是如何一步步加载到spring容器中的。 可扩展的接口启动调用顺序图以下是我整理的spring容器中Bean的生命周期内所有可扩展的点的调用顺序，下面会一个个分析 1. ApplicationContextInitializer org.springframework.context.ApplicationContextInitializer 这是整个spring容器在刷新之前初始化ConfigurableApplicationContext的回调接口，简单来说，就是在容器刷新之前调用此类的initialize方法。这个点允许被用户自己扩展。用户可以在整个spring容器还没被初始化之前做一些事情。 可以想到的场景可能为，在最开始激活一些配置，或者利用这时候class还没被类加载器加载的时机，进行动态字节码注入等操作。 1public class TestApplicationContextInitializer implements ApplicationContextInitializer &#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; System.out.println(&quot;[ApplicationContextInitializer]&quot;); &#125; &#125; 因为这时候spring容器还没被初始化，所以想要自己的扩展的生效，有以下三种方式： 在启动类中用springApplication.addInitializers(new TestApplicationContextInitializer())语句加入 配置文件配置context.initializer.classes=com.example.demo.TestApplicationContextInitializer Spring SPI扩展，在spring.factories中加入org.springframework.context.ApplicationContextInitializer=com.example.demo.TestApplicationContextInitializer 2. BeanDefinitionRegistryPostProcessor org.springframework.beans.factory.support.BeanDefinitionRegistryPostProcessor 这个接口在读取项目中的beanDefinition之后执行，提供一个补充的扩展点。 使用场景：你可以在这里动态注册自己的beanDefinition，可以加载classpath之外的bean 扩展方式为: 1public class TestBeanDefinitionRegistryPostProcessor implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; System.out.println(&quot;[BeanDefinitionRegistryPostProcessor] postProcessBeanDefinitionRegistry&quot;); &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;[BeanDefinitionRegistryPostProcessor] postProcessBeanFactory&quot;); &#125; &#125; 3. BeanFactoryPostProcessor org.springframework.beans.factory.config.BeanFactoryPostProcessor 这个接口是beanFactory的扩展接口，调用时机在spring在读取beanDefinition信息之后，实例化bean之前。 在这个时机，用户可以通过实现这个扩展接口来自行处理一些东西，比如修改已经注册的beanDefinition的元信息。 扩展方式为： 1public class TestBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;[BeanFactoryPostProcessor]&quot;); &#125; &#125; 4. InstantiationAwareBeanPostProcessor org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessor 该接口继承了BeanPostProcess接口，区别如下： BeanPostProcess接口只在bean的初始化阶段进行扩展（注入spring上下文前后），而InstantiationAwareBeanPostProcessor接口在此基础上增加了3个方法，把可扩展的范围增加了实例化阶段和属性注入阶段。 该类主要的扩展点有以下5个方法，主要在bean生命周期的两大阶段：实例化阶段 和初始化阶段 ，下面一起进行说明，按调用顺序为： postProcessBeforeInstantiation：实例化bean之前，相当于new这个bean之前 postProcessAfterInstantiation：实例化bean之后，相当于new这个bean之后 postProcessPropertyValues：bean已经实例化完成，在属性注入时阶段触发，@Autowired,@Resource等注解原理基于此方法实现 postProcessBeforeInitialization：初始化bean之前，相当于把bean注入spring上下文之前 postProcessAfterInitialization：初始化bean之后，相当于把bean注入spring上下文之后 使用场景：这个扩展点非常有用 ，无论是写中间件和业务中，都能利用这个特性。比如对实现了某一类接口的bean在各个生命期间进行收集，或者对某个类型的bean进行统一的设值等等。 扩展方式为： 1public class TestInstantiationAwareBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;[TestInstantiationAwareBeanPostProcessor] before initialization &quot; + beanName); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;[TestInstantiationAwareBeanPostProcessor] after initialization &quot; + beanName); return bean; &#125; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;[TestInstantiationAwareBeanPostProcessor] before instantiation &quot; + beanName); return null; &#125; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;[TestInstantiationAwareBeanPostProcessor] after instantiation &quot; + beanName); return true; &#125; @Override public PropertyValues postProcessPropertyValues(PropertyValues pvs, PropertyDescriptor[] pds, Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;[TestInstantiationAwareBeanPostProcessor] postProcessPropertyValues &quot; + beanName); return pvs; &#125; 5. SmartInstantiationAwareBeanPostProcessor org.springframework.beans.factory.config.SmartInstantiationAwareBeanPostProcessor 该扩展接口有3个触发点方法： predictBeanType： 该触发点发生在postProcessBeforeInstantiation之前(在图上并没有标明，因为一般不太需要扩展这个点)，这个方法用于预测Bean的类型，返回第一个预测成功的Class类型，如果不能预测返回null；当你调用BeanFactory.getType(name)时当通过bean的名字无法得到bean类型信息时就调用该回调方法来决定类型信息。 determineCandidateConstructors： 该触发点发生在postProcessBeforeInstantiation之后，用于确定该bean的构造函数之用，返回的是该bean的所有构造函数列表。用户可以扩展这个点，来自定义选择相应的构造器来实例化这个bean。 getEarlyBeanReference： 该触发点发生在postProcessAfterInstantiation之后，当有循环依赖的场景，当bean实例化好之后，为了防止有循环依赖，会提前暴露回调方法，用于bean实例化的后置处理。这个方法就是在提前暴露的回调方法中触发。 扩展方式为： 1public class TestSmartInstantiationAwareBeanPostProcessor implements SmartInstantiationAwareBeanPostProcessor &#123; @Override public Class&lt;?&gt; predictBeanType(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;[TestSmartInstantiationAwareBeanPostProcessor] predictBeanType &quot; + beanName); return beanClass; &#125; @Override public Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;[TestSmartInstantiationAwareBeanPostProcessor] determineCandidateConstructors &quot; + beanName); return null; &#125; @Override public Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;[TestSmartInstantiationAwareBeanPostProcessor] getEarlyBeanReference &quot; + beanName); return bean; &#125; &#125; 6. BeanFactoryAware org.springframework.beans.factory.BeanFactoryAware 这个类只有一个触发点，发生在bean的实例化之后，注入属性之前，也就是Setter之前。这个类的扩展点方法为setBeanFactory，可以拿到BeanFactory这个属性。 使用场景为，你可以在bean实例化之后，但还未初始化之前，拿到 BeanFactory，在这个时候，可以对每个bean作特殊化的定制。也或者可以把BeanFactory拿到进行缓存，日后使用。 扩展方式为： 1public class TestBeanFactoryAware implements BeanFactoryAware &#123; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;[TestBeanFactoryAware] &quot; + beanFactory.getBean(TestBeanFactoryAware.class).getClass().getSimpleName()); &#125; &#125; 7. ApplicationContextAwareProcessor org.springframework.context.support.ApplicationContextAwareProcessor 该类本身并没有扩展点，但是该类内部却有6个扩展点可供实现 ，这些类触发的时机在bean实例化之后，初始化之前 可以看到，该类用于执行各种驱动接口，在bean实例化之后，属性填充之后，通过执行以上红框标出的扩展接口，来获取对应容器的变量。所以这里应该来说是有6个扩展点 ，这里就放一起来说了 EnvironmentAware： 用于获取EnviromentAware的一个扩展类，这个变量非常有用， 可以获得系统内的所有参数。当然个人认为这个Aware没必要去扩展，因为spring内部都可以通过注入的方式来直接获得。 EmbeddedValueResolverAware： 用于获取StringValueResolver的一个扩展类， StringValueResolver用于获取基于String类型的properties的变量，一般我们都用@Value的方式去获取，如果实现了这个Aware接口，把StringValueResolver缓存起来，通过这个类去获取String类型的变量，效果是一样的。 ResourceLoaderAware： 用于获取ResourceLoader的一个扩展类，ResourceLoader可以用于获取classpath内所有的资源对象，可以扩展此类来拿到ResourceLoader对象。 ApplicationEventPublisherAware： 用于获取ApplicationEventPublisher的一个扩展类，ApplicationEventPublisher可以用来发布事件，结合ApplicationListener来共同使用，下文在介绍ApplicationListener时会详细提到。这个对象也可以通过spring注入的方式来获得。 MessageSourceAware： 用于获取MessageSource的一个扩展类，MessageSource主要用来做国际化。 ApplicationContextAware： 用来获取ApplicationContext的一个扩展类，ApplicationContext应该是很多人非常熟悉的一个类了，就是spring上下文管理器，可以手动的获取任何在spring上下文注册的bean，我们经常扩展这个接口来缓存spring上下文，包装成静态方法。同时ApplicationContext也实现了BeanFactory，MessageSource，ApplicationEventPublisher等接口，也可以用来做相关接口的事情。 8. BeanNameAware org.springframework.beans.factory.BeanNameAware 可以看到，这个类也是Aware扩展的一种，触发点在bean的初始化之前，也就是postProcessBeforeInitialization之前，这个类的触发点方法只有一个：setBeanName 使用场景为：用户可以扩展这个点，在初始化bean之前拿到spring容器中注册的的beanName，来自行修改这个beanName的值。 扩展方式为： 1public class NormalBeanA implements BeanNameAware&#123; public NormalBeanA() &#123; System.out.println(&quot;NormalBean constructor&quot;); &#125; @Override public void setBeanName(String name) &#123; System.out.println(&quot;[BeanNameAware] &quot; + name); &#125; &#125; 9. @PostConstruct javax.annotation.PostConstruct 这个并不算一个扩展点，其实就是一个标注。其作用是在bean的初始化阶段，如果对一个方法标注了@PostConstruct，会先调用这个方法。这里重点是要关注下这个标准的触发点，这个触发点是在postProcessBeforeInitialization之后，InitializingBean.afterPropertiesSet之前。 使用场景：用户可以对某一方法进行标注，来进行初始化某一个属性 扩展方式为： 1public class NormalBeanA &#123; public NormalBeanA() &#123; System.out.println(&quot;NormalBean constructor&quot;); &#125; @PostConstruct public void init()&#123; System.out.println(&quot;[PostConstruct] NormalBeanA&quot;); &#125; &#125; 10. InitializingBean org.springframework.beans.factory.InitializingBean 这个类，顾名思义，也是用来初始化bean的。InitializingBean接口为bean提供了初始化方法的方式，它只包括afterPropertiesSet方法，凡是继承该接口的类，在初始化bean的时候都会执行该方法。这个扩展点的触发时机在postProcessAfterInitialization之前。 使用场景：用户实现此接口，来进行系统启动的时候一些业务指标的初始化工作。 扩展方式为： 1public class NormalBeanA implements InitializingBean&#123; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println(&quot;[InitializingBean] NormalBeanA&quot;); &#125; &#125; 11. FactoryBean org.springframework.beans.factory.FactoryBean 一般情况下，Spring通过反射机制利用bean的class属性指定支线类去实例化bean，在某些情况下，实例化Bean过程比较复杂，如果按照传统的方式，则需要在bean中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个org.springframework.bean.factory.FactoryBean的工厂类接口，用户可以通过实现该接口定制实例化Bean的逻辑。FactoryBean接口对于Spring框架来说占用重要的地位，Spring自身就提供了70多个FactoryBean的实现。它们隐藏了实例化一些复杂bean的细节，给上层应用带来了便利。从Spring3.0开始，FactoryBean开始支持泛型，即接口声明改为FactoryBean&lt;T&gt;的形式 使用场景：用户可以扩展这个类，来为要实例化的bean作一个代理，比如为该对象的所有的方法作一个拦截，在调用前后输出一行log，模仿ProxyFactoryBean的功能。 扩展方式为： 1public class TestFactoryBean implements FactoryBean&lt;TestFactoryBean.TestFactoryInnerBean&gt; &#123; @Override public TestFactoryBean.TestFactoryInnerBean getObject() throws Exception &#123; System.out.println(&quot;[FactoryBean] getObject&quot;); return new TestFactoryBean.TestFactoryInnerBean(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return TestFactoryBean.TestFactoryInnerBean.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; public static class TestFactoryInnerBean&#123; &#125; &#125; 12. SmartInitializingSingleton org.springframework.beans.factory.SmartInitializingSingleton 这个接口中只有一个方法afterSingletonsInstantiated，其作用是是 在spring容器管理的所有单例对象（非懒加载对象）初始化完成之后调用的回调接口。其触发时机为postProcessAfterInitialization之后。 使用场景：用户可以扩展此接口在对所有单例对象初始化完毕后，做一些后置的业务处理。 扩展方式为： 1public class TestSmartInitializingSingleton implements SmartInitializingSingleton &#123; @Override public void afterSingletonsInstantiated() &#123; System.out.println(&quot;[TestSmartInitializingSingleton]&quot;); &#125; &#125; 13. CommandLineRunner org.springframework.boot.CommandLineRunner 这个接口也只有一个方法：run(String... args)，触发时机为整个项目启动完毕后，自动执行。如果有多个CommandLineRunner，可以利用@Order来进行排序。 使用场景：用户扩展此接口，进行启动项目之后一些业务的预处理。 扩展方式为： 1public class TestCommandLineRunner implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;[TestCommandLineRunner]&quot;); &#125; &#125; 14. DisposableBean org.springframework.beans.factory.DisposableBean 这个扩展点也只有一个方法：destroy()，其触发时机为当此对象销毁时，会自动执行这个方法。比如说运行applicationContext.registerShutdownHook时，就会触发这个方法。 扩展方式为： 1public class NormalBeanA implements DisposableBean &#123; @Override public void destroy() throws Exception &#123; System.out.println(&quot;[DisposableBean] NormalBeanA&quot;); &#125; &#125; 15. ApplicationListener org.springframework.context.ApplicationListener 准确的说，这个应该不算spring&amp;springboot当中的一个扩展点，ApplicationListener可以监听某个事件的event，触发时机可以穿插在业务方法执行过程中，用户可以自定义某个业务事件。但是spring内部也有一些内置事件，这种事件，可以穿插在启动调用中。我们也可以利用这个特性，来自己做一些内置事件的监听器来达到和前面一些触发点大致相同的事情。 接下来罗列下spring主要的内置事件： ContextRefreshedEvent ApplicationContext 被初始化或刷新时，该事件被发布。这也可以在ConfigurableApplicationContext接口中使用 refresh()方法来发生。此处的初始化是指：所有的Bean被成功装载，后处理Bean被检测并激活，所有Singleton Bean 被预实例化，ApplicationContext容器已就绪可用。 ContextStartedEvent 当使用 ConfigurableApplicationContext （ApplicationContext子接口）接口中的 start() 方法启动 ApplicationContext时，该事件被发布。你可以调查你的数据库，或者你可以在接受到这个事件后重启任何停止的应用程序。 ContextStoppedEvent 当使用 ConfigurableApplicationContext接口中的 stop()停止ApplicationContext 时，发布这个事件。你可以在接受到这个事件后做必要的清理的工作 ContextClosedEvent 当使用 ConfigurableApplicationContext接口中的 close()方法关闭 ApplicationContext 时，该事件被发布。一个已关闭的上下文到达生命周期末端；它不能被刷新或重启 RequestHandledEvent 这是一个 web-specific 事件，告诉所有 bean HTTP 请求已经被服务。只能应用于使用DispatcherServlet的Web应用。在使用Spring作为前端的MVC控制器时，当Spring处理用户请求结束后，系统会自动触发该事件 最后我们从这些spring&amp;springboot的扩展点当中，大致可以窥视到整个bean的生命周期。在业务开发或者写中间件业务的时候，可以合理利用spring提供给我们的扩展点，在spring启动的各个阶段内做一些事情。以达到自定义初始化的目的。此篇总结，如果有错误或者疏漏的地方，恳请指正。","categories":[],"tags":[]},{"title":"面向接口：限流","slug":"接口设计/面向接口：限流","date":"2024-09-02T10:58:29.715Z","updated":"2024-09-03T02:36:01.074Z","comments":true,"path":"2024/09/02/接口设计/面向接口：限流/","permalink":"https://andy-whb-cn.github.io/2024/09/02/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%EF%BC%9A%E9%99%90%E6%B5%81/","excerpt":"","text":"如何在SpringBoot中使用Guava和Redis实现接口限流的文章。具体包括： 使用Guava实现单机令牌桶限流 使用Redis实现分布式限流 现在，一个问题摆在我们面前：如何将这两种限流机制整合到同一个组件中，以便用户随时切换呢？ 显然，我们需要定义一个通用的限流组件，将其引入到业务中，并支持通过配置文件自由切换不同的限流机制。举例而言，当使用limit.type=redis时，启用Redis分布式限流组件，当使用limit.type=local时，启用Guava限流组件。这种自由切换机制能够为用户提供更大的灵活性和可维护性。 接下来，让我们开始动手实现吧！ 第一步，创建通用模块cloud-limiter-starter首先在父项目下创建一个模块 然后在pom文件中引入相关依赖 1&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringFramework--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 小提示：通用模块命名最好遵照规则以starter命名结束，同时通用模块引入的依赖最好设置&lt;scope&gt;provided&lt;/scope&gt;属性。 第二步，实现限流功能 创建限流接口 既然有两种限流机制，按照套路肯定得先创建一个限流接口，就叫LimiterManager吧。 1public interface LimiterManager &#123; boolean tryAccess(Limiter limiter);&#125; 分别实现Redis的限流功能和Guava的限流功能，这里只给出核心代码。 Guava限流的核心实现GuavaLimiter 1@Slf4jpublic class GuavaLimiter implements LimiterManager&#123; private final Map&lt;String, RateLimiter&gt; limiterMap = Maps.newConcurrentMap(); @Override public boolean tryAccess(Limiter limiter) &#123; RateLimiter rateLimiter = getRateLimiter(limiter); if (rateLimiter == null) &#123; return false; &#125; boolean access = rateLimiter.tryAcquire(1,100, TimeUnit.MILLISECONDS); log.info(&quot;&#123;&#125; access :&#123;&#125;&quot;,limiter.getKey() , access); return access; &#125;&#125; Redis限流的核心实现RedisLimiter 1@Slf4jpublic class RedisLimiter implements LimiterManager&#123; private final StringRedisTemplate stringRedisTemplate; public RedisLimiter(StringRedisTemplate stringRedisTemplate) &#123; this.stringRedisTemplate = stringRedisTemplate; &#125; @Override public boolean tryAccess(Limiter limiter) &#123; String key = limiter.getKey(); if (StringUtils.isEmpty(key)) &#123; throw new LimiterException( &quot;redis limiter key cannot be null&quot; ); &#125; List&lt;String&gt; keys = new ArrayList&lt;&gt;(); keys.add( key ); int seconds = limiter.getSeconds(); int limitCount = limiter.getLimitNum(); String luaScript = buildLuaScript(); RedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(luaScript, Long.class); Long count = stringRedisTemplate.execute( redisScript, keys, &quot;&quot; + limitCount, &quot;&quot; + seconds ); log.info( &quot;Access try count is &#123;&#125; for key=&#123;&#125;&quot;, count, key ); return count != null &amp;&amp; count != 0; &#125;&#125; 第三步，创建配置类编写配置类根据配置文件注入限流实现类，当配置文件中属性 limit.type=local 时启用Guava限流机制，当limit.type=redis 时启用Redis限流机制。 1@Configurationpublic class LimiterConfigure &#123; @Bean @ConditionalOnProperty(name = &quot;limit.type&quot;,havingValue = &quot;local&quot;) public LimiterManager guavaLimiter()&#123; return new GuavaLimiter(); &#125; @Bean @ConditionalOnProperty(name = &quot;limit.type&quot;,havingValue = &quot;redis&quot;) public LimiterManager redisLimiter(StringRedisTemplate stringRedisTemplate)&#123; return new RedisLimiter(stringRedisTemplate); &#125;&#125; 第四步，创建AOP根据前面的两篇文章可知，避免限流功能污染业务逻辑的最好方式是借助Spring AOP，所以很显然还得需要创建一个AOP。 1@Aspect@EnableAspectJAutoProxy(proxyTargetClass = true) //使用CGLIB代理@Conditional(LimitAspectCondition.class)public class LimitAspect &#123; @Setter(onMethod_ = @Autowired) private LimiterManager limiterManager; @Pointcut(&quot;@annotation(com.jianzh5.limit.aop.Limit)&quot;) private void check() &#123; &#125; @Before(&quot;check()&quot;) public void before(JoinPoint joinPoint)&#123; MethodSignature signature = (MethodSignature) joinPoint.getSignature(); Method method = signature.getMethod(); Limit limit = method.getAnnotation(Limit.class); if(limit != null)&#123; Limiter limiter = Limiter.builder().limitNum(limit.limitNum()) .seconds(limit.seconds()) .key(limit.key()).build(); if(!limiterManager.tryAccess(limiter))&#123; throw new LimiterException( &quot;There are currently many people , please try again later!&quot; ); &#125; &#125; &#125;&#125; 注意到类上我加了一行@Conditional(LimitAspectCondition.class)，使用了自定义条件选择器，意思是只有当配置类中出现了limit.type属性时才会加载这个AOP。 1public class LimitAspectCondition implements Condition &#123; @Override public boolean matches(ConditionContext conditionContext, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; //检查配置文件是否包含limit.type属性 return conditionContext.getEnvironment().containsProperty(ConfigConstant.LIMIT_TYPE); &#125;&#125; 第四步，创建spring.factories文件，引导SpringBoot加载配置类1## AutoConfigurationorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.jianzh5.limit.config.LimiterConfigure,\\ com.jianzh5.limit.aop.LimitAspect 完整目录结构如下： 第五步，在项目中引用限流组件 引入依赖 1&lt;dependency&gt; &lt;groupId&gt;com.jianzh5&lt;/groupId&gt; &lt;artifactId&gt;cloud-limit-starter&lt;/artifactId&gt;&lt;/dependency&gt; 在application.properties中设置加载的限流组件 1limit.type = redis 如果不配置此属性则不加载对应限流功能。 在需要限流的接口上加上注解1@Limit(key = &quot;Limiter:test&quot;,limitNum = 3,seconds = 1) 小结通过上述步骤，我们已经成功实现了一个通用限流组件。在实际应用中，只需要根据场景需求选择对应的限流机制，即可非常方便的进行限流操作。这种灵活性和便捷性，也是SpringBoot中定义Starter的一般套路。","categories":[],"tags":[]},{"title":"SpringBoot GraphQL","slug":"SpringBoot/SpringBoot：GraphQL","date":"2024-09-02T10:36:22.017Z","updated":"2025-11-05T01:56:44.426Z","comments":true,"path":"2024/09/02/SpringBoot/SpringBoot：GraphQL/","permalink":"https://andy-whb-cn.github.io/2024/09/02/SpringBoot/SpringBoot%EF%BC%9AGraphQL/","excerpt":"","text":"概述REST作为一种现代网络应用非常流行的软件架构风格受到广大WEB开发者的喜爱，在目前软件架构设计模式中随处可见REST的身影，但是随着REST的流行与发展，它的一个最大的缺点开始暴露出来： 在很多时候客户端需要的数据往往在不同的地方具有相似性，但却又不尽相同。 如同样的用户信息，在有的场景下前端只需要用户的简要信息（名称、头像），在其他场景下又需要用户的详细信息。当这样的相似但又不同的地方多的时候，就需要开发更多的接口来满足前端的需要。 随着这样的场景越来越多，接口越来越多，文档越来越臃肿，前后端沟通成本呈指数增加。 基于上面的场景，我们迫切需要有一种解决方案或框架，可以使得在使用同一个领域模型（DO、DTO）的数据接口时可以由前端指定需要的接口字段，而后端根据前端的需求自动适配并返回对应的字段。 这就是我们今天的主角GraphQL。 场景模拟考虑下面的场景： 用户 与 文章 是一对多的关系，一个用户可以发表多篇文章，同时又可以根据文章找到对应的作者。 我们需要构建以下几个Graphql查询： 根据用户ID获取用户详情，并获取此用户发表的所有文章 根据文章ID获取文章详情，并获取文章作者的信息 当然项目是基于SpringBoot开发的。 开发实战在正式开发之前我推荐你在IDEA上安装一下 JS GraphQL插件，这个插件方便我们编写Schema，语法纠错，代码高亮等等。。。 创建一个SpringBoot项目通过IDEA创建一个SpringBoot项目，并引入对应的jar 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--graphql start--&gt;&lt;dependency&gt; &lt;groupId&gt;com.graphql-java&lt;/groupId&gt;&lt;artifactId&gt;graphql-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;5.0.2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.graphql-java&lt;/groupId&gt; &lt;artifactId&gt;graphql-java-tools&lt;/artifactId&gt; &lt;version&gt;5.2.4&lt;/version&gt;&lt;/dependency&gt; &lt;!--graphql end--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 这里主要需要引入 graphql-spring-boot-starter和 graphql-java-tools。 建立Java实体类User 123456789101112131415161718@Datapublic class User &#123; private int userId; private String userName; private String realName; private String email; private List&lt;Post&gt; posts; public User() &#123; &#125; public User(int userId, String userName, String realName, String email) &#123; this.userId = userId; this.userName = userName; this.realName = realName; this.email = email; &#125;&#125; Post 123456789101112131415161718@Datapublic class Post &#123; private int postId; private String title ; private String text; private String category; private User user; public Post() &#123; &#125; public Post(int postId, String title, String text, String category) &#123; this.postId = postId; this.title = title; this.text = text; this.category = category; &#125;&#125; 定义了两个JAVA实体：Post，User。 编写Schema文件在resources&#x2F;schema目录下创建GraphQL Schema文件 123456789101112131415161718192021222324252627schema &#123; query: Query,&#125;type Query &#123; # 获取具体的用户 getUserById(id:Int) : User # 获取具体的博客 getPostById(id:Int) : Post&#125;type User &#123; userId : ID!, userName : String, realName : String, email : String, posts : [Post],&#125;type Post &#123; postId : ID!, title : String!, text : String, category: String user: User,&#125; 如上，我们通过 type关键字定义了两个对象，User与Post。在属性后面添加！表明这是一个非空属性，通过[Post]表明这是一个Post集合，类似于Java对象中List。 通过Query关键字定义了两个查询对象，getUserById，getPostById，分别返回User对象和Post对象。 关于schema的语法大家可以参考链接：https://graphql.org/learn/schema 编写业务逻辑PostService 1234567891011121314@Servicepublic class PostService implements GraphQLQueryResolver &#123; /** * 为了测试，只查询id为1的结果 */ public Post getPostById(int id)&#123; if(id == 1)&#123; User user = new User(1,&quot;javadaily&quot;,&quot;JAVA日知录&quot;,&quot;zhangsan@qq.com&quot;); Post post = new Post(1,&quot;Hello,Graphql&quot;,&quot;Graphql初体验&quot;,&quot;日记&quot;); post.setUser(user); return post; &#125;else&#123; return null; &#125; &#125;&#125; UserService 12345678910111213141516171819202122232425@Servicepublic class UserService implements GraphQLQueryResolver &#123; List&lt;User&gt; userList = Lists.newArrayList(); public User getUserById(int id)&#123; return userList.stream() .filter(item &gt; item.getUserId() == id) .findAny() .orElse(null); &#125; @PostConstruct public void initUsers()&#123; Post post1 = new Post(1,&quot;Hello,Graphql1&quot;,&quot;Graphql初体验1&quot;,&quot;日记&quot;); Post post2 = new Post(2,&quot;Hello,Graphql2&quot;,&quot;Graphql初体验2&quot;,&quot;日记&quot;); Post post3 = new Post(3,&quot;Hello,Graphql3&quot;,&quot;Graphql初体验3&quot;,&quot;日记&quot;); List&lt;Post&gt; posts = Lists.newArrayList(post1,post2,post3); User user1 = new User(1,&quot;zhangsan&quot;,&quot;张三&quot;,&quot;zhangsan@qq.com&quot;); User user2 = new User(2,&quot;lisi&quot;,&quot;李四&quot;,&quot;lisi@qq.com&quot;); user1.setPosts(posts); user2.setPosts(posts); userList.add(user1); userList.add(user2); &#125;&#125; 基于Graphql的查询需要实现 GraphQLQueryResolver接口，由于为了便于演示我们并没有引入数据层，请大家知悉。 配置Graphql 端点1234server.port = 8080graphql.servlet.corsEnabled=true# 配置端点graphql.servlet.mapping=/graphqlgraphql.servlet.enabled=true 配置完端口和端点后我们就可以对我们编写的Graphql接口进行测试了。 接口地址为：localhost:8080/graphql 测试这里我使用的是Chrome浏览器的 Altair Graphal Client插件，当然你还可以使用其他的客户端工具，如：graphql-playground。 安装插件浏览器输入chrome:&#x2F;&#x2F;extensions&#x2F;，在扩展中心搜索Altair后即可添加至浏览器。 查询启动SpringBoot项目，然后在打开的Altair插件界面，输入Graphql端点 http://localhost:8080/graphql，然后点击 Docs，将鼠标移至需要的查询上，点击 ADD QUERY 即可添加对应的查询。 点击Send Request 即可看到查询结果： 然后我们在Query中可以根据我们的需要新增或删除接口字段并重新请求接口，会看到响应结果中也会根据我们的请求自动返回结果： 小结Graphql支持的数据操作有： 查询（Query）：获取数据的基本查询。 变更（Mutation）：支持对数据的增删改等操作。 订阅（Subscription）：用于监听数据变动、并靠websocket等协议推送变动的消息给对方。 本节内容我们基于SpringBoot完成了Query的数据操作，实现过程还是相对比较简单。希望此文能让大家对Graphql有一个整体的了解，如果大家对Graphql感兴趣后面还会更新此系列文章，完成对其他数据操作的整合。","categories":[],"tags":[]},{"title":"SpringBoot启动参数","slug":"SpringBoot/SpringBoot：容器参数优化","date":"2024-09-02T09:02:25.399Z","updated":"2024-09-03T02:35:28.457Z","comments":true,"path":"2024/09/02/SpringBoot/SpringBoot：容器参数优化/","permalink":"https://andy-whb-cn.github.io/2024/09/02/SpringBoot/SpringBoot%EF%BC%9A%E5%AE%B9%E5%99%A8%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96/","excerpt":"","text":"12345server: tomcat: min-spare-threads: 20 max-threads: 100 connection-timeout: 5000 目前的容器优化，目前来说没有太多地方，需要考虑如下几个点 线程数 超时时间 这块对tomcat进行了一个优化配置，最大线程数是100，初始化线程是20, 超时时间是5000ms 默认tomcat最大线程数200，初始化线程10, 连接超时时间20s ⚠️upload failed, check dev console ⚠️upload failed, check dev console","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"}]},{"title":"Restful API 版本控制","slug":"接口设计/面向接口：Restful API 版本控制","date":"2024-09-02T08:47:53.483Z","updated":"2024-09-02T08:57:11.861Z","comments":true,"path":"2024/09/02/接口设计/面向接口：Restful API 版本控制/","permalink":"https://andy-whb-cn.github.io/2024/09/02/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%EF%BC%9ARestful%20API%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/","excerpt":"","text":"在实际项目开发中我们经常需要对接口进行版本管理。那今天我们就来聊聊为什么需要版本控制，以及如何对REST API进行版本控制。我们将讨论4种版本控制的方法，并比较不同的方法。 通过此文您将学到 为什么我们需要对RESTful API 进行版本控制? 可用的版本控制有哪些? 如何实现基于 Restful 的版本控制? 为什么我们需要对RESTful API进行版本化最好的版本控制方法是不进行版本控制。 构建向后兼容的服务，以便尽可能避免版本控制！ 然而，在许多情况下我们都需要进行版本控制，然我们看看下面具体的例子：最初，你有个这个版本的Student服务，返回数据如下：&#123; &quot;name&quot;: &quot;Bob Charlie&quot; &#125; 后来，您希望将学生的名字拆分，因此创建了这个版本的服务。&#123; &quot;name&quot;: &#123; &quot;firstName&quot;: &quot;Bob&quot;, &quot;lastName&quot;: &quot;Charlie&quot; &#125; &#125; 您可以从同一个服务支持这两个请求，但是随着每个版本的需求多样化，它会变得越来越复杂。 在这种情况下，版本控制就成必不可少，强制性的了。 接下来让我们创建一个简单的SpringBoot的maven项目，并理解对 RESTful 服务进行版本控制的4种不同方法。 几个用于实现版本控制的Bean 第一个版本的 Bean 12345@Data @AllArgsConstructor public class StudentV1 &#123; private String name; &#125; ` 第二个版本的 Bean 1234@Data public class StudentV2 &#123; private Name name; &#125; StudentV2使用的Name实体 123456@Data @AllArgsConstructor public class Name &#123; private String firstName; private String lastName; &#125; Restful 版本控制的方法我们希望创建两个版本的服务，一个返回 StudentV1，另一个返回 StudentV2。 让我们来看看创建相同服务版本的4种不同方法。 通过 URI 进行版本控制12345678910111213@RestController public class StudentUriController &#123; @GetMapping(&quot;v1/student&quot;) public StudentV1 studentV1() &#123; return new StudentV1(&quot;javadaily&quot;); &#125; @GetMapping(&quot;v2/student&quot;) public StudentV2 studentV2() &#123; return new StudentV2(new Name(&quot;javadaily&quot;, &quot;JAVA日知录&quot;)); &#125; &#125; 请求：http://localhost:8080/v1/student响应：{“name”:”javadaily”} 请求：http://localhost:8080/v2/student响应：{“name”:{“firstName”:”javadaily”,”lastName”:”JAVA日知录”}} 通过请求参数进行版本控制版本控制的第二种方法是使用请求参数来区分版本。请求示例如下所示： http://localhost:8080/student/param?version=1 http://localhost:8080/student/param?version=2 实现方式如下： 12345678910111213@RestController public class StudentParmController &#123; @GetMapping(value=&quot;/student/param&quot;, params = &quot;version=1&quot;) public StudentV1 studentV1() &#123; return new StudentV1(&quot;javadaily&quot;); &#125; @GetMapping(value=&quot;/student/param&quot;, params = &quot;version=2&quot;) public StudentV2 studentV2() &#123; return new StudentV2(new Name(&quot;javadaily&quot;, &quot;JAVA日知录&quot;)); &#125; &#125; 请求：http://localhost:8080/student/param?version=1响应：{“name”:”javadaily”} 请求：http://localhost:8080/student/param?version=2响应：{“name”:{“firstName”:”javadaily”,”lastName”:”JAVA日知录”}} 通过自定义Header进行版本控制版本控制的第三种方法是使用请求头来区分版本，请求示例如下： http://localhost:8080/student/header headers&#x3D;[X-API-VERSION&#x3D;1] http://localhost:8080/student/header headers&#x3D;[X-API-VERSION&#x3D;2] 实现方式如下所示： 123456789101112@RestController public class StudentHeaderController &#123; @GetMapping(value=&quot;/student/header&quot;,headers = &quot;X-API-VERSION=1&quot;) public StudentV1 studentV1() &#123; return new StudentV1(&quot;javadaily&quot;); &#125; @GetMapping(value=&quot;/student/header&quot;,headers = &quot;X-API-VERSION=2&quot;) public StudentV2 studentV2() &#123; return new StudentV2(new Name(&quot;javadaily&quot;, &quot;JAVA日知录&quot;)); &#125; &#125; 下图展示了我们如何使用Postman执行带有请求头的Get请求方法。 请求：http://localhost:8080/student/headerheader：X-API-VERSION = 1 请求：http://localhost:8080/student/headerheader：X-API-VERSION = 2 通过媒体类型进行版本控制最后一种版本控制方法是在请求中使用Accept Header，请求示例如下： http://localhost:8080/student/produce headers=[Accept=application/api-v1+json] http://localhost:8080/student/produce headers=[Accept=application/api-v2+json] 实现方式如下： 1234567891011@RestController public class StudentProduceController &#123; @GetMapping(value=&quot;/student/produce&quot;,produces = &quot;application/api-v1+json&quot;) public StudentV1 studentV1() &#123; return new StudentV1(&quot;javadaily&quot;); &#125; @GetMapping(value=&quot;/student/produce&quot;,produces = &quot;application/api-v2+json&quot;) public StudentV2 studentV2() &#123; return new StudentV2(new Name(&quot;javadaily&quot;, &quot;JAVA日知录&quot;)); &#125; &#125; 下图展示了我们如何使用Postman执行带有请求Accept的Get方法。 请求：http://localhost:8080/student/produceheader：Accept = application/api-v1+json 请求：http://localhost:8080/student/produceheader：Accept = application/api-v2+json 影响版本选择的因素以下因素影响版本控制的选择 URI 污染 - URL版本和请求参数版本控制会污染URI空间。 滥用请求头 - Accept 请求头并不是为版本控制而设计的。 缓存 - 如果你使用基于头的版本控制，我们不能仅仅基于URL缓存，你需要考虑特定的请求头。 是否能在浏览器直接执行 ? - 如果您有非技术消费者，那么基于URL的版本将更容易使用，因为它们可以直接在浏览器上执行。 API文档 - 如何让文档生成理解两个不同的url是同一服务的版本？ 事实上，并没有完美的版本控制解决方案，你需要根据项目实际情况进行选择。 下面列表展示了主要API提供商使用的不同版本控制方法： 媒体类型的版本控制 Github 自定义Header Microsoft URI路径 Twitter，百度，知乎 请求参数控制 Amazon 好了，今天的文章就到这里了，希望能对你有所帮助。","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"微服务","slug":"微服务","permalink":"https://andy-whb-cn.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"SpringBoot参数校验","slug":"SpringBoot/SpringBoot：输入参数校验","date":"2024-09-02T07:13:41.928Z","updated":"2024-09-03T02:35:16.366Z","comments":true,"path":"2024/09/02/SpringBoot/SpringBoot：输入参数校验/","permalink":"https://andy-whb-cn.github.io/2024/09/02/SpringBoot/SpringBoot%EF%BC%9A%E8%BE%93%E5%85%A5%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C/","excerpt":"","text":"https://mp.weixin.qq.com/s?__biz=MzAwMTk4NjM1MA==&amp;mid=2247512866&amp;idx=1&amp;sn=f9d1549dc312c48a9fde14fb1fdb5d07&amp;chksm=9ad3a963ada420756be6f848faef228d08b2ea49d87d2c083eabd6a2cf184cefa2ed8fa05964&amp;cur_album_id=1517924978380308484&amp;scene=189#wechat_redirect 首先我们来看看什么是Validator参数校验器，为什么需要参数校验？ 为什么需要参数校验在日常的接口开发中，为了防止非法参数对业务造成影响，经常需要对接口的参数做校验，例如登录的时候需要校验用户名密码是否为空，创建用户的时候需要校验邮件、手机号码格式是否准确。靠代码对接口参数一个个校验的话就太繁琐了，代码可读性极差。 Validator框架就是为了解决开发人员在开发的时候少写代码，提升开发效率；Validator专门用来进行接口参数校验，例如常见的必填校验，email格式校验，用户名必须位于6到12之间 等等… Validator校验框架遵循了JSR-303验证规范（参数校验规范）, JSR是Java Specification Requests的缩写。接下来我们看看在SpringbBoot中如何集成参数校验框架。 SpringBoot中集成参数校验第一步，引入依赖12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt; 注：从springboot-2.3开始，校验包被独立成了一个starter组件，所以需要引入validation和web，而springboot-2.3之前的版本只需要引入 web 依赖就可以了。 第二步，定义要参数校验的实体类12345678910111213141516171819@Data public class ValidVO &#123; private String id; @Length(min = 6,max = 12,message = &quot;appId长度必须位于6到12之间&quot;) private String appId; @NotBlank(message = &quot;名字为必填项&quot;) private String name; @Email(message = &quot;请填写正确的邮箱地址&quot;) private String email; private String sex; @NotEmpty(message = &quot;级别不能为空&quot;) private String level; &#125; 在实际开发中对于需要校验的字段都需要设置对应的业务提示，即message属性。常见的约束注解如下： 注解 功能 @AssertFalse 可以为null,如果不为null的话必须为false @AssertTrue 可以为null,如果不为null的话必须为true @DecimalMax 设置不能超过最大值 @DecimalMin 设置不能超过最小值 @Digits 设置必须是数字且数字整数的位数和小数的位数必须在指定范围内 @Future 日期必须在当前日期的未来 @Past 日期必须在当前日期的过去 @Max 最大不得超过此最大值 @Min 最大不得小于此最小值 @NotNull 不能为null，可以是空 @Null 必须为null @Pattern 必须满足指定的正则表达式 @Size 集合、数组、map等的size()值必须在指定范围内 @Email 必须是email格式 @Length 长度必须在指定范围内 @NotBlank 字符串不能为null,字符串trim()后也不能等于“” @NotEmpty 不能为null，集合、数组、map等size()不能为0；字符串trim()后可以等于“” @Range 值必须在指定范围内 @URL 必须是一个URL 注：此表格只是简单的对注解功能的说明，并没有对每一个注解的属性进行说明；可详见源码。 在Controller层对需要参数校验的方法加上@Validated注解 参数校验一般分为两类：在Controller使用模型接收数据时， @Validated注解直接放在该模型参数前即可。 1234567@PostMapping(value = &quot;test1&quot;) public String test1(@Validated @RequestBody ValidEntity validEntity)&#123; return &quot;test1 valid success&quot;; &#125; @PostMapping(value = &quot;test3&quot;) public String test3(@Validated ValidEntity validEntity)&#123; return &quot;test3 valid success&quot;; &#125; 当我们是直接在Controller层中的参数前，使用约束注解时，@Validated要直接放在类上 1234@PostMapping(value = &quot;test2&quot;) public String test2(@Email String email)&#123; return &quot;test2 valid success&quot;; &#125; 此时需要在主类上增加@Validated注解 123456@Validated @RestController @RequestMapping(&quot;/demo/valid&quot;) public class ValidController &#123; ... &#125; 在参数校验时我们既可以使用@Validated也可以使用@Valid注解，两者功能大部分类似；主要区别在于：@Valid属于javax下的，而@Validated属于spring下；@Valid支持嵌套校验、而@Validated不支持，@Validated支持分组，而@Valid不支持。@Validated： 用在类、方法和方法参数上，但不能用于成员属性。@Valid：可以用在方法、构造函数、方法参数和成员属性上@Validated和@Valid支持混合使用 第三步，定义校验类进行测试1234567891011121314151617181920212223242526@RestController @Slf4j @Validated public class ValidController &#123; @ApiOperation(&quot;RequestBody校验&quot;) @PostMapping(&quot;/valid/test1&quot;) public String test1(@Validated @RequestBody ValidVO validVO)&#123; log.info(&quot;validEntity is &#123;&#125;&quot;, validVO); return &quot;test1 valid success&quot;; &#125; @ApiOperation(&quot;Form校验&quot;) @PostMapping(value = &quot;/valid/test2&quot;) public String test2(@Validated ValidVO validVO)&#123; log.info(&quot;validEntity is &#123;&#125;&quot;, validVO); return &quot;test2 valid success&quot;; &#125; @ApiOperation(&quot;单参数校验&quot;) @PostMapping(value = &quot;/valid/test3&quot;) public String test3(@Email String email)&#123; log.info(&quot;email is &#123;&#125;&quot;, email); return &quot;email valid success&quot;; &#125; &#125; 这里我们先定义三个方法test1，test2，test3，test1使用了@RequestBody注解，用于接受前端发送的json数据，test2模拟表单提交，test3模拟单参数提交。注意，当使用单参数校验时需要在Controller上加上@Validated注解，否则不生效。 第四步，体验效果 调用test1方法，提示的是org.springframework.web.bind.MethodArgumentNotValidException异常POST http://localhost:8080/valid/test1 Content-Type: application/json &#123; &quot;id&quot;: 1, &quot;level&quot;: &quot;12&quot;, &quot;email&quot;: &quot;47693899&quot;, &quot;appId&quot;: &quot;ab1c&quot; &#125; 123456&#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;Validation failed for argument [0] in public java.lang.String com.jianzh5.blog.valid.ValidController.test1(com.jianzh5.blog.valid.ValidVO) with 3 errors: [Field error in object &#x27;validVO&#x27; on field &#x27;email&#x27;: rejected value [47693899]; codes [Email.validVO.email,Email.email,Email.java.lang.String,Email]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.email,email]; arguments []; default message [email],[Ljavax.validation.constraints.Pattern$Flag;@26139123,.*]; default message [不是一个合法的电子邮件地址]]...&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628239624332 &#125; 调用test2方法，提示的是org.springframework.validation.BindException异常POST http://localhost:8080/valid/test2 Content-Type: application/x-www-form-urlencoded id=1&amp;level=12&amp;email=476938977&amp;appId=ab1c 1234567891011121314151617&#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;org.springframework.validation.BeanPropertyBindingResult: 3 errors\\nField error in object &#x27;validVO&#x27; on field &#x27;name&#x27;: rejected value [null]; codes [NotBlank.validVO.name,NotBlank.name,NotBlank.java.lang.String,NotBlank]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [validVO.name,name]; arguments []; default message [name]]; default message [名字为必填项]...&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628239301951 &#125; ```3. 调用test3方法，提示的是`javax.validation.ConstraintViolationException`异常`POST http://localhost:8080/valid/test3 Content-Type: application/x-www-form-urlencoded email=476938977 ````json &#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;test3.email: 不是一个合法的电子邮件地址&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628239281022 &#125; 通过加入Validator校验框架可以帮助我们自动实现参数的校验。 参数异常加入全局异常处理器虽然我们之前定义了全局异常拦截器，也看到了拦截器确实生效了，但是Validator校验框架返回的错误提示太臃肿了，不便于阅读，为了方便前端提示，我们需要将其简化一下。 直接修改之前定义的RestExceptionHandler，单独拦截参数校验的三个异常：javax.validation.ConstraintViolationException，org.springframework.validation.BindException，org.springframework.web.bind.MethodArgumentNotValidException，代码如下： 12345678910111213141516171819202122@ExceptionHandler(value = &#123;BindException.class, ValidationException.class, MethodArgumentNotValidException.class&#125;) public ResponseEntity&lt;ResultData&lt;String&gt;&gt; handleValidatedException(Exception e) &#123; ResultData&lt;String&gt; resp = null; if (e instanceof MethodArgumentNotValidException) &#123; // BeanValidation exception MethodArgumentNotValidException ex = (MethodArgumentNotValidException) e; resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(), ex.getBindingResult().getAllErrors().stream() .map(ObjectError::getDefaultMessage) .collect(Collectors.joining(&quot;; &quot;)) ); &#125; else if (e instanceof ConstraintViolationException) &#123; // BeanValidation GET simple param ConstraintViolationException ex = (ConstraintViolationException) e; resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(), ex.getConstraintViolations().stream() .map(ConstraintViolation::getMessage) .collect(Collectors.joining(&quot;; &quot;)) ); &#125; else if (e instanceof BindException) &#123; // BeanValidation GET object param BindException ex = (BindException) e; resp = ResultData.fail(HttpStatus.BAD_REQUEST.value(), ex.getAllErrors().stream() .map(ObjectError::getDefaultMessage) .collect(Collectors.joining(&quot;; &quot;)) ); &#125; return new ResponseEntity&lt;&gt;(resp,HttpStatus.BAD_REQUEST); &#125; 默认情况下在对参数进行校验时Spring Validation会校验完所有字段然后才抛出异常，可以通过配置开启 Fali Fast模式，一旦校验失败就立即返回。 12345678910111213@Configuration public class ValidatedConfig &#123; @Bean public Validator validator() &#123; ValidatorFactory validatorFactory = Validation.byProvider(HibernateValidator.class) .configure() // 快速失败模式 .failFast(true) .buildValidatorFactory(); return validatorFactory.getValidator(); &#125; &#125; 体验效果POST http://localhost:8080/valid/test1 Content-Type: application/json &#123; &quot;id&quot;: 1, &quot;level&quot;: &quot;12&quot;, &quot;email&quot;: &quot;47693899&quot;, &quot;appId&quot;: &quot;ab1c&quot; &#125; 123456&#123; &quot;status&quot;: 400, &quot;message&quot;: &quot;名字为必填项; 不是一个合法的电子邮件地址; appId长度必须位于6到12之间&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628435116680 &#125; 是不是感觉清爽多了？ 自定义参数校验虽然Spring Validation 提供的注解基本上够用，但是面对复杂的定义，我们还是需要自己定义相关注解来实现自动校验。 比如上面实体类中的sex性别属性，只允许前端传递传 M，F 这2个枚举值，如何实现呢？ 第一步，创建自定义注解1234567891011121314151617181920@Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE&#125;) @Retention(RUNTIME) @Repeatable(EnumString.List.class) @Documented @Constraint(validatedBy = EnumStringValidator.class)public @interface EnumString &#123; String message() default &quot;value not in enum values.&quot;; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;; String[] value(); @Target(&#123;METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE&#125;) @Retention(RUNTIME) @Documented @interface List &#123; EnumString[] value(); &#125; &#125; 第二步，自定义校验逻辑12345678910111213141516public class EnumStringValidator implements ConstraintValidator&lt;EnumString, String&gt; &#123; private List&lt;String&gt; enumStringList; @Override public void initialize(EnumString constraintAnnotation) &#123; enumStringList = Arrays.asList(constraintAnnotation.value()); &#125; @Override public boolean isValid(String value, ConstraintValidatorContext context) &#123; if(value == null)&#123; return true; &#125; return enumStringList.contains(value); &#125; &#125; 第三步，在字段上增加注解123@ApiModelProperty(value = &quot;性别&quot;) @EnumString(value = &#123;&quot;F&quot;,&quot;M&quot;&#125;, message=&quot;性别只允许为F或M&quot;) private String sex; 第四步，体验效果POST http://localhost:8080/valid/test2 Content-Type: application/x-www-form-urlencoded id=1&amp;name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;appId=ab1cdddd&amp;sex=N 123456&#123; &quot;status&quot;: 400, &quot;message&quot;: &quot;性别只允许为F或M&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628435243723 &#125; 分组校验一个VO对象在新增的时候某些字段为必填，在更新的时候又非必填。如上面的ValidVO中 id 和 appId 属性在新增操作时都是非必填，而在编辑操作时都为必填，name在新增操作时为必填，面对这种场景你会怎么处理呢？ 在实际开发中我见到很多同学都是建立两个VO对象，ValidCreateVO，ValidEditVO来处理这种场景，这样确实也能实现效果，但是会造成类膨胀，而且极其容易被开发老鸟们嘲笑。 其实Validator校验框架已经考虑到了这种场景并且提供了解决方案，就是分组校验，只不过很多同学不知道而已。要使用分组校验，只需要三个步骤： 第一步：定义分组接口12345678public interface ValidGroup extends Default &#123; interface Crud extends ValidGroup&#123; interface Create extends Crud&#123;&#125; interface Update extends Crud&#123;&#125; interface Query extends Crud&#123;&#125; interface Delete extends Crud&#123;&#125; &#125; &#125; 这里我们定义一个分组接口ValidGroup让其继承javax.validation.groups.Default，再在分组接口中定义出多个不同的操作类型，Create，Update，Query，Delete。至于为什么需要继承Default我们稍后再说。 第二步，在模型中给参数分配分组1234567891011121314151617181920212223@Data @ApiModel(value = &quot;参数校验类&quot;) public class ValidVO &#123; @ApiModelProperty(&quot;ID&quot;) @Null(groups = ValidGroup.Crud.Create.class) @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;) private String id; @Null(groups = ValidGroup.Crud.Create.class) @NotNull(groups = ValidGroup.Crud.Update.class, message = &quot;应用ID不能为空&quot;) @ApiModelProperty(value = &quot;应用ID&quot;,example = &quot;cloud&quot;) private String appId; @ApiModelProperty(value = &quot;名字&quot;) @NotBlank(groups = ValidGroup.Crud.Create.class,message = &quot;名字为必填项&quot;) private String name; @ApiModelProperty(value = &quot;邮箱&quot;) @Email(message = &quot;请填写正取的邮箱地址&quot;) private String email; ... &#125; 给参数指定分组，对于未指定分组的则使用的是默认分组。 第三步，给需要参数校验的方法指定分组123456789101112131415161718192021@RestController @Api(&quot;参数校验&quot;) @Slf4j @Validated public class ValidController &#123; @ApiOperation(&quot;新增&quot;) @PostMapping(value = &quot;/valid/add&quot;) public String add(@Validated(value = ValidGroup.Crud.Create.class) ValidVO validVO) &#123; log.info(&quot;validEntity is &#123;&#125;&quot;, validVO); return &quot;test3 valid success&quot;; &#125; @ApiOperation(&quot;更新&quot;) @PostMapping(value = &quot;/valid/update&quot;) public String update(@Validated(value = ValidGroup.Crud.Update.class) ValidVO validVO) &#123; log.info(&quot;validEntity is &#123;&#125;&quot;, validVO); return &quot;test4 valid success&quot;; &#125; &#125; 这里我们通过value属性给add()和update()方法分别指定Create和Update分组。 第四步，体验效果POST http://localhost:8080/valid/add Content-Type: application/x-www-form-urlencoded name=javadaily&amp;level=12&amp;email=476938977@qq.com&amp;sex=F 在Create时我们没有传递id和appId参数，校验通过。 当我们使用同样的参数调用update方法时则提示参数校验错误。 123456&#123; &quot;status&quot;: 400, &quot;message&quot;: &quot;ID不能为空; 应用ID不能为空&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628492514313 &#125; 由于email属于默认分组，而我们的分组接口ValidGroup已经继承了Default分组，所以也是可以对email字段作参数校验的。如： POST http://localhost:8080/valid/add Content-Type: application/x-www-form-urlencoded name=javadaily&amp;level=12&amp;email=476938977&amp;sex=F 123456&#123; &quot;status&quot;: 400, &quot;message&quot;: &quot;请填写正取的邮箱地址&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1628492637305 &#125; 当然如果你的ValidGroup没有继承Default分组，那在代码属性上就需要加上@Validated(value = &#123;ValidGroup.Crud.Create.class, Default.class&#125;才能让email字段的校验生效。 小结参数校验在实际开发中使用频率非常高，但是很多同学还只是停留在简单的使用上，像分组校验，自定义参数校验这2个高阶技巧基本没怎么用过，经常出现譬如建立多个VO用于接受Create，Update场景的情况，很容易被老鸟被所鄙视嘲笑，希望大家好好掌握。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"}]},{"title":"SpringBoot统一返回格式","slug":"SpringBoot/SpringBoot：统一返回格式","date":"2024-09-02T06:39:47.310Z","updated":"2024-09-03T02:35:20.472Z","comments":true,"path":"2024/09/02/SpringBoot/SpringBoot：统一返回格式/","permalink":"https://andy-whb-cn.github.io/2024/09/02/SpringBoot/SpringBoot%EF%BC%9A%E7%BB%9F%E4%B8%80%E8%BF%94%E5%9B%9E%E6%A0%BC%E5%BC%8F/","excerpt":"","text":"http://mp.weixin.qq.com/s?__biz=MzAwMTk4NjM1MA==&amp;mid=2247492641&amp;idx=1&amp;sn=23f42094f442f382581d4bcdd191e12a&amp;chksm=9ad3fe60ada47776313cc10f4b5ed50cfebd9d21bd4bee54698c8e8d3ddf89d1c81e98665743&amp;scene=21#wechat_redirect 基于SpringBoot前后端分离开发模式下，如何友好的返回统一的标准格式以及如何优雅的处理全局异常。首先我们来看看为什么要返回统一的标准格式？ 为什么要对SpringBoot返回统一的标准格式在默认情况下，SpringBoot的返回格式常见的有三种： 第一种：返回 String 1234@GetMapping(&quot;/hello&quot;) public String getStr()&#123; return &quot;hello,javadaily&quot;; &#125; 此时调用接口获取到的返回值是这样： 1hello,javadaily 第二种：返回自定义对象 12345@GetMapping(&quot;/aniaml&quot;) public Aniaml getAniaml()&#123; Aniaml aniaml = new Aniaml(1,&quot;pig&quot;); return aniaml; &#125; 此时调用接口获取到的返回值是这样： 1&#123;&quot;id&quot;: 1, &quot;name&quot;: &quot;pig&quot; &#125; 第三种：接口异常 12345@GetMapping(&quot;/error&quot;) public int error()&#123; int i = 9/0; return i; &#125; 此时调用接口获取到的返回值是这样： 123456&#123; &quot;timestamp&quot;: &quot;2021-07-08T08:05:15.423+00:00&quot;, &quot;status&quot;: 500, &quot;error&quot;: &quot;Internal Server Error&quot;, &quot;path&quot;: &quot;/wrong&quot; &#125; 基于以上种种情况，如果你和前端开发人员联调接口她们就会很懵逼，由于我们没有给他一个统一的格式，前端人员不知道如何处理返回值。 还有甚者，有的同学比如小张喜欢对结果进行封装，他使用了Result对象，小王也喜欢对结果进行包装，但是他却使用的是Response对象，当出现这种情况时我相信前端人员一定会抓狂的。 所以我们项目中是需要定义一个统一的标准返回格式的。 定义返回标准格式一个标准的返回格式至少包含3部分： status 状态值：由后端统一定义各种返回结果的状态码 message 描述：本次接口调用的结果描述 data 数据：本次返回的数据。12345&#123; &quot;status&quot;:&quot;100&quot;, &quot;message&quot;:&quot;操作成功&quot;, &quot;data&quot;:&quot;hello,javadaily&quot; &#125; 当然也可以按需加入其他扩展值，比如接口调用时间 timestamp: 接口调用时间 定义返回对象123456789101112131415161718192021222324252627@Data public class ResultData&lt;T&gt; &#123; /** 结果状态 ,具体状态码参见ResultData.java*/ private int status; private String message; private T data; private long timestamp ; public ResultData ()&#123; this.timestamp = System.currentTimeMillis(); &#125; public static &lt;T&gt; ResultData&lt;T&gt; success(T data) &#123; ResultData&lt;T&gt; resultData = new ResultData&lt;&gt;(); resultData.setStatus(ReturnCode.RC100.getCode()); resultData.setMessage(ReturnCode.RC100.getMessage()); resultData.setData(data); return resultData; &#125; public static &lt;T&gt; ResultData&lt;T&gt; fail(int code, String message) &#123; ResultData&lt;T&gt; resultData = new ResultData&lt;&gt;(); resultData.setStatus(code); resultData.setMessage(message); return resultData; &#125;&#125; 定义状态码1234567891011121314151617181920212223242526272829303132public enum ReturnCode &#123; RC100(100,&quot;操作成功&quot;), RC999(999,&quot;操作失败&quot;), RC200(200,&quot;服务开启限流保护,请稍后再试!&quot;), RC201(201,&quot;服务开启降级保护,请稍后再试!&quot;), RC202(202,&quot;热点参数限流,请稍后再试!&quot;), RC203(203,&quot;系统规则不满足要求,请稍后再试!&quot;), RC204(204,&quot;授权规则不通过,请稍后再试!&quot;), RC403(403,&quot;无访问权限,请联系管理员授予权限&quot;), RC401(401,&quot;匿名用户访问无权限资源时的异常&quot;), RC500(500,&quot;系统异常，请稍后重试&quot;), INVALID_TOKEN(2001,&quot;访问令牌不合法&quot;), ACCESS_DENIED(2003,&quot;没有权限访问该资源&quot;), CLIENT_AUTHENTICATION_FAILED(1001,&quot;客户端认证失败&quot;), USERNAME_OR_PASSWORD_ERROR(1002,&quot;用户名或密码错误&quot;), UNSUPPORTED_GRANT_TYPE(1003, &quot;不支持的认证模式&quot;); private final int code; private final String message; ReturnCode(int code, String message)&#123; this.code = code; this.message = message; &#125; public int getCode() &#123; return code; &#125; public String getMessage() &#123; return message; &#125; &#125; 统一返回格式1234@GetMapping(&quot;/hello&quot;) public ResultData&lt;String&gt; getStr()&#123; return ResultData.success(&quot;hello,javadaily&quot;);&#125; 此时调用接口获取到的返回值是这样： 1234567&#123; &quot;status&quot;: 100, &quot;message&quot;: &quot;hello,javadaily&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1625736481648, &quot;httpStatus&quot;: 0 &#125; 这样确实已经实现了我们想要的结果，我在很多项目中看到的都是这种写法，在Controller层通过ResultData.success()对返回结果进行包装后返回给前端。 看到这里我们不妨停下来想想，这样做有什么弊端呢？ 最大的弊端就是我们后面每写一个接口都需要调用ResultData.success()这行代码对结果进行包装，重复劳动，浪费体力； 而且还很容易被其他老鸟给嘲笑。 所以呢我们需要对代码进行优化，目标就是不要每个接口都手工制定ResultData返回值。 高级实现方式要优化这段代码很简单，我们只需要借助SpringBoot提供的ResponseBodyAdvice即可。 ResponseBodyAdvice的作用：拦截Controller方法的返回值，统一处理返回值&#x2F;响应体，一般用来统一返回格式，加解密，签名等等。 先来看下ResponseBodyAdvice的源码： 123456public interface ResponseBodyAdvice&lt;T&gt; &#123; /** * 是否支持advice功能 * true 支持，false 不支持 */ boolean supports(MethodParameter var1, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; var2); /** * 对返回的数据进行处理 */ @Nullable T beforeBodyWrite(@Nullable T var1, MethodParameter var2, MediaType var3, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; var4, ServerHttpRequest var5, ServerHttpResponse var6); &#125; ` 我们只需要编写一个具体实现类即可 1234567891011121314@RestControllerAdvice public class ResponseAdvice implements ResponseBodyAdvice&lt;Object&gt; &#123; @Autowired private ObjectMapper objectMapper; @Override public boolean supports(MethodParameter methodParameter, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass) &#123; return true; &#125; @SneakyThrows @Override public Object beforeBodyWrite(Object o, MethodParameter methodParameter, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse) &#123; if(o instanceof String)&#123; return objectMapper.writeValueAsString(ResultData.success(o)); &#125; return ResultData.success(o); &#125; &#125; 需要注意两个地方： @RestControllerAdvice是@RestController注解的增强，可以实现三个方面的功能： 全局异常处理 全局数据绑定 全局数据预处理 String类型判断123if(o instanceof String)&#123; return objectMapper.writeValueAsString(ResultData.success(o)); &#125; 这段代码一定要加，如果Controller直接返回String的话，SpringBoot是直接返回，故我们需要手动转换成json。经过上面的处理我们就再也不需要通过ResultData.success()来进行转换了，直接返回原始数据格式，SpringBoot自动帮我们实现包装类的封装。 1234@GetMapping(&quot;/hello&quot;) public String getStr()&#123; return &quot;hello,javadaily&quot;; &#125; 此时我们调用接口返回的数据结果为： 12345678910111213141516171819&#123; &quot;status&quot;: 100, &quot;message&quot;: &quot;hello,javadaily&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1625736481648, &quot;httpStatus&quot;: 0 &#125; ```是不是感觉很完美，别急，还有个问题在等着你呢。### 接口异常问题此时有个问题，由于我们没对Controller的异常进行处理，当我们调用的方法一旦出现异常，就会出现问题，比如下面这个接口```java@GetMapping(&quot;/wrong&quot;) public int error()&#123; int i = 9/0; return i; &#125; 返回的结果为： 这显然不是我们想要的结果，接口都报错了还返回操作成功的响应码，前端看了会打人的。别急，接下来我们进入第二个议题，如何优雅的处理全局异常。 SpringBoot为什么需要全局异常处理器 不用手写try…catch，由全局异常处理器统一捕获 使用全局异常处理器最大的便利就是程序员在写代码时不再需要手写try...catch了，前面我们讲过，默认情况下SpringBoot出现异常时返回的结果是这样： 123456&#123; &quot;timestamp&quot;: &quot;2021-07-08T08:05:15.423+00:00&quot;, &quot;status&quot;: 500, &quot;error&quot;: &quot;Internal Server Error&quot;, &quot;path&quot;: &quot;/wrong&quot; &#125; 这种数据格式返回给前端，前端是看不懂的，所以这时候我们一般通过try...catch来处理异常 1234567891011@GetMapping(&quot;/wrong&quot;) public int error()&#123; int i; try&#123; i = 9/0; &#125;catch (Exception e)&#123; log.error(&quot;error:&#123;&#125;&quot;, e); i = 0; &#125; return i; &#125; 我们追求的目标肯定是不需要再手动写try...catch了，而是希望由全局异常处理器处理。 对于自定义异常，只能通过全局异常处理器来处理 1234@GetMapping(&quot;error1&quot;) public void empty()&#123; throw new RuntimeException(&quot;自定义异常&quot;); &#125; 当我们引入Validator参数校验器的时候，参数校验不通过会抛出异常，此时是无法用try...catch捕获的，只能使用全局异常处理器。 如何实现全局异常处理器1234567891011@Slf4j @RestControllerAdvice public class RestExceptionHandler &#123; @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public ResultData&lt;String&gt; exception(Exception e) &#123; log.error(&quot;全局异常信息 ex=&#123;&#125;&quot;, e.getMessage(), e); return ResultData.fail(ReturnCode.RC500.getCode(), e.getMessage()); &#125; &#125; 有三个细节需要说明一下： @RestControllerAdvice，RestController的增强类，可用于实现全局异常处理器 @ExceptionHandler,统一处理某一类异常，从而减少代码重复率和复杂度，比如要获取自定义异常可以@ExceptionHandler(BusinessException.class) @ResponseStatus指定客户端收到的http状态码 体验效果这时候我们调用如下接口： 1234@GetMapping(&quot;error1&quot;) public void empty()&#123; throw new RuntimeException(&quot;自定义异常&quot;); &#125; 返回的结果如下： 123456&#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;自定义异常&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1625795902556 &#125; 基本满足我们的需求了。 但是当我们同时启用统一标准格式封装功能ResponseAdvice和RestExceptionHandler全局异常处理器时又出现了新的问题： 1234567891011&#123; &quot;status&quot;: 100, &quot;message&quot;: &quot;操作成功&quot;, &quot;data&quot;: &#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;自定义异常&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1625796167986 &#125;, &quot;timestamp&quot;: 1625796168008 &#125; 此时返回的结果是这样，统一格式增强功能会给返回的异常结果再次封装，所以接下来我们需要解决这个问题。 全局异常接入返回的标准格式要让全局异常接入标准格式很简单，因为全局异常处理器已经帮我们封装好了标准格式，我们只需要直接返回给客户端即可。 123456789101112@SneakyThrows @Override public Object beforeBodyWrite(Object o, MethodParameter methodParameter, MediaType mediaType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; aClass, ServerHttpRequest serverHttpRequest, ServerHttpResponse serverHttpResponse) &#123; if(o instanceof String)&#123; return objectMapper.writeValueAsString(ResultData.success(o)); &#125; if(o instanceof ResultData)&#123; return o; &#125; return ResultData.success(o); &#125; 关键代码： 123if(o instanceof ResultData)&#123; return o; &#125; 如果返回的结果是ResultData对象，直接返回即可。 这时候我们再调用上面的错误方法，返回的结果就符合我们的要求了。 123456&#123; &quot;status&quot;: 500, &quot;message&quot;: &quot;自定义异常&quot;, &quot;data&quot;: null, &quot;timestamp&quot;: 1625796580778 &#125; 希望通过这篇文章你能掌握如何在你项目中友好实现统一标准格式到返回并且可以优雅的处理全局异常。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"},{"name":"Java","slug":"Java","permalink":"https://andy-whb-cn.github.io/tags/Java/"},{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"微服务","slug":"微服务","permalink":"https://andy-whb-cn.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"面向接口：幂等性","slug":"接口设计/面向接口：幂等性","date":"2024-09-02T02:59:25.925Z","updated":"2024-09-02T10:49:12.127Z","comments":true,"path":"2024/09/02/接口设计/面向接口：幂等性/","permalink":"https://andy-whb-cn.github.io/2024/09/02/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%EF%BC%9A%E5%B9%82%E7%AD%89%E6%80%A7/","excerpt":"","text":"原文（https://mp.weixin.qq.com/s/58j92LF2AP5mKXjQl-YaRg） 一、什么是幂等性幂等是一个数学与计算机学概念，在数学中某一元运算为幂等时，其作用在任一元素两次后会和其作用一次的结果相同。 在计算机中编程中，一个幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。幂等函数或幂等方法是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。 二、什么是接口幂等性在HTTP&#x2F;1.1中，对幂等性进行了定义。它描述了一次和多次请求某一个资源对于资源本身应该具有同样的结果（网络超时等问题除外），即第一次请求的时候对资源产生了副作用，但是以后的多次请求都不会再对资源产生副作用。 这里的副作用是不会对结果产生破坏或者产生不可预料的结果。也就是说，其任意多次执行对资源本身所产生的影响均与一次执行的影响相同。 三、为什么需要实现幂等性在接口调用时一般情况下都能正常返回信息不会重复提交，不过在遇见以下情况时可以就会出现问题，如： 前端重复提交表单： 在填写一些表格时候，用户填写完成提交，很多时候会因网络波动没有及时对用户做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。 用户恶意进行刷单： 例如在实现用户投票这种功能时，如果用户针对一个用户进行重复提交投票，这样会导致接口接收到用户重复提交的投票信息，这样会使投票结果与事实严重不符。 接口超时重复提交： 很多时候 HTTP 客户端工具都默认开启超时重试的机制，尤其是第三方调用接口时候，为了防止网络波动超时等造成的请求失败，都会添加重试机制，导致一个请求提交多次。 消息进行重复消费： 当使用 MQ 消息中间件时候，如果发生消息中间件出现错误未及时提交消费信息，导致发生重复消费。使用幂等性最大的优势在于使接口保证任何幂等性操作，免去因重试等造成系统产生的未知的问题。 四、引入幂等性后对系统的影响幂等性是为了简化客户端逻辑处理，能放置重复提交等操作，但却增加了服务端的逻辑复杂性和成本，其主要是： 把并行执行的功能改为串行执行，降低了执行效率。 增加了额外控制幂等的业务逻辑，复杂化了业务功能；所以在使用时候需要考虑是否引入幂等性的必要性，根据实际业务场景具体分析，除了业务上的特殊要求外，一般情况下不需要引入的接口幂等性。 五、Restful API 接口的幂等性现在流行的 Restful 推荐的几种 HTTP 接口方法中，分别存在幂等行与不能保证幂等的方法，如下： √ 满足幂等 x 不满足幂等 可能满足也可能不满足幂等，根据实际业务逻辑有关 方法类型 是否幂等 描述 Get √ Get 方法用于获取资源。其一般不会也不应当对系统资源进行改变，所以是幂等的。 Post × Post 方法一般用于创建新的资源。其每次执行都会新增数据，所以不是幂等的。 Put - Put 方法一般用于修改资源。该操作则分情况来判断是不是满足幂等，更新操作中直接根据某个值进行更新，也能保持幂等。不过执行累加操作的更新是非幂等。 Delete - Delete 方法一般用于删除资源。该操作则分情况来判断是不是满足幂等，当根据唯一值进行删除时，删除同一个数据多次执行效果一样。不过需要注意，带查询条件的删除则就不一定满足幂等了。例如在根据条件删除一批数据后，这时候新增加了一条数据也满足条件，然后又执行了一次删除，那么将会导致新增加的这条满足条件数据也被删除。 六、如何实现幂等性方案一：数据库唯一主键方案描述数据库唯一主键的实现主要是利用数据库中主键唯一约束的特性，一般来说唯一主键比较适用于“插入”时的幂等性，其能保证一张表中只能存在一条带该唯一主键的记录。使用数据库唯一主键完成幂等性时需要注意的是，该主键一般来说并不是使用数据库中自增主键，而是使用分布式 ID 充当主键（可以参考 Java 中分布式 ID 的设计方案 这篇文章），这样才能能保证在分布式环境下 ID 的全局唯一性。 适用操作： 插入操作 删除操作 使用限制： 需要生成全局唯一主键 ID； 主要流程： 主要流程： ① 客户端执行创建请求，调用服务端接口。 ② 服务端执行业务逻辑，生成一个分布式 ID，将该 ID 充当待插入数据的主键，然后执数据插入操作，运行对应的 SQL 语句。 ③ 服务端将该条数据插入数据库中，如果插入成功则表示没有重复调用接口。如果抛出主键重复异常，则表示数据库中已经存在该条记录，返回错误信息到客户端。 方案二：数据库乐观锁方案描述：数据库乐观锁方案一般只能适用于执行“更新操作”的过程，我们可以提前在对应的数据表中多添加一个字段，充当当前数据的版本标识。这样每次对该数据库该表的这条数据执行更新时，都会将该版本标识作为一个条件，值为上次待更新数据中的版本标识的值。 适用操作： 更新操作 使用限制： 需要数据库对应业务表中添加额外字段； 描述示例： 例如，存在如下的数据表中： id name price 1 小米手机 1000 2 苹果手机 2500 3 华为手机 1600 为了每次执行更新时防止重复更新，确定更新的一定是要更新的内容，我们通常都会添加一个 version 字段记录当前的记录版本，这样在更新时候将该值带上，那么只要执行更新操作就能确定一定更新的是某个对应版本下的信息。 id name price version 1 小米手机 1000 10 2 苹果手机 2500 21 3 华为手机 1600 5 这样每次执行更新时候，都要指定要更新的版本号，如下操作就能准确更新 version&#x3D;5 的信息： 1UPDATE my_table SET price=price+50,version=version+1 WHERE id=1 AND version=5 上面 WHERE 后面跟着条件 id&#x3D;1 AND version&#x3D;5 被执行后，id&#x3D;1 的 version 被更新为 6，所以如果重复执行该条 SQL 语句将不生效，因为 id&#x3D;1 AND version&#x3D;5 的数据已经不存在，这样就能保住更新的幂等，多次更新对结果不会产生影响。 方案三：防重 Token 令牌方案描述：针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用 Token 的机制实现防止重复提交。简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID 一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis 中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。如果不存在对应的 Key 或 Value 不匹配就返回重复执行的错误信息，这样来保证幂等操作。 适用操作： 插入操作 更新操作 删除操作 使用限制： 需要生成全局唯一 Token 串； 需要使用第三方组件 Redis 进行数据效验； 主要流程： ① 服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 ID 或者 UUID 串。 ② 客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。 ③ 然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。 ④ 将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。 ⑤ 客户端在执行提交表单时，把 Token 存入到 Headers 中，执行业务请求带上该 Headers。 ⑥ 服务端接收到请求后从 Headers 中拿到 Token，然后根据 Token 到 Redis 中查找该 key 是否存在。 ⑦ 服务端根据 Redis 中是否存该 key 进行判断，如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。 注意，在并发情况下，执行 Redis 查找数据与删除需要保证原子性，否则很可能在并发下无法保证幂等性。其实现方法可以使用分布式锁或者使用 Lua 表达式来注销查询与删除操作。 方案四、下游传递唯一序列号方案描述：所谓请求序列号，其实就是每次向服务端请求时候附带一个短时间内唯一不重复的序列号，该序列号可以是一个有序 ID，也可以是一个订单号，一般由下游生成，在调用上游服务端接口时附加该序列号和用于认证的 ID。当上游服务器收到请求信息后拿取该 序列号 和下游 认证ID 进行组合，形成用于操作 Redis 的 Key，然后到 Redis 中查询是否存在对应的 Key 的键值对，根据其结果： 如果存在，就说明已经对该下游的该序列号的请求进行了业务处理，这时可以直接响应重复请求的错误信息。 如果不存在，就以该 Key 作为 Redis 的键，以下游关键信息作为存储的值（例如下游商传递的一些业务逻辑信息），将该键值对存储到 Redis 中 ，然后再正常执行对应的业务逻辑即可。 适用操作： 插入操作 更新操作 删除操作 使用限制： 要求第三方传递唯一序列号； 需要使用第三方组件 Redis 进行数据效验； 主要流程： 主要步骤： ① 下游服务生成分布式 ID 作为序列号，然后执行请求调用上游接口，并附带“唯一序列号”与请求的“认证凭据ID”。 ② 上游服务进行安全效验，检测下游传递的参数中是否存在“序列号”和“凭据ID”。 ③ 上游服务到 Redis 中检测是否存在对应的“序列号”与“认证ID”组成的 Key，如果存在就抛出重复执行的异常信息，然后响应下游对应的错误信息。如果不存在就以该“序列号”和“认证ID”组合作为 Key，以下游关键信息作为 Value，进而存储到 Redis 中，然后正常执行接来来的业务逻辑。 上面步骤中插入数据到 Redis 一定要设置过期时间。这样能保证在这个时间范围内，如果重复调用接口，则能够进行判断识别。如果不设置过期时间，很可能导致数据无限量的存入 Redis，致使 Redis 不能正常工作。 七、实现接口幂等示例这里使用防重 Token 令牌方案，该方案能保证在不同请求动作下的幂等性，实现逻辑可以看上面写的”防重 Token 令牌”方案，接下来写下实现这个逻辑的代码。 1、Maven 引入相关依赖这里使用 Maven 工具管理依赖，这里在 pom.xml 中引入 SpringBoot、Redis、lombok 相关依赖。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.3.4.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;groupId&gt;mydlq.club&lt;/groupId&gt; &lt;artifactId&gt;springboot-idempotent-token&lt;/artifactId&gt; &lt;version&gt;0.0.1&lt;/version&gt; &lt;name&gt;springboot-idempotent-token&lt;/name&gt; &lt;description&gt;Idempotent Demo&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!--springboot web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--springboot data redis--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2、配置连接 Redis 的参数在 application 配置文件中配置连接 Redis 的参数如下： 1234567891011121314spring: redis: ssl: false host: 127.0.0.1 port: 6379 database: 0 timeout: 1000 password: lettuce: pool: max-active: 100 max-wait: -1 min-idle: 0 max-idle: 20 3、创建与验证 Token 工具类创建用于操作 Token 相关的 Service 类，里面存在 Token 创建与验证方法，其中： Token 创建方法： 使用 UUID 工具创建 Token 串，设置以 “idempotent_token:“+“Token串” 作为 Key，以用户信息当成 Value，将信息存入 Redis 中。 Token 验证方法： 接收 Token 串参数，加上 Key 前缀形成 Key，再传入 value 值，执行 Lua 表达式（Lua 表达式能保证命令执行的原子性）进行查找对应 Key 与删除操作。执行完成后验证命令的返回结果，如果结果不为空且非0，则验证成功，否则失败。 1import java.util.Arrays;import java.util.UUID;import java.util.concurrent.TimeUnit;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.StringRedisTemplate;import org.springframework.data.redis.core.script.DefaultRedisScript;import org.springframework.data.redis.core.script.RedisScript;import org.springframework.stereotype.Service;@Slf4j@Servicepublic class TokenUtilService &#123; @Autowired private StringRedisTemplate redisTemplate; /** * 存入 Redis 的 Token 键的前缀 */ private static final String IDEMPOTENT_TOKEN_PREFIX = &quot;idempotent_token:&quot;; /** * 创建 Token 存入 Redis，并返回该 Token * * @param value 用于辅助验证的 value 值 * @return 生成的 Token 串 */ public String generateToken(String value) &#123; // 实例化生成 ID 工具对象 String token = UUID.randomUUID().toString(); // 设置存入 Redis 的 Key String key = IDEMPOTENT_TOKEN_PREFIX + token; // 存储 Token 到 Redis，且设置过期时间为5分钟 redisTemplate.opsForValue().set(key, value, 5, TimeUnit.MINUTES); // 返回 Token return token; &#125; /** * 验证 Token 正确性 * * @param token token 字符串 * @param value value 存储在Redis中的辅助验证信息 * @return 验证结果 */ public boolean validToken(String token, String value) &#123; // 设置 Lua 脚本，其中 KEYS[1] 是 key，KEYS[2] 是 value String script = &quot;if redis.call(&#x27;get&#x27;, KEYS[1]) == KEYS[2] then return redis.call(&#x27;del&#x27;, KEYS[1]) else return 0 end&quot;; RedisScript&lt;Long&gt; redisScript = new DefaultRedisScript&lt;&gt;(script, Long.class); // 根据 Key 前缀拼接 Key String key = IDEMPOTENT_TOKEN_PREFIX + token; // 执行 Lua 脚本 Long result = redisTemplate.execute(redisScript, Arrays.asList(key, value)); // 根据返回结果判断是否成功成功匹配并删除 Redis 键值对，若果结果不为空和0，则验证通过 if (result != null &amp;&amp; result != 0L) &#123; log.info(&quot;验证 token=&#123;&#125;,key=&#123;&#125;,value=&#123;&#125; 成功&quot;, token, key, value); return true; &#125; log.info(&quot;验证 token=&#123;&#125;,key=&#123;&#125;,value=&#123;&#125; 失败&quot;, token, key, value); return false; &#125;&#125; 4、创建测试的 Controller 类创建用于测试的 Controller 类，里面有获取 Token 与测试接口幂等性的接口，内容如下： 1import lombok.extern.slf4j.Slf4j;import mydlq.club.example.service.TokenUtilService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;@Slf4j@RestControllerpublic class TokenController &#123; @Autowired private TokenUtilService tokenService; /** * 获取 Token 接口 * * @return Token 串 */ @GetMapping(&quot;/token&quot;) public String getToken() &#123; // 获取用户信息（这里使用模拟数据） // 注：这里存储该内容只是举例，其作用为辅助验证，使其验证逻辑更安全，如这里存储用户信息，其目的为: // - 1)、使用&quot;token&quot;验证 Redis 中是否存在对应的 Key // - 2)、使用&quot;用户信息&quot;验证 Redis 的 Value 是否匹配。 String userInfo = &quot;mydlq&quot;; // 获取 Token 字符串，并返回 return tokenService.generateToken(userInfo); &#125; /** * 接口幂等性测试接口 * * @param token 幂等 Token 串 * @return 执行结果 */ @PostMapping(&quot;/test&quot;) public String test(@RequestHeader(value = &quot;token&quot;) String token) &#123; // 获取用户信息（这里使用模拟数据） String userInfo = &quot;mydlq&quot;; // 根据 Token 和与用户相关的信息到 Redis 验证是否存在对应的信息 boolean result = tokenService.validToken(token, userInfo); // 根据验证结果响应不同信息 return result ? &quot;正常调用&quot; : &quot;重复调用&quot;; &#125;&#125; 5、创建 SpringBoot 启动类创建启动类，用于启动 SpringBoot 应用。 123456789import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 6、写测试类进行测试写个测试类进行测试，多次访问同一个接口，测试是否只有第一次能否执行成功。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import org.junit.Assert;import org.junit.Test;import org.junit.runner.RunWith;import lombok.extern.slf4j.Slf4j;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.http.MediaType;import org.springframework.test.context.junit4.SpringRunner;import org.springframework.test.web.servlet.MockMvc;import org.springframework.test.web.servlet.request.MockMvcRequestBuilders;import org.springframework.test.web.servlet.setup.MockMvcBuilders;import org.springframework.web.context.WebApplicationContext;@Slf4j@SpringBootTest@RunWith(SpringRunner.class)public class IdempotenceTest &#123; @Autowired private WebApplicationContext webApplicationContext; @Test public void interfaceIdempotenceTest() throws Exception &#123; // 初始化 MockMvc MockMvc mockMvc = MockMvcBuilders.webAppContextSetup(webApplicationContext).build(); // 调用获取 Token 接口 String token = mockMvc.perform(MockMvcRequestBuilders.get(&quot;/token&quot;) .accept(MediaType.TEXT_HTML)) .andReturn() .getResponse() .getContentAsString(); log.info(&quot;获取的 Token 串：&#123;&#125;&quot;, token); // 循环调用 5 次进行测试 for (int i = 1; i &lt;= 5; i++) &#123; log.info(&quot;第&#123;&#125;次调用测试接口&quot;, i); // 调用验证接口并打印结果 String result = mockMvc.perform(MockMvcRequestBuilders.post(&quot;/test&quot;) .header(&quot;token&quot;, token) .accept(MediaType.TEXT_HTML)) .andReturn() .getResponse() .getContentAsString(); log.info(result); // 结果断言 if (i == 0) &#123; Assert.assertEquals(result, &quot;正常调用&quot;); &#125; else &#123; Assert.assertEquals(result, &quot;重复调用&quot;); &#125; &#125; &#125;&#125; 显示如下： 1[main] IdempotenceTest: 获取的 Token 串：980ea707-ce2e-456e-a059-0a03332110b4[main] IdempotenceTest: 第1次调用测试接口[main] IdempotenceTest: 正常调用[main] IdempotenceTest: 第2次调用测试接口[main] IdempotenceTest: 重复调用[main] IdempotenceTest: 第3次调用测试接口[main] IdempotenceTest: 重复调用[main] IdempotenceTest: 第4次调用测试接口[main] IdempotenceTest: 重复调用[main] IdempotenceTest: 第5次调用测试接口[main] IdempotenceTest: 重复调用 八、最后总结幂等性是开发当中很常见也很重要的一个需求，尤其是支付、订单等与金钱挂钩的服务，保证接口幂等性尤其重要。在实际开发中，我们需要针对不同的业务场景我们需要灵活的选择幂等性的实现方式： 对于下单等存在唯一主键的，可以使用“唯一主键方案”的方式实现。 对于更新订单状态等相关的更新场景操作，使用“乐观锁方案”实现更为简单。 对于上下游这种，下游请求上游，上游服务可以使用“下游传递唯一序列号方案”更为合理。 类似于前端重复提交、重复下单、没有唯一ID号的场景，可以通过 Token 与 Redis 配合的“防重 Token 方案”实现更为快捷。 上面只是给与一些建议，再次强调一下，实现幂等性需要先理解自身业务需求，根据业务逻辑来实现这样才合理，处理好其中的每一个结点细节，完善整体的业务流程设计，才能更好的保证系统的正常运行。最后做一个简单总结 方案名称 适用方法 实现复杂度 方案缺点 数据库唯一主键 插入操作 删除操作 简单 - 只能用于插入操作；- 只能用于存在唯一主键场景； 数据库乐观锁 更新操作 简单 - 只能用于更新操作；- 表中需要额外添加字段； 请求序列号 插入操作 更新操作 删除操作 简单 - 需要保证下游生成唯一序列号；- 需要 Redis 第三方存储已经请求的序列号； 防重 Token 令牌 插入操作 更新操作 删除操作 适中 - 需要 Redis 第三方存储生成的 Token 串；","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://andy-whb-cn.github.io/tags/Java/"},{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"微服务","slug":"微服务","permalink":"https://andy-whb-cn.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"Java：应用启动脚本","slug":"JVM/Java：应用启动脚本","date":"2024-08-27T08:10:51.500Z","updated":"2024-11-15T09:31:46.921Z","comments":true,"path":"2024/08/27/JVM/Java：应用启动脚本/","permalink":"https://andy-whb-cn.github.io/2024/08/27/JVM/Java%EF%BC%9A%E5%BA%94%E7%94%A8%E5%90%AF%E5%8A%A8%E8%84%9A%E6%9C%AC/","excerpt":"","text":"常见的Java应用启停脚本reboot_jar_shell.sh 123456789101112131415161718#!/bin/shbootClassPath=$*appName=$1echo &quot;==========================&quot;echo &quot;stop $&#123;appName&#125;&quot;PID=`ps axu | grep java | grep &quot;$&#123;appName&#125;&quot; |grep -v grep| awk &#x27;&#123;printf $2&#125;&#x27;`if [ -n &quot;$&#123;PID&#125;&quot; ]; then echo &quot;kill process $&#123;PID&#125;&quot; kill -9 $&#123;PID&#125;fiecho &quot;$&#123;appName&#125; stopped&quot;echo &quot;start $&#123;appName&#125;&quot;echo &quot;boot classpath: $&#123;bootClassPath&#125;&quot;nohup java server $bootClassPath &gt;nohup.log 2&gt;&amp;1 &amp;echo &quot;$appName started&quot;echo &quot;==========================&quot; restart.sh 123456#!/bin/shecho &quot;--------xxx 开始启动--------------&quot; sh reboot_jar_shell.sh -DappName=xxx -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/data/xxxx/logs -Djava.io.tmpdir=/data/tmp/xxxx -Xbootclasspath/a:/data/xxxx/config -Dspring.profiles.active=&lt;env&gt; -Dfile.encoding=utf-8 -jar xxx.jar sleep 10echo &quot;--------xxx 启动成功--------------&quot; JVM heap参数设置建议：1、JVM默认会根据运行机器的配置情况自动设置heap大小；2、尽可能通过选择GC算法调优，而不是调整heap大小，除非应用需要的heap大小超过了默认值；3、通常情况下，heap大小设置可以参考Full GC后老年代存活对象大小的3-4倍；4、如果明确知道应用需要用到的heap大小，可以将Xms和Xmx设置为相同值，避免heap resize，会让GC更高效。相关建议来源参考书籍《Java Performance, 2nd Edition》 by Scott Oaks GC日志打印：-XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCApplicationStoppedTime -Xloggc:gc.log Jvm优化这块主要不是谈如何优化，jvm优化是一个需要场景化的，没有什么太多特定参数，一般来说在server端运行都会指定如下参数 初始内存和最大内存基本会设置成一样的，具体大小根据场景设置，-server是一个必须要用的参数，至于收集器这些使用默认的就可以了，除非有特定需求。 1.使用-server模式设置JVM使用server模式。64位JDK默认启动该模式 java -server -jar springboot-1.0.jar 2.指定堆参数这个根据服务器的内存大小，来设置堆参数。 -Xms :设置Java堆栈的初始化大小 -Xmx :设置最大的java堆大小 java -server -Xms512m -Xmx768m -jar springboot-1.0.jar 设置初始化堆内存为512MB，最大为768MB。 3.远程Debug在服务器上将启动参数修改为： 1java -Djavax.net.debug=ssl -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8888 -jar springboot-1.0.jar 这个时候服务端远程Debug模式开启，端口号为8888。 在IDEA中，点击Edit Configuration按钮。 出现弹窗，点击+按钮，找到Remote选项。 在【1】中填入Remote项目名称，在【2】中填IP地址和端口号，在【3】选择远程调试的项目module，配置完成后点击OK即可 如果碰到连接超时的情况，很有可能服务器的防火墙的问题，举例CentOs7,关闭防火墙 1systemctl stop firewalld.service #停止firewall systemctl disable firewalld.service #禁止firewall开机启动 点击debug按钮，IDEA控制台打印信息： 说明远程调试成功。 JVM工具远程连接jconsole与Jvisualvm远程连接通常我们的web服务都输部署在服务器上的，在window使用jconsole是很方便的，相对于Linux就有一些麻烦了，需要进行一些设置。 1.查看hostname,首先使用hostname -i 查看，服务器的hostname为127.0.0.1，这个是不对的，需要进行修改 2.修改hostname修改&#x2F;etc&#x2F;hosts文件，将其第一行的“127.0.0.1 localhost.localdomain localhost”，修改为：“192.168.44.128 localhost.localdomain localhost”.“192.168.44.128”为实际的服务器的IP 3.重启Linux，在服务器上输入hostname -i，查看实际设置的IP地址是否为你设置的 4.启动服务，参数为：java -jar -Djava.rmi.server.hostname=192.168.44.128 - Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=911 - Dcom.sun.management.jmxremote.ssl=false - Dcom.sun.management.jmxremote.authenticate=false jantent-1.0-SNAPSHOT.jar ip为192.168.44.128，端口为911 。 5.打开Jconsole，进行远程连接,输入IP和端口即可点击连接，经过稍稍等待之后，即可完成连接，如下图所示： 同理，JvisualVm的远程连接是同样的，启动参数也是一样。 然后在本机JvisualVm输入IP：PORT，即可进行远程连接：如下图所示： 相比较Jvisualvm功能更加强大一下，界面也更美观。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://andy-whb-cn.github.io/tags/Java/"},{"name":"脚本","slug":"脚本","permalink":"https://andy-whb-cn.github.io/tags/%E8%84%9A%E6%9C%AC/"}]},{"title":"SpringBoot对象复制","slug":"SpringBoot/SpringBoot：对象复制","date":"2024-08-22T08:33:34.000Z","updated":"2024-09-04T00:50:59.425Z","comments":true,"path":"2024/08/22/SpringBoot/SpringBoot：对象复制/","permalink":"https://andy-whb-cn.github.io/2024/08/22/SpringBoot/SpringBoot%EF%BC%9A%E5%AF%B9%E8%B1%A1%E5%A4%8D%E5%88%B6/","excerpt":"","text":"今天带来SpringBoot老鸟系列的第四篇，来聊聊在日常开发中如何优雅的实现对象复制。 首先我们看看为什么需要对象复制？ 为什么需要对象复制 如上，是我们平时开发中最常见的三层MVC架构模型，编辑操作时Controller层接收到前端传来的DTO对象，在Service层需要将DTO转换成DO，然后在数据库中保存。查询操作时Service层查询到DO对象后需要将DO对象转换成VO对象，然后通过Controller层返回给前端进行渲染。 这中间会涉及到大量的对象转换，很明显我们不能直接使用getter/setter复制对象属性，这看上去太low了。想象一下你业务逻辑中充斥着大量的getter&amp;setter，代码评审时老鸟们会如何笑话你？ 所以我们必须要找一个第三方工具来帮我们实现对象转换。 看到这里有同学可能会问，为什么不能前后端都统一使用DO对象呢？这样就不存在对象转换呀？ 设想一下如果我们不想定义 DTO 和 VO，直接将 DO 用到数据访问层、服务层、控制层和外部访问接口上。此时该表删除或则修改一个字段，DO 必须同步修改，这种修改将会影响到各层，这并不符合高内聚低耦合的原则。通过定义不同的 DTO 可以控制对不同系统暴露不同的属性，通过属性映射还可以实现具体的字段名称的隐藏。不同业务使用不同的模型，当一个业务发生变更需要修改字段时，不需要考虑对其它业务的影响，如果使用同一个对象则可能因为 “不敢乱改” 而产生很多不优雅的兼容性行为。 对象复制工具类推荐对象复制的类库工具有很多，除了常见的Apache的BeanUtils，Spring的BeanUtils，Cglib BeanCopier，还有重量级组件MapStruct，Orika，Dozer，ModelMapper等。 如果没有特殊要求，这些工具类都可以直接使用，除了Apache的BeanUtils。原因在于Apache BeanUtils底层源码为了追求完美，加了过多的包装，使用了很多反射，做了很多校验，所以导致性能较差，并在阿里巴巴开发手册上强制规定避免使用 Apache BeanUtils。 强制规定避免使用 Apache BeanUtils 至于剩下的重量级组件，综合考虑其性能还有使用的易用性，我这里更推荐使用Orika。Orika底层采用了javassist类库生成Bean映射的字节码，之后直接加载执行生成的字节码文件，在速度上比使用反射进行赋值会快很多。 国外大神 baeldung 已经对常见的组件性能进行过详细测试，大家可以通过 https://www.baeldung.com/java-performance-mapping-frameworks 查看。 Orika基本使用要使用Orika很简单，只需要简单四步： 引入依赖 12345&lt;dependency&gt; &lt;groupId&gt;ma.glasnost.orika&lt;/groupId&gt; &lt;artifactId&gt;orika-core&lt;/artifactId&gt; &lt;version&gt;1.5.4&lt;/version&gt;&lt;/dependency&gt; 构造一个MapperFactory 1MapperFactory mapperFactory = new DefaultMapperFactory.Builder().build(); 注册字段映射 12345mapperFactory.classMap(SourceClass.class, TargetClass.class) .field(&quot;firstName&quot;, &quot;givenName&quot;) .field(&quot;lastName&quot;, &quot;sirName&quot;) .byDefault() .register(); 当字段名在两个实体不一致时可以通过.field()方法进行映射，如果字段名都一样则可省略，byDefault()方法用于注册名称相同的属性，如果不希望某个字段参与映射，可以使用exclude方法。 进行映射12345MapperFacade mapper = mapperFactory.getMapperFacade();SourceClass source = new SourceClass(); // set some field values...// map the fields of &#x27;source&#x27; onto a new instance of PersonDestTargetClass target = mapper.map(source, TargetClass.class); 经过上面四步我们就完成了SourceClass到TargetClass的转换。至于Orika的其他使用方法大家可以参考 http://orika-mapper.github.io/orika-docs/index.html 看到这里，肯定有粉丝会说：你这推荐的啥玩意呀，这个Orika使用也不简单呀，每次都要这先创建MapperFactory，建立字段映射关系，才能进行映射转换。 别急，我这里给你准备了一个工具类OrikaUtils，你可以通过文末github仓库获取。 它提供了五个公共方法： 分别对应： 字段一致实体转换 字段不一致实体转换（需要字段映射） 字段一致集合转换 字段不一致集合转换（需要字段映射） 字段属性转换注册 接下来我们通过单元测试案例重点介绍此工具类的使用。 Orika工具类使用文档先准备两个基础实体类，Student，Teacher。 1234567@Data@AllArgsConstructor@NoArgsConstructorpublic class Student &#123; private String id; private String name; private String email;&#125; 12345678@Data@AllArgsConstructor@NoArgsConstructorpublic class Teacher &#123; private String id; private String name; private String emailAddress;&#125; TC1，基础实体映射12345678/** * 只拷贝相同的属性 */@Testpublic void convertObject()&#123; Student student = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); Teacher teacher = OrikaUtils.convert(student, Teacher.class); System.out.println(teacher);&#125; 输出结果： 1Teacher(id=1, name=javadaily, emailAddress=null) 此时由于属性名不一致，无法映射字段email。 TC2，实体映射 - 字段转换123456789/** * 拷贝不同属性 */@Testpublic void convertRefObject()&#123; Student student = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(1); //map key 放置 源属性，value 放置 目标属性 refMap.put(&quot;email&quot;,&quot;emailAddress&quot;); Teacher teacher = OrikaUtils.convert(student, Teacher.class, refMap); System.out.println(teacher);&#125; 输出结果： 1Teacher(id=1, name=javadaily, emailAddress=jianzh5@163.com) 此时由于对字段做了映射，可以将email映射到emailAddress。注意这里的refMap中key放置的是源实体的属性，而value放置的是目标实体的属性，不要弄反了。 TC3，基础集合映射123456789/** * 只拷贝相同的属性集合 */@Testpublic void convertList()&#123; Student student1 = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); Student student2 = new Student(&quot;2&quot;,&quot;JAVA日知录&quot;,&quot;jianzh5@xxx.com&quot;); List&lt;Student&gt; studentList = Lists.newArrayList(student1,student2); List&lt;Teacher&gt; teacherList = OrikaUtils.convertList(studentList, Teacher.class); System.out.println(teacherList);&#125; 输出结果： 1[Teacher(id=1, name=javadaily, emailAddress=null), Teacher(id=2, name=JAVA日知录, emailAddress=null)] 此时由于属性名不一致，集合中无法映射字段email。 TC4，集合映射 - 字段映射1234567891011/** * 映射不同属性的集合 */@Testpublic void convertRefList()&#123; Student student1 = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); Student student2 = new Student(&quot;2&quot;,&quot;JAVA日知录&quot;,&quot;jianzh5@xxx.com&quot;); List&lt;Student&gt; studentList = Lists.newArrayList(student1,student2); Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(2); //map key 放置 源属性，value 放置 目标属性 refMap.put(&quot;email&quot;,&quot;emailAddress&quot;); List&lt;Teacher&gt; teacherList = OrikaUtils.convertList(studentList, Teacher.class,refMap); System.out.println(teacherList);&#125; 输出结果： 1[Teacher(id=1, name=javadaily, emailAddress=jianzh5@163.com), Teacher(id=2, name=JAVA日知录, emailAddress=jianzh5@xxx.com)] 也可以通过这样映射： 123Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(2);refMap.put(&quot;email&quot;,&quot;emailAddress&quot;);List&lt;Teacher&gt; teacherList = OrikaUtils.classMap(Student.class,Teacher.class,refMap).mapAsList(studentList,Teacher.class); TC5，集合与实体映射有时候我们需要将集合数据映射到实体中，如Person类 12@Datapublic class Person &#123; private List&lt;String&gt; nameParts;&#125; 现在需要将Person类nameParts的值映射到Student中，可以这样做 123456789101112/** * 数组和List的映射 */@Testpublic void convertListObject()&#123; Person person = new Person(); person.setNameParts(Lists.newArrayList(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;)); Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(2); //map key 放置 源属性，value 放置 目标属性 refMap.put(&quot;nameParts[0]&quot;,&quot;id&quot;); refMap.put(&quot;nameParts[1]&quot;,&quot;name&quot;); refMap.put(&quot;nameParts[2]&quot;,&quot;email&quot;); Student student = OrikaUtils.convert(person, Student.class,refMap); System.out.println(student);&#125; 输出结果： 1Student(id=1, name=javadaily, email=jianzh5@163.com) TC6，类类型映射有时候我们需要类类型对象映射，如BasicPerson类 12@Datapublic class BasicPerson &#123; private Student student;&#125; 现在需要将BasicPerson映射到Teacher 12345678910111213/** * 类类型映射 */@Testpublic void convertClassObject()&#123; BasicPerson basicPerson = new BasicPerson(); Student student = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); basicPerson.setStudent(student); Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(2); //map key 放置 源属性，value 放置 目标属性 refMap.put(&quot;student.id&quot;,&quot;id&quot;); refMap.put(&quot;student.name&quot;,&quot;name&quot;); refMap.put(&quot;student.email&quot;,&quot;emailAddress&quot;); Teacher teacher = OrikaUtils.convert(basicPerson, Teacher.class,refMap); System.out.println(teacher);&#125; 输出结果： 1Teacher(id=1, name=javadaily, emailAddress=jianzh5@163.com) TC7，多重映射有时候我们会遇到多重映射，如将StudentGrade映射到TeacherGrade 1234@Datapublic class StudentGrade &#123; private String studentGradeName; private List&lt;Student&gt; studentList;&#125;@Datapublic class TeacherGrade &#123; private String teacherGradeName; private List&lt;Teacher&gt; teacherList;&#125; 这种场景稍微复杂，Student与Teacher的属性有email字段不相同，需要做转换映射；StudentGrade与TeacherGrade中的属性也需要映射。 1234567891011121314151617181920/** * 一对多映射 */@Testpublic void convertComplexObject()&#123; Student student1 = new Student(&quot;1&quot;,&quot;javadaily&quot;,&quot;jianzh5@163.com&quot;); Student student2 = new Student(&quot;2&quot;,&quot;JAVA日知录&quot;,&quot;jianzh5@xxx.com&quot;); List&lt;Student&gt; studentList = Lists.newArrayList(student1,student2); StudentGrade studentGrade = new StudentGrade(); studentGrade.setStudentGradeName(&quot;硕士&quot;); studentGrade.setStudentList(studentList); Map&lt;String,String&gt; refMap1 = new HashMap&lt;&gt;(1); //map key 放置 源属性，value 放置 目标属性 refMap1.put(&quot;email&quot;,&quot;emailAddress&quot;); OrikaUtils.register(Student.class,Teacher.class,refMap1); Map&lt;String,String&gt; refMap2 = new HashMap&lt;&gt;(2); //map key 放置 源属性，value 放置 目标属性 refMap2.put(&quot;studentGradeName&quot;, &quot;teacherGradeName&quot;); refMap2.put(&quot;studentList&quot;, &quot;teacherList&quot;); TeacherGrade teacherGrade = OrikaUtils.convert(studentGrade,TeacherGrade.class,refMap2); System.out.println(teacherGrade);&#125; 多重映射的场景需要根据情况调用OrikaUtils.register()注册字段映射。 输出结果： 1TeacherGrade(teacherGradeName=硕士, teacherList=[Teacher(id=1, name=javadaily, emailAddress=jianzh5@163.com), Teacher(id=2, name=JAVA日知录, emailAddress=jianzh5@xxx.com)]) TC8，MyBaits plus分页映射如果你使用的是mybatis的分页组件，可以这样转换 1234567891011121314public IPage&lt;UserDTO&gt; selectPage(UserDTO userDTO, Integer pageNo, Integer pageSize) &#123; Page page = new Page&lt;&gt;(pageNo, pageSize); LambdaQueryWrapper&lt;User&gt; query = new LambdaQueryWrapper(); if (StringUtils.isNotBlank(userDTO.getName())) &#123; query.like(User::getKindName,userDTO.getName()); &#125; IPage&lt;User&gt; pageList = page(page,query); // 实体转换 SysKind转化为SysKindDto Map&lt;String,String&gt; refMap = new HashMap&lt;&gt;(3); refMap.put(&quot;kindName&quot;,&quot;name&quot;); refMap.put(&quot;createBy&quot;,&quot;createUserName&quot;); refMap.put(&quot;createTime&quot;,&quot;createDate&quot;); return pageList.convert(item &gt; OrikaUtils.convert(item, UserDTO.class, refMap));&#125; 小结在MVC架构中肯定少不了需要用到对象复制，属性转换的功能，借用Orika组件，可以很简单实现这些功能。本文在Orika的基础上封装了工具类，进一步简化了Orika的操作，希望对各位有所帮助。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"}]},{"title":"前端版本更新检测","slug":"前端/前端：版本更新检测","date":"2024-08-22T08:33:34.000Z","updated":"2024-09-03T00:47:17.267Z","comments":true,"path":"2024/08/22/前端/前端：版本更新检测/","permalink":"https://andy-whb-cn.github.io/2024/08/22/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF%EF%BC%9A%E7%89%88%E6%9C%AC%E6%9B%B4%E6%96%B0%E6%A3%80%E6%B5%8B/","excerpt":"","text":"前端版本更新检测方案采用Etag比较https://blog.csdn.net/qq_38951259/article/details/136739490 采用前后端Version比较1、后台提供轻量级version api；2、前端页面初始化或定时，比较本地version和服务端version是否有变更，设置local vesion变更变量；3、前端在进入router前，判断有local vesion变更变量，刷新本地缓存并删除local vesion变更变量； 引申：为避免频繁去请求后台的version，可以考虑按时间戳（每日）去检查远端version更新。","categories":[],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://andy-whb-cn.github.io/tags/Vue/"},{"name":"前端","slug":"前端","permalink":"https://andy-whb-cn.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Flink 处理复杂的Json格式","slug":"大数据/大数据：Flink-Nested-Json","date":"2024-08-22T08:33:34.000Z","updated":"2024-09-03T00:49:05.032Z","comments":true,"path":"2024/08/22/大数据/大数据：Flink-Nested-Json/","permalink":"https://andy-whb-cn.github.io/2024/08/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%EF%BC%9AFlink-Nested-Json/","excerpt":"","text":"Flink 复杂Json格式处理Flink 官方文档：https://nightlies.apache.org/flink/flink-docs-release-1.20/zh/docs/connectors/table/formats/json/ Flink 对于单层Json的处理，可以支持直接转换，但对于复杂的嵌套Json则需要在类型定义上做一些处理。 以下是结合ROW、ARRAY、MAP的简单示例介绍（原文： https://blog.csdn.net/m0_67400972/article/details/123923656 ） 123456789101112131415161718192021222324252627282930&#123; &quot;id&quot;:1238123899121, &quot;name&quot;:&quot;asdlkjasjkdla998y1122&quot;, &quot;date&quot;:&quot;1990-10-14&quot;, &quot;obj&quot;:&#123; &quot;time1&quot;:&quot;12:12:43Z&quot;, &quot;str&quot;:&quot;sfasfafs&quot;, &quot;lg&quot;:2324342345 &#125;, &quot;arr&quot;:[ &#123; &quot;f1&quot;:&quot;f1str11&quot;, &quot;f2&quot;:134 &#125;, &#123; &quot;f1&quot;:&quot;f1str22&quot;, &quot;f2&quot;:555 &#125; ], &quot;time&quot;:&quot;12:12:43Z&quot;, &quot;timestamp&quot;:&quot;1990-10-14T12:12:43Z&quot;, &quot;map&quot;:&#123; &quot;flink&quot;:123 &#125;, &quot;mapinmap&quot;:&#123; &quot;inner_map&quot;:&#123; &quot;key&quot;:234 &#125; &#125;&#125; 123456789101112131415161718192021CREATE TABLE json_source ( id BIGINT, name STRING, `date` DATE, obj ROW&lt;time1 TIME,str STRING,lg BIGINT&gt;, arr ARRAY&lt;ROW&lt;f1 STRING,f2 INT&gt;&gt;, `time` TIME, `timestamp` TIMESTAMP(3), `map` MAP&lt;STRING,BIGINT&gt;, mapinmap MAP&lt;STRING,MAP&lt;STRING,INT&gt;&gt;, proctime as PROCTIME() ) WITH ( &#x27;connector.type&#x27; = &#x27;kafka&#x27;, &#x27;connector.topic&#x27; = &#x27;test&#x27;, &#x27;connector.properties.zookeeper.connect&#x27; = &#x27;localhost:2181&#x27;, &#x27;connector.properties.bootstrap.servers&#x27; = &#x27;localhost:9092&#x27;, &#x27;connector.properties.group.id&#x27; = &#x27;testGroup&#x27;, &#x27;connector.version&#x27;=&#x27;universal&#x27;, &#x27;format.type&#x27; = &#x27;json&#x27;, &#x27;connector.startup-mode&#x27;=&#x27;latest-offset&#x27; ); 12345-- 构造insert into json_source select 111 as id,&#x27;name&#x27; as name,Row(CURRENT_TIME,&#x27;ss&#x27;,123) as obj,Array[Row(&#x27;f&#x27;,1),Row(&#x27;s&#x27;,2)] as arr,Map[&#x27;k1&#x27;,&#x27;v1&#x27;,&#x27;k2&#x27;,&#x27;v2&#x27;] as `map`,Map[&#x27;inner_map&#x27;,Map[&#x27;k&#x27;,&#x27;v&#x27;]] as mapinmap;-- 获取，注意数组index从1开始select id, name,`date`,obj.str,arr[1].f1,`map`[&#x27;flink&#x27;],mapinmap[&#x27;inner_map&#x27;][&#x27;key&#x27;] from json_source;","categories":[],"tags":[{"name":"Flink","slug":"Flink","permalink":"https://andy-whb-cn.github.io/tags/Flink/"}]},{"title":"面向接口：防篡改&防重放","slug":"接口设计/面向接口：防篡改&防重放","date":"2024-08-22T08:33:34.000Z","updated":"2024-09-03T00:44:41.798Z","comments":true,"path":"2024/08/22/接口设计/面向接口：防篡改&防重放/","permalink":"https://andy-whb-cn.github.io/2024/08/22/%E6%8E%A5%E5%8F%A3%E8%AE%BE%E8%AE%A1/%E9%9D%A2%E5%90%91%E6%8E%A5%E5%8F%A3%EF%BC%9A%E9%98%B2%E7%AF%A1%E6%94%B9&%E9%98%B2%E9%87%8D%E6%94%BE/","excerpt":"","text":"对于互联网来说，只要你系统的接口暴露在外网，就避免不了接口安全问题。如果你的接口在外网裸奔，只要让黑客知道接口的地址和参数就可以调用，那简直就是灾难。 举个例子：你的网站用户注册的时候，需要填写手机号，发送手机验证码，如果这个发送验证码的接口没有经过特殊安全处理，那这个短信接口早就被人盗刷不知道浪费多少钱了。 那如何保证接口安全呢？ 一般来说，暴露在外网的api接口需要做到防篡改和防重放才能称之为安全的接口。 防篡改我们知道http 是一种无状态的协议，服务端并不知道客户端发送的请求是否合法，也并不知道请求中的参数是否正确。 举个例子, 现在有个充值的接口，调用后可以给用户增加对应的余额。 1http://localhost/api/user/recharge?user_id=1001&amp;amount=10 如果非法用户通过抓包获取到接口参数后，修改user_id 或 amount的值就可以实现给任意账户添加余额的目的。 如何解决采用https协议可以将传输的明文进行加密，但是黑客仍然可以截获传输的数据包，进一步伪造请求进行重放攻击。如果黑客使用特殊手段让请求方设备使用了伪造的证书进行通信，那么https加密的内容也会被解密。 一般的做法有2种： 采用https方式把接口的数据进行加密传输，即便是被黑客破解，黑客也花费大量的时间和精力去破解。 接口后台对接口的请求参数进行验证，防止被黑客篡改； 步骤1：客户端使用约定好的秘钥对传输的参数进行加密，得到签名值sign1，并且将签名值也放入请求的参数中，发送请求给服务端 步骤2：服务端接收到客户端的请求，然后使用约定好的秘钥对请求的参数再次进行签名，得到签名值sign2。 步骤3：服务端比对sign1和sign2的值，如果不一致，就认定为被篡改，非法请求。 防重放防重放也叫防复用。简单来说就是我获取到这个请求的信息之后什么也不改,，直接拿着接口的参数 重复请求这个充值的接口。此时我的请求是合法的, 因为所有参数都是跟合法请求一模一样的。 重放攻击会造成两种后果： 针对插入数据库接口：重放攻击，会出现大量重复数据，甚至垃圾数据会把数据库撑爆。 针对查询的接口：黑客一般是重点攻击慢查询接口，例如一个慢查询接口1s，只要黑客发起重放攻击，就必然造成系统被拖垮，数据库查询被阻塞死。 对于重放攻击一般有两种做法： 基于timestamp的方案每次HTTP请求，都需要加上timestamp参数，然后把timestamp和其他参数一起进行数字签名。因为一次正常的HTTP请求，从发出到达服务器一般都不会超过60s，所以服务器收到HTTP请求之后，首先判断时间戳参数与当前时间比较，是否超过了60s，如果超过了则认为是非法请求。 一般情况下，黑客从抓包重放请求耗时远远超过了60s，所以此时请求中的timestamp参数已经失效了。如果黑客修改timestamp参数为当前的时间戳，则sign1参数对应的数字签名就会失效，因为黑客不知道签名秘钥，没有办法生成新的数字签名。 但是这种方式的漏洞也是显而易见，如果在60s之内进行重放攻击，那就没办法了，所以这种方式不能保证请求仅一次有效。 老鸟们一般会采取下面这种方案，既可以解决接口重放问题，又可以解决接口一次请求有效的问题。 基于nonce + timestamp 的方案nonce的意思是仅一次有效的随机字符串，要求每次请求时该参数要保证不同。实际使用用户信息+时间戳+随机数等信息做个哈希之后，作为nonce参数。 此时服务端的处理流程如下： 去 redis 中查找是否有 key 为 nonce:&#123;nonce&#125; 的 string 如果没有，则创建这个 key，把这个 key 失效的时间和验证 timestamp 失效的时间一致，比如是 60s。 如果有，说明这个 key 在 60s 内已经被使用了，那么这个请求就可以判断为重放请求。 这种方案nonce和timestamp参数都作为签名的一部分传到后端，基于timestamp方案可以让黑客只能在60s内进行重放攻击，加上nonce随机数以后可以保证接口只能被调用一次，可以很好的解决重放攻击问题。 代码实现接下来通过实际代码来看看如何实现接口的防篡改和防重放。 1、构建请求头对象1@Data@Builderpublic class RequestHeader &#123; private String sign ; private Long timestamp ; private String nonce;&#125; 2、工具类从HttpServletRequest获取请求参数1@Slf4j@UtilityClasspublic class HttpDataUtil &#123; /** * post请求处理：获取 Body 参数，转换为SortedMap * * @param request */ public SortedMap&lt;String, String&gt; getBodyParams(final HttpServletRequest request) throws IOException &#123; byte[] requestBody = StreamUtils.copyToByteArray(request.getInputStream()); String body = new String(requestBody); return JsonUtil.json2Object(body, SortedMap.class); &#125; /** * get请求处理：将URL请求参数转换成SortedMap */ public static SortedMap&lt;String, String&gt; getUrlParams(HttpServletRequest request) &#123; String param = &quot;&quot;; SortedMap&lt;String, String&gt; result = new TreeMap&lt;&gt;(); if (StringUtils.isEmpty(request.getQueryString())) &#123; return result; &#125; try &#123; param = URLDecoder.decode(request.getQueryString(), &quot;utf-8&quot;); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; String[] params = param.split(&quot;&amp;&quot;); for (String s : params) &#123; String[] array=s.split(&quot;=&quot;); result.put(array[0], array[1]); &#125; return result; &#125;&#125; 这里的参数放入SortedMap中对其进行字典排序，前端构建签名时同样需要对参数进行字典排序。 3、签名验证工具类1@Slf4j@UtilityClasspublic class SignUtil &#123; /** * 验证签名 * 验证算法：把timestamp + JsonUtil.object2Json(SortedMap)合成字符串，然后MD5 */ @SneakyThrows public boolean verifySign(SortedMap&lt;String, String&gt; map, RequestHeader requestHeader) &#123; String params = requestHeader.getNonce() + requestHeader.getTimestamp() + JsonUtil.object2Json(map); return verifySign(params, requestHeader); &#125; /** * 验证签名 */ public boolean verifySign(String params, RequestHeader requestHeader) &#123; log.debug(&quot;客户端签名: &#123;&#125;&quot;, requestHeader.getSign()); if (StringUtils.isEmpty(params)) &#123; return false; &#125; log.info(&quot;客户端上传内容: &#123;&#125;&quot;, params); String paramsSign = DigestUtils.md5DigestAsHex(params.getBytes()).toUpperCase(); log.info(&quot;客户端上传内容加密后的签名结果: &#123;&#125;&quot;, paramsSign); return requestHeader.getSign().equals(paramsSign); &#125;&#125; 4、HttpServletRequest包装类1public class SignRequestWrapper extends HttpServletRequestWrapper &#123; //用于将流保存下来 private byte[] requestBody = null; public SignRequestWrapper(HttpServletRequest request) throws IOException &#123; super(request); requestBody = StreamUtils.copyToByteArray(request.getInputStream()); &#125; @Override public ServletInputStream getInputStream() throws IOException &#123; final ByteArrayInputStream bais = new ByteArrayInputStream(requestBody); return new ServletInputStream() &#123; @Override public boolean isFinished() &#123; return false; &#125; @Override public boolean isReady() &#123; return false; &#125; @Override public void setReadListener(ReadListener readListener) &#123; &#125; @Override public int read() throws IOException &#123; return bais.read(); &#125; &#125;; &#125; @Override public BufferedReader getReader() throws IOException &#123; return new BufferedReader(new InputStreamReader(getInputStream())); &#125;&#125; 防篡改和防重放我们会通过SpringBoot Filter来实现，而编写的filter过滤器需要读取request数据流，但是request数据流只能读取一次，需要自己实现HttpServletRequestWrapper对数据流包装，目的是将request流保存下来。 5、创建过滤器实现安全校验1@Configurationpublic class SignFilterConfiguration &#123; @Value(&quot;$&#123;sign.maxTime&#125;&quot;) private String signMaxTime; //filter中的初始化参数 private Map&lt;String, String&gt; initParametersMap = new HashMap&lt;&gt;(); @Bean public FilterRegistrationBean contextFilterRegistrationBean() &#123; initParametersMap.put(&quot;signMaxTime&quot;,signMaxTime); FilterRegistrationBean registration = new FilterRegistrationBean(); registration.setFilter(signFilter()); registration.setInitParameters(initParametersMap); registration.addUrlPatterns(&quot;/sign/*&quot;); registration.setName(&quot;SignFilter&quot;); // 设置过滤器被调用的顺序 registration.setOrder(1); return registration; &#125; @Bean public Filter signFilter() &#123; return new SignFilter(); &#125;&#125; 1@Slf4jpublic class SignFilter implements Filter &#123; @Resource private RedisUtil redisUtil; //从fitler配置中获取sign过期时间 private Long signMaxTime; private static final String NONCE_KEY = &quot;x-nonce-&quot;; @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; HttpServletRequest httpRequest = (HttpServletRequest) servletRequest; HttpServletResponse httpResponse = (HttpServletResponse) servletResponse; log.info(&quot;过滤URL:&#123;&#125;&quot;, httpRequest.getRequestURI()); HttpServletRequestWrapper requestWrapper = new SignRequestWrapper(httpRequest); //构建请求头 RequestHeader requestHeader = RequestHeader.builder() .nonce(httpRequest.getHeader(&quot;x-Nonce&quot;)) .timestamp(Long.parseLong(httpRequest.getHeader(&quot;X-Time&quot;))) .sign(httpRequest.getHeader(&quot;X-Sign&quot;)) .build(); //验证请求头是否存在 if(StringUtils.isEmpty(requestHeader.getSign()) || ObjectUtils.isEmpty(requestHeader.getTimestamp()) || StringUtils.isEmpty(requestHeader.getNonce()))&#123; responseFail(httpResponse, ReturnCode.ILLEGAL_HEADER); return; &#125; /* * 1.重放验证 * 判断timestamp时间戳与当前时间是否操过60s（过期时间根据业务情况设置）,如果超过了就提示签名过期。 */ long now = System.currentTimeMillis() / 1000; if (now - requestHeader.getTimestamp() &gt; signMaxTime) &#123; responseFail(httpResponse,ReturnCode.REPLAY_ERROR); return; &#125; //2. 判断nonce boolean nonceExists = redisUtil.hasKey(NONCE_KEY + requestHeader.getNonce()); if(nonceExists)&#123; //请求重复 responseFail(httpResponse,ReturnCode.REPLAY_ERROR); return; &#125;else &#123; redisUtil.set(NONCE_KEY+requestHeader.getNonce(), requestHeader.getNonce(), signMaxTime); &#125; boolean accept; SortedMap&lt;String, String&gt; paramMap; switch (httpRequest.getMethod())&#123; case &quot;GET&quot;: paramMap = HttpDataUtil.getUrlParams(requestWrapper); accept = SignUtil.verifySign(paramMap, requestHeader); break; case &quot;POST&quot;: paramMap = HttpDataUtil.getBodyParams(requestWrapper); accept = SignUtil.verifySign(paramMap, requestHeader); break; default: accept = true; break; &#125; if (accept) &#123; filterChain.doFilter(requestWrapper, servletResponse); &#125; else &#123; responseFail(httpResponse,ReturnCode.ARGUMENT_ERROR); return; &#125; &#125; private void responseFail(HttpServletResponse httpResponse, ReturnCode returnCode) &#123; ResultData&lt;Object&gt; resultData = ResultData.fail(returnCode.getCode(), returnCode.getMessage()); WebUtils.writeJson(httpResponse,resultData); &#125; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; String signTime = filterConfig.getInitParameter(&quot;signMaxTime&quot;); signMaxTime = Long.parseLong(signTime); &#125;&#125; 6、Redis工具类1@Componentpublic class RedisUtil &#123; @Resource private RedisTemplate&lt;String, Object&gt; redisTemplate; /** * 判断key是否存在 * @param key 键 * @return true 存在 false不存在 */ public boolean hasKey(String key) &#123; try &#123; return Boolean.TRUE.equals(redisTemplate.hasKey(key)); &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 普通缓存放入并设置时间 * @param key 键 * @param value 值 * @param time 时间(秒) time要大于0 如果time小于等于0 将设置无限期 * @return true成功 false 失败 */ public boolean set(String key, Object value, long time) &#123; try &#123; if (time &gt; 0) &#123; redisTemplate.opsForValue().set(key, value, time, TimeUnit.SECONDS); &#125; else &#123; set(key, value); &#125; return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125; /** * 普通缓存放入 * @param key 键 * @param value 值 * @return true成功 false失败 */ public boolean set(String key, Object value) &#123; try &#123; redisTemplate.opsForValue().set(key, value); return true; &#125; catch (Exception e) &#123; e.printStackTrace(); return false; &#125; &#125;&#125;","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"接口","slug":"接口","permalink":"https://andy-whb-cn.github.io/tags/%E6%8E%A5%E5%8F%A3/"}]},{"title":"微服务方案设计","slug":"架构设计/微服务方案设计","date":"2024-08-22T08:33:34.000Z","updated":"2024-09-23T02:22:10.985Z","comments":true,"path":"2024/08/22/架构设计/微服务方案设计/","permalink":"https://andy-whb-cn.github.io/2024/08/22/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1/","excerpt":"","text":"微服务API网关模式链接：https://microservices.io/patterns/apigateway.html 微服务项目的目录结构设计通常需要和微服务设计模式相结合。不同的设计模式下的项目结构侧重点会有所不同。1、典型分库模式下的目录结构，每个微服务都有完整独立的库和功能，可以独立部署运行。 12345678910111213#示例| - micro-service-1| - - biz-common| - - biz-dao| - - biz-service| - - biz-api| - - biz-starter| - micro-service-2| - - biz-common| - - biz-dao| - - biz-service| - - biz-api| - - biz-starter 2、共库模式下的目录结构，Manage Service和DAO层共用，微服务可定制化API，独立部署运行。有很多共库模式的目录结构未必完全按照如下示例划分，但实质理念是一致的。 123456789101112131415# 示例| - common-provider| - - biz-common| - - biz-dao| - - biz-manage-service| - micro-service-1| - - biz-common| - - biz-service| - - biz-api| - - biz-starter| - micro-service-2| - - biz-common| - - biz-service| - - biz-api| - - biz-starter","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"微服务","slug":"微服务","permalink":"https://andy-whb-cn.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"java","slug":"java","permalink":"https://andy-whb-cn.github.io/tags/java/"}]},{"title":"安全框架 Spring Security vs Shiro","slug":"认证鉴权/Spring Security vs Shiro","date":"2024-08-22T08:33:34.000Z","updated":"2024-11-21T14:26:46.012Z","comments":true,"path":"2024/08/22/认证鉴权/Spring Security vs Shiro/","permalink":"https://andy-whb-cn.github.io/2024/08/22/%E8%AE%A4%E8%AF%81%E9%89%B4%E6%9D%83/Spring%20Security%20vs%20Shiro/","excerpt":"","text":"目前在java web应用安全框架中，比较常用的是Spring Security和Shiro框架, 二者在核心功能上几乎差不多，从使用的角度各有优缺点。从使用量上来说，Shiro要高于 Spring Security， Shiro的入门也相对比较容易。但Spring Security依托于Spring社区的支持，对于和Spring系列框架的集成有更好的融合型和兼容性。 相同点：1、认证功能2、授权功能3、加密功能4、会话管理5、缓存支持6、rememberMe功能 ShiroShiro四大核心功能:Authentication,Authorization,Cryptography,Session Management Shiro三个核心组件：Subject, SecurityManager 和 Realms.Subject：主体，可以是任何可以与应用交互的 “用户”；SecurityManager：相当于 SpringMVC 中的 DispatcherServlet, 是 Shiro 的心脏；所有具体的交互都通过 SecurityManager 进行控制；它管理着所有 Subject、且负责进行认证和授权、及会话、缓存的管理。Realm：域，Shiro从Realm获取安全数据（如用户、角色、权限），就是说SecurityManager要验证用户身份，那么它需要从Realm获取相应的用户进行比较以确定用户身份是否合法；也需要从Realm得到用户相应的角色&#x2F;权限进行验证用户是否能进行操作；可以把Realm看成DataSource，即安全数据源。 除前文所讲Subject、SecurityManager 、Realm三个核心组件外，Shiro主要组件还包括： Authenticator: 认证就是核实用户身份的过程。这个过程的常见例子是大家都熟悉的“用户&#x2F;密码”组合。多数用户在登录软件系统时，通常提供自己的用户名（当事人）和支持他们的密码（证书）。如果存储在系统中的密码（或密码表示）与用户提供的匹配，他们就被认为通过认证。 Authorizer ：授权实质上就是访问控制 - 控制用户能够访问应用中的哪些内容，比如资源、Web页面等等。SessionManager ：在安全框架领域，Apache Shiro提供了一些独特的东西：可在任何应用或架构层一致地使用Session API。即，Shiro为任何应用提供了一个会话编程范式 - 从小型后台独立应用到大型集群Web应用。这意味着，那些希望使用会话的应用开发者，不必被迫使用Servlet或EJB容器了。或者，如果正在使用这些容器，开发者现在也可以选择使用在任何层统一一致的会话API，取代Servlet或EJB机制。 CacheManager: 对Shiro的其他组件提供缓存支持。 使用示例1、引入shiro包 12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt;&lt;/dependency&gt; 2、Shiro配置类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Configurationpublic class ShiroConfig &#123; // 配置ShiroFilter @Bean public ShiroFilterFactoryBean getShiroFilterFactoryBean(@Qualifier(&quot;securityManager&quot;) DefaultWebSecurityManager securityManager)&#123; ShiroFilterFactoryBean shiroFilterFactoryBean=new ShiroFilterFactoryBean(); //设置安全管理器 shiroFilterFactoryBean.setSecurityManager(securityManager); //添加Shiro拦截器 /** * Shiro 内置过滤器，可以实现权限相关的拦截器 * anon:无需认证（登录）可以直接访问 * authc:必须认证才能访问 * user:如果使用rememberMe的功能才可以访问 * perms:该资源得到资源权限才可以访问 * role:该资源必须得到角色权限才可以访问 */ Map&lt;String,String&gt; filterMap=new LinkedHashMap&lt;&gt;(); filterMap.put(&quot;/login&quot;,&quot;anon&quot;); //添加Shiro授权拦截器 filterMap.put(&quot;/add&quot;,&quot;perms[添加]&quot;); filterMap.put(&quot;/foresee&quot;,&quot;perms[预言未来]&quot;); filterMap.put(&quot;/update&quot;,&quot;perms[修改]&quot;); filterMap.put(&quot;/delete&quot;,&quot;perms[删除]&quot;); filterMap.put(&quot;/*&quot;,&quot;authc&quot;); //跳转到登陆的页面 shiroFilterFactoryBean.setLoginUrl(&quot;/login&quot;); //设置未授权的页面 shiroFilterFactoryBean.setUnauthorizedUrl(&quot;/unAuthorized&quot;); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterMap); return shiroFilterFactoryBean; &#125; /** * 创建DefaultWebSecurityManager */ @Bean(&quot;securityManager&quot;) public DefaultWebSecurityManager getDefaultWebSecurityManager(@Qualifier(&quot;userRealm&quot;) UserRealm userRealm)&#123; DefaultWebSecurityManager securityManager=new DefaultWebSecurityManager(); //关联Realm securityManager.setRealm(userRealm); return securityManager; &#125; /** * 创建Realm */ @Bean(&quot;userRealm&quot;) public UserRealm getRealm()&#123; UserRealm userRealm=new UserRealm(); return userRealm; &#125; /** * 配置shiroDialect,用于thymeleaf和shiro标签配合使用 */ @Bean public ShiroDialect getShiroDialect()&#123; ShiroDialect shiroDialect=new ShiroDialect(); return shiroDialect; &#125;&#125; 3、自定义Realm 123456789101112131415161718192021222324252627282930313233343536373839404142434445public class UserRealm extends AuthorizingRealm &#123; @Resource private IUserService userService; @Resource private IPermissionService permissionService; //认证 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; // 判断用户是否存在 UsernamePasswordToken usernamePasswordToken=(UsernamePasswordToken)token; User user=userService.findByname(usernamePasswordToken.getUsername()); if(user==null)&#123; //用户名不存在 return null; &#125; // 判断密码是否正确 if(user.getPassword().equals(usernamePasswordToken.getPassword()))&#123; return new SimpleAuthenticationInfo(user, user.getPassword(),&quot;&quot;); &#125; return null; &#125; //授权 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; // 获取登陆信息 Subject subject = SecurityUtils.getSubject(); User user = (User)subject.getPrincipal(); User user1=userService.findById(user.getId()); if(user1==null)&#123; //用户已经不存在 return null; &#125; //开始授权 SimpleAuthorizationInfo simpleAuthorizationInfo=new SimpleAuthorizationInfo(); List&lt;Permission&gt; permissions =permissionService.getPermissionByUserId(user1.getId()); for (Permission per : permissions) &#123; simpleAuthorizationInfo.addStringPermission(per.getName()); &#125; return simpleAuthorizationInfo; &#125;&#125; 4、接口使用 123456789101112131415@RequestMapping(&quot;/login&quot;)public String login(User user, Model model) &#123; try &#123; Subject subject = SecurityUtils.getSubject(); subject.login(new UsernamePasswordToken(user.getUsername(), user.getPassword())); model.addAttribute(user); return &quot;dashboard&quot;; &#125; catch (UnknownAccountException e) &#123; model.addAttribute(&quot;msg&quot;,&quot;用户名不存在&quot;); return &quot;login&quot;; &#125;catch (IncorrectCredentialsException e)&#123; model.addAttribute(&quot;msg&quot;,&quot;密码错误&quot;); return &quot;login&quot;; &#125;&#125; Spring SecuritySpring Security对Servlet的支持是基于Servlet Filters的。SecurityFilterAutoConfiguration会自动注册一个名为springSecurityFilterChain的DelegatingFilterProxy。请求到达 DelegatingFilterProxy触发 SecurityFilterChain_执行一系列的filter.可以看一下浏览器Http请求到达@RestController依次需要经过的Security Filter。其中需要关注的几个Filter SecurityContextHolderFilter(@Deprecated SecurityContextPersistenceFilter)：它在整个SecurityFilterChain中具有较高的优先级，当一个请求进入SecurityFilterChain的时候，需要从SecurityContextRepository加载SecurityContext实例①，并调用SecurityContextHolder对应的set方法进行保存②，以便后续其他地方获取这个SecurityContext实例，通常会保存在ThreadLocal中。 BasicAuthenticationFilter: 尝试从Basic Auth HTTP Header中获取用户名和密码进行用户身份校验。 UsernamePasswordAuthenticationFilter: 尝试从请求体或参数中获取用户名和密码进行用户身份校验。从request请求参数中获取用户名和密码并封装成UsernamePasswordAuthenticationToken①，然后交给ProviderManager#authenticate方法对其认证②，认证通过后返回AuthenticationProvider的Authentication对象③，此时SecurityContextHolderStrategy会创建出一个空载的SecurityContext实例④，并传入上述Authentication⑤，然后调用SecurityContextHolderStrategy保存⑤，最后通过SecurityContextRepository进行持久化⑦。 DefaultLoginPageGeneratingFilter: 如果不显示的关闭这个特性，默认会生成登陆页面。这就是为什么开启了Spring Security以后会有默认的登录页。 DefaultLogoutPageGeneratingFilter: 如果不显示的关闭这个特性，默认会生成登出页面。 AuthorizationFilter(@Deprecated FilterSecurityInterceptor): AuthorizationFilter主要是用来判断请求访问受保护资源时，是否符合授权条件。这时就需要获取当前用户的授权信息，先通过SecurityContext得到Authentication认证信息①，如果获取到Authentication实例为空，就表示请求并没有认证过，那么就会抛出一个AuthenticationCredentialsNotFoundException异常②，这个异常会被ExceptionTranslationFilter捕获，通常情况下，异常处理方式就是跳转到到登录页面③，让用户完成登录的操作。 核心组件接口： Authentication：顶层接口，用于保存身份认证信息，主要包括3个部分：用户标识（principal，通常为用户名），凭证（credentials，通常为密码），权限信息（authorities，通常为该用户所拥有的角色） SecurityContext：顶层接口，直译为安全上下文，内部只定义了getAuthentication和setAuthentication两个方法，概括地说，SecurityContext相当于用于装载Authentication对象的容器，在整个SecurityFilterChain中，为不同的认证机制操作Authentication对象时提供服务。 AuthenticationManager: 顶层接口，定义了“认证“方法。 AuthenticationProvider: 顶层接口，同样也定义了一个签名相同的“认证”方法，不同于AuthenticationManager的认证方法，这个才是各种认证协议的具体实现，它通常接受一个未认证的Authentication对象的参数，该对象仅包含了principal和credentials的信息，在经过认证后，会把authorities填充进来，并将状态设置为已认证。在spring security中内置了很多实现类，例如OAuth2LoginAuthenticationProvider，用于实现OAuth2.0认证协议等。当然我们也可以根据需要自定义其实现。 SecurityContextRepository：顶层接口，定义了保存和加载SecuriyContext对象的方法，常用的实现有HttpSessionSecurityContextRepository，即通过request的会话对象session，存取SecurityContext的实例。 SecurityContextHolderStrategy：顶层接口，定义了在当前请求的线程中，获取和设置SecurityContext对象等方法，在5.8版本之后，新增了两个get&#x2F;set“延迟（Deferred）”接口，主要是使用了Supplier函数式接口实现的惰性计算，不过只是性能上的考量，本质上都是用于维护SecurityContext对象的方法 类： SecurityContextHolder：它是spring security认证模型中最为常用的一个工具类，它采用策略模式封装了SecurityContextHolderStrategy接口实现，默认的策略实现为ThreadLocalSecurityContextHolderStrategy，底层使用了ThreadLocal实现对SecurityContext对象的存取，可以保证在一次请求的同一个线程中，方便地获取SecurityContext对象。 ProviderManager: AuthenticationManager的实现类，它内部维护了一个List&lt;AuthenticationProvider&gt; 成员变量，在实现AuthenticationManager#authenticate方法时，其实是遍历这个List&lt;AuthenticationProvider&gt;列表，依次判断是否支持当前Authentication对象（如OAuth2LoginAuthenticationProvider支持OAuth2LoginAuthenticationToken），如果支持，则调用AuthenticationProvider#authenticate方法，完成认证过程。 使用示例1、引入包 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 2、配置Security 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@EnableWebSecurity public class SecurityConfig &#123; @Bean public UserDetailsService inMemoryUserDetailsManager() &#123; UserDetails user = User.builder() .username(&quot;user&quot;) .password(passwordEncoder().encode(&quot;password&quot;)) .roles(&quot;USER&quot;) .build(); UserDetails admin = User.builder() .username(&quot;admin&quot;) .password(passwordEncoder().encode(&quot;password&quot;)) .roles(&quot;USER&quot;, &quot;ADMIN&quot;) .build(); return new InMemoryUserDetailsManager(user, admin); &#125; /* @Bean public UserDetailsService jdbcUserDetailsService(DataSource dataSource) &#123; return new JdbcUserDetailsManager(dataSource); &#125; */ @Bean public PasswordEncoder passwordEncoder() &#123; // 用于单向密码校验，匹配(输入明文密码，UserDetails的加密密码) return new BCryptPasswordEncoder(); &#125; @Bean public SecurityFilterChain filterChain(HttpSecurity http) throws Exception &#123; http.authorizeRequests() .requestMatchers(&quot;/login&quot;).permitAll() .requestMatchers(&quot;/**&quot;).authenticated() .and() .formLogin().permitAll(); //@formatter:off http.authorizeRequests() .requestMatchers(&quot;/login&quot;).permitAll() // 允许所有人login访问 .requestMatchers(&quot;/**&quot;).hasAnyRole(&quot;USER&quot;, &quot;ADMIN&quot;) .requestMatchers(&quot;/admin/**&quot;).hasAnyRole(&quot;ADMIN&quot;) .and() .formLogin() .loginPage(&quot;/login&quot;) // 指定登陆页，区别默认登陆页面 .loginProcessingUrl(&quot;/process-login&quot;) .defaultSuccessUrl(&quot;/home&quot;) .failureUrl(&quot;/login?error=true&quot;) .permitAll() .and() .logout() .logoutSuccessUrl(&quot;/login?logout=true&quot;) // 指定登出页面 .invalidateHttpSession(true) .deleteCookies(&quot;JSESSIONID&quot;) .permitAll() // 允许logout访问 .and() .csrf().disable(); // 关闭csrf校验 //@formatter:on return http.build(); &#125; @Bean public WebSecurityCustomizer webSecurityCustomizer() &#123; // 资源类请求无需权限校验 return (web) -&gt; web.ignoring() .requestMatchers(&quot;/resources/**&quot;, &quot;/static/**&quot;); &#125; /* @Bean AuthenticationSuccessHandler authenticationSuccessHandler() &#123; return new CustomAuthenticationSuccessHandler(); &#125; @Bean AuthenticationFailureHandler authenticationFailureHandler() &#123; return new CustomAuthenticationFailureHandler(); &#125; */ &#125; 参考链接：https://howtodoinjava.com/spring-security/spring-security-tutorial/","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"},{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"安全","slug":"安全","permalink":"https://andy-whb-cn.github.io/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"前端：IFrame自适应高度","slug":"前端/前端：IFrame-Auto-Resize","date":"2024-04-30T06:43:29.847Z","updated":"2024-09-03T00:45:45.976Z","comments":true,"path":"2024/04/30/前端/前端：IFrame-Auto-Resize/","permalink":"https://andy-whb-cn.github.io/2024/04/30/%E5%89%8D%E7%AB%AF/%E5%89%8D%E7%AB%AF%EF%BC%9AIFrame-Auto-Resize/","excerpt":"","text":"IFrame子页面自适应高度问题项目中经常会遇到需要通过IFrame集成子页面的情况，比较常见的问题如跨域、自适应页面高度等。 方案一 廖老师这里介绍得很全面，直接引用原文 https://liaoxuefeng.com/blogs/all/2024-02-25-auto-resize-iframe/ 方案二 使用第三方库(Vue), https://github.com/davidjbradshaw/iframe-resizer 安装库1$ npm install iframe-resizer@latest -S IFrame子窗口页面123456789101112131415// directives/iframeResize.jsimport iframeResize from &#x27;iframe-resizer/js/iframeResizer&#x27; export default &#123; beforeMount: (el, &#123; value = &#123;&#125; &#125;) =&gt; &#123; el.addEventListener(&#x27;load&#x27;, () =&gt; iframeResize(value, el)) &#125;, unmounted: (el) =&gt; &#123; el.iFrameResizer.removeListeners() &#125;&#125; // index.jsimport iframeResize from &#x27;./iframeResize&#x27;app.directive(&#x27;resize&#x27;, iframeResize) IFrame父窗口页面12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273&lt;template&gt; &lt;div class=&quot;iframe-wrapper&quot;&gt; &lt;iframe v-resize=&quot;iFrameResizer&quot; id=&quot;Iframe&quot; width=&quot;100%&quot; :src=&quot;url&quot; frameborder=&quot;0&quot; &gt;&lt;/iframe&gt; &lt;/div&gt;&lt;/template&gt; &lt;script&gt;import &#123; mapGetters &#125; from &#x27;vuex&#x27;import &#123; jumpOtherSSO &#125; from &#x27;@/utils/sso/sso&#x27;import &#123; openFunc &#125; from &#x27;@/utils/util&#x27;export default &#123; name: &#x27;AppCenter&#x27;, data () &#123; return &#123; iFrameResizer: &#123; log: false, heightCalculationMethod: &#x27;lowestElement&#x27;, warningTimeout: 0 &#125;, ssoUrl: &#x27;&#x27; &#125; &#125;, mounted () &#123; // this.updateIframeHeightFunc() if (this.isUserLogin) &#123; jumpOtherSSO(&#x27;appCenter&#x27;, &#123; page: 1 &#125;).then(res =&gt; &#123; this.ssoUrl = res.data &#125;).catch(() =&gt; &#123; this.ssoUrl = this.$route.query.url &#125;) &#125; window.addEventListener(&#x27;message&#x27;, (e) =&gt; &#123; if (e.data.appId) &#123; const routeData = this.$router.resolve(&#123; name: this.$routerNameMap.appCenterDetails, query: &#123; url: xxx`, id: e.data.appId &#125; &#125;) openFunc(routeData.href) &#125; &#125;) &#125;, computed: &#123; ...mapGetters([&#x27;isUserLogin&#x27;]), url () &#123; return !this.isUserLogin ? this.$route.query.url : this.ssoUrl &#125; &#125;, methods: &#123; updateIframeHeightFunc () &#123; const oIframe = document.getElementById(&#x27;Iframe&#x27;) const deviceHeight = document.documentElement.clientHeight + 2360 oIframe.style.height = `$&#123;deviceHeight&#125;px` &#125; &#125;&#125;&lt;/script&gt; &lt;style lang=&quot;scss&quot; scoped&gt;.iframe-wrapper &#123; width: 100%; height: 100%; border: 0;&#125;&lt;/style&gt;","categories":[],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://andy-whb-cn.github.io/tags/Vue/"},{"name":"前端","slug":"前端","permalink":"https://andy-whb-cn.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"Google 智能体Agents白皮书","slug":"大模型/Google智能体Agents白皮书","date":"2024-01-09T03:11:00.000Z","updated":"2025-01-14T09:46:41.379Z","comments":true,"path":"2024/01/09/大模型/Google智能体Agents白皮书/","permalink":"https://andy-whb-cn.github.io/2024/01/09/%E5%A4%A7%E6%A8%A1%E5%9E%8B/Google%E6%99%BA%E8%83%BD%E4%BD%93Agents%E7%99%BD%E7%9A%AE%E4%B9%A6/","excerpt":"","text":"智能体 Agents作者：Julia Wiesinger， Patrick Marlow 和 Vladimir Vuskovic [TOC] 引言 智能体（Agent）概念：通过连接生成式AI大模型（Gen-AI Model）进行推理、逻辑和对外部信息访问的组合。 人类在复杂的模式识别任务方面非常出色。然而，在得出结论之前，他们通常依赖工具 —— 如书籍、谷歌搜索或计算器 —— 来补充预先的知识。就像人类一样，生成式AI大模型（Gen-AI Model）可以被训练使用工具来访问实时信息或建议现实世界的行动。例如，大模型可以利用数据库检索工具来访问特定信息，如客户的购买历史记录，来生成量身定制的购物建议。或者，根据用户的查询，大模型可以进行各种 API 调用，向同事发送电子邮件回复或完成金融交易。要做到这一点，大模型不仅需要访问一组外部工具，还需要有能力以自我导向的方式规划和执行任何任务。所有这些都与生成式AI大模型（Gen-AI Model）相关联的这种推理、逻辑和对外部信息的访问的组合引出了智能体（Agent）的概念，即一个继承并超越生成式AI大模型（Gen-AI Model）标准能力的程序。本白皮书将更详细地探讨所有这些及相关方面。 什么是智能体Agent从最基本的形式来看，Gen-AI 智能体(Agent)可以被定义为一种应用程序，它通过观察世界并使用其可支配的工具对世界采取行动来尝试实现一个目标。Agent是自主的，可以在没有人类干预的情况下独立行动，特别是当被赋予它们要实现的适当目标时。Agent在实现目标的方法上也可以是积极主动的。即使在没有人类明确指令集的情况下，Agent也可以推断出下一步应该做什么来实现其最终目标。虽然AI中的Agent概念非常通用且强大，但本白皮书重点关注当前Gen-AI Model能够构建的特定类型的Agent。 为了理解智能体Agent的内部运作，让我们首先介绍驱动Agent的行为、动作和决策的基本组件。这些组件的组合可以被描述为一个认知架构(Cognative Architecture)，并且有许多这样的架构能够通过这些组件的混合和匹配来实现。智能体Agent的认知架构中有三个基本核心组件，如图 1 所示。 图 1. 通用智能体Agent的认知架构和基本组件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105direction: rightclasses: &#123;d2: &#123;label: &quot;&quot;icon: https://icons.terrastruct.com/emotions%2F025-smile.svgstyle.stroke-width: 0style.fill: white&#125;NONE: &#123;style.opacity: 0&#125;GREEN: &#123;style.stroke: &quot;#72A17E&quot;; style.fill: &quot;#D3E8D9&quot;; style.border-radius: 8&#125;GREEN-X: &#123;style.stroke: &quot;#6E9776&quot;; style.fill: &quot;#E9F4EA&quot;; style.border-radius: 8&#125;RED: &#123;style.stroke: &quot;#B56598&quot;; style.fill: &quot;#F9E8F2&quot;; style.border-radius: 8&#125;YELLOW: &#123;style.stroke: &quot;#D3B258&quot;; style.fill: &quot;#FCF7E1&quot;; style.border-radius: 8&#125;BLUE: &#123;style.stroke: &quot;#5484C4&quot;; style.fill: &quot;#EAEFFC&quot;; style.border-radius: 8&#125;&#125;u.class: [d2] u: Usera: Agent Runtime &#123;class: BLUEgrid-columns: 2grid-gap: 10l: &quot;&quot; &#123;class: NONEgrid-rows: 2grid-gap: 10a1: Orchestration &#123;class: GREENgrid-rows: 1grid-columns: 1grid-gap: 10a11: Profile, goals, &amp;instructions &#123;class: GREEN-X&#125;xx: &quot;&quot; &#123;class: GREEN-Xgrid-columns: 3grid-gap: 5x0: Memory &#123;class: GREEN-X; style.stroke-width: 0&#125;x1: short-term &#123;class: GREEN-X; style.stroke-dash: 3; grid-gap: 0&#125;x2: long-term &#123;class: GREEN-X; style.stroke-dash: 3; grid-gap: 0&#125;&#125;a13: Model based Reasoning/Planning &#123;class: GREEN-X&#125;&#125;a2: Model &#123;class: RED&#125;&#125;r: &quot;&quot; &#123;class: NONEgrid-columns: 1grid-gap: 10a3: Tools &#123;class: YELLOW; height: 350&#125;&#125;&#125;u -&gt; a: user_querya -&gt; u: agent_response 大模型（Model)在智能体Agent的范围内，模型是指将被用作智能体Agent流程的集中决策制定者的语言模型（LM）。智能体Agent使用的模型可以是一个或多个任意规模（小&#x2F;大）的语言模型，这些模型能够遵循基于指令的推理和逻辑框架，如 ReAct、思维链（Chain-of-Thought）或思维树（Tree-of-Thoughts）。模型可以是通用的、多模态的，也可以根据特定智能体Agent架构的需求进行微调。为了获得最佳的生产结果，你应该利用最适合你期望的最终应用的模型，并且理想情况下，该模型是在与你计划在认知架构中使用的工具相关的数据特征上进行训练的。需要注意的是，模型通常不是使用智能体Agent的特定配置设置（即工具选择、编排&#x2F;推理设置）进行训练的。然而，可以通过向模型提供展示智能体Agent能力的示例，包括智能体在各种上下文中使用特定工具或推理步骤的实例，来进一步优化模型以适应智能体Agent的任务。 工具（Tools）基础模型虽然在文本和图像生成方面令人印象深刻，但仍受限于无法与外部世界交互。工具弥补了这一差距，使智能体Agent能够与外部数据和服务交互，同时解锁比基础模型单独所能实现的更广泛的行动范围。工具可以有各种形式，并且具有不同程度的复杂性，但通常与常见的 Web API 方法（如 GET、POST、PATCH 和 DELETE）一致。例如，一个工具可以更新数据库中的客户信息或获取天气数据以影响智能体Agent向用户提供的旅行建议。有了工具，智能体Agent可以访问和处理现实世界的信息。这使它们能够支持更专业的系统，如检索增强生成（RAG），这大大扩展了智能体Agent的能力，超出了基础模型自身所能实现的范围。我们将在下面更详细地讨论工具，但最重要的是要理解，工具在智能体Agent的内部能力和外部世界之间架起了一座桥梁，解锁了更广泛的可能性。 编排层（The orchestration layer）编排层描述了一个循环过程，该过程规定了智能体Agent如何接收信息、进行一些内部推理，并使用该推理来决定其下一个行动或决策。一般来说，这个循环将持续到智能体达到其目标或停止点。编排层的复杂性可能因智能体Agent及其执行的任务而有很大差异。一些循环可以是带有决策规则的简单计算，而其他循环可能包含链式逻辑、涉及额外的机器学习算法或实施其他概率推理技术。我们将在认知架构部分中讨论更多关于智能体编排层的详细实现。 智能体和大模型对比（Agents vs Models）为了更清楚地了解智能体和大模型之间的区别，请考虑以下图表： 大模型（Models） 智能体（Agents） 知识限定于可用的训练数据 知识通过工具与外部系统的连接得以扩展。 基于用户查询进行单次推理 &#x2F; 预测。除非专门为模型实现了相关功能，否则不会对会话历史或连续上下文（即聊天历史）进行管理。 对会话历史（即聊天历史）进行管理，以便能够基于用户查询以及编排层所做的决策开展多轮推理&#x2F;预测。在此语境下，“一轮”被定义为交互系统与智能体之间的一次交互（即一次传入事件&#x2F;查询以及智能体的一次回复）。 未实现原生工具 工具在智能体架构中以原生方式实现。 未实现原生逻辑层。用户可以将prompts表述为简单问题，也可以运用推理框架（思维链、推理与行动等）来构建复杂prompts，以引导模型进行预测。 采用思维链（CoT）、推理与行动（ReAct）等推理框架，或诸如LangChain等其他预构建智能体框架的原生认知架构。 认知架构：智能体Agent如何运作假想有一位厨师在繁忙的厨房里，他的目标是为餐厅顾客创造美味的菜肴，这就涉及一系列计划、执行和调整的循环过程： 收集信息：例如顾客的订单、食品储藏室和冰箱里有哪些食材。 内部推理：根据刚刚收集的信息，推理可以制作哪些菜肴和风味特征。 执行动作：执行切菜、混合香料、烤肉等一系列动作来完成这道菜。 在过程的每个阶段，厨师都会根据需要进行调整，在食材耗尽或收到客户反馈时完善他们的计划，并使用之前的一组结果来确定下一个行动计划。这个信息获取、计划、执行和调整的循环过程描述了厨师为实现目标而采用的独特认知架构。 就像厨师一样，智能体Agent可以通过迭代处理信息、做出明智的决策并根据以前的输出优化下一步行动，使用认知架构来实现其最终目标。智能体Agent认知架构的核心是编排层，负责维护内存、状态、推理和规划。它使用快速发展的提示工程和相关框架领域来指导推理和规划，使Agent能够更有效地与其环境交互并完成任务。语言模型的提示工程框架和任务规划领域的研究正在迅速发展，产生了各种有前途的方法。虽然不是详尽无遗的列表，但这些是本文发布时可用的一些最流行的框架和推理技术： ReAct：一种提示工程框架，为语言模型提供一种思考过程策略，以便对用户查询进行推理并采取行动，无论是否有上下文示例。ReAct 提示已被证明优于几个最先进的基线，并提高了语言模型的人类互操作性和可信度。 思维链（Chain-of-Thought，CoT）：一种提示工程框架，它通过中间步骤实现推理能力。CoT 有多种子技术，包括自洽性、主动提示和多模态 CoT，每种技术在特定应用中都有其优缺点。 思维树（Tree-of-thoughts）：一种非常适合探索或战略性前瞻任务的提示工程框架。它对思维链提示进行了概括，并允许模型探索各种作为语言模型通用问题解决中间步骤的思维链。 Agent可以使用上述推理技术之一，或许多其他技术，为给定的用户请求选择下一个最佳行动。例如，让我们考虑一个使用 ReAct 框架为用户查询选择正确行动和工具的Agent程序。事件的顺序可能是这样的： 用户向Agent发送查询 Agent开始执行 ReAct 序列 Agent向模型提供提示，要求它生成下一个 ReAct 步骤之一及其相应的输出： a. 问题：用户查询中的输入问题，随提示一起提供 b. 想法：模型对下一步应该做什么的思考 c. 行动：模型对下一步要采取什么行动的决定 i. 这是可以选择工具的地方 ii. 例如，一个动作可以是 [Flight， Search， Code， None] 之一，其中前 3 个表示模型可以选择的已知工具，最后一个表示 “无工具选择” d. 行动输入：模型决定向工具提供哪些输入（如果有） e. 观察：动作 &#x2F; 动作输入序列的结果 i. 这个想法 &#x2F; 行动 &#x2F; 行动输入 &#x2F; 观察可以根据需要重复 N 次 f. 最终答案：模型提供给原始用户查询的最终答案 ReAct 循环结束，并将最终答案返回给用户 图 2.示例Agent：在编排层中使用 ReAct 推理 如图 2 所示，Model、Tool和Agent配置协同工作，根据用户的原始查询为用户提供有根据的简洁回复。虽然模型本可以根据其先验知识猜测答案（产生幻觉），但它却使用了一个工具（Flights）来搜索实时外部信息。这些额外的信息被提供给模型，使其能够根据真实的事实数据做出更明智的决策，并将这些信息总结后反馈给用户。 总之，智能体Agent响应的质量可以直接与模型对这些各种任务进行推理和行动的能力相关联，包括选择正确工具的能力，以及该工具被定义得有多好。就像一位厨师用新鲜食材精心制作菜肴并关注顾客反馈一样，智能体Agent依靠合理的推理和可靠的信息来提供最佳结果。在下一节中，我们将深入探讨智能体与新鲜数据的各种连接方式。 工具：我们打开外部世界的钥匙虽然语言模型在处理信息方面表现出色，但它们缺乏直接感知和影响现实世界的能力。这限制了它们在需要与外部系统或数据交互的情况下的实用性。这意味着，从某种意义上说，语言模型的好坏仅取决于它从训练数据中学到的东西。但是，无论我们向模型提供多少数据，它们仍然缺乏与外部世界交互的基本能力。那么，我们如何赋予我们的模型与外部系统进行实时、上下文感知交互的能力呢？函数、扩展、数据存储和插件都是为模型提供这种关键能力的方法。 虽然它们有很多名称，但工具Tool是在我们的基础模型和外部世界之间建立联系的东西。与外部系统和数据的这种联系使我们的智能体Agent能够执行更广泛的任务，并以更高的准确性和可靠性来完成这些任务。例如，工具可以使智能体调整智能家居设置、更新日历、从数据库中获取用户信息，或者根据特定的指令集发送电子邮件。 截至本白皮书发布之日，能够与谷歌模型交互的主要工具类型有三种：扩展程序、函数和数据存储。通过为智能体配备工具，我们为它们不仅理解世界而且对世界采取行动释放了巨大的潜力，为无数新的应用和可能性打开了大门。 扩展理解扩展的最简单方法是将它们视为以标准化方式弥合 API 与Agent之间的差距，使Agent能够无缝地执行 API，而不管其底层实现如何。假设你已经构建了一个旨在帮助用户预订航班的Agent。你知道你想使用谷歌航班 API 来检索航班信息，但你不确定如何让你的Agent调用这个 API 端点。 图 3. 智能体如何与外部 API 交互？ 一种方法是实现自定义代码，该代码将接收传入的用户查询，解析查询中的相关信息，然后进行 API 调用。例如，在航班预订用例中，用户可能会说 “我想预订从奥斯汀到苏黎世的航班”。在这种情况下，我们的自定义代码解决方案需要在尝试进行 API 调用之前从用户查询中提取 “奥斯汀” 和 “苏黎世” 作为相关实体。但是，如果用户说 “我想预订去苏黎世的航班” 而从未提供出发城市会发生什么呢？没有所需的数据，API 调用将失败，并且需要实现更多代码才能捕获像这样的边缘情况和特殊情况。这种方法不可扩展，并且在任何超出已实现自定义代码的场景中都很容易出错。 更有弹性的方法是使用扩展。扩展通过以下方式弥合Agent和 API 之间的差距： 通过示例教Agent如何使用 API 。 教导Agent成功调用 API 需要哪些参数或参数是什么。 图4.扩展将Agent连接到外部API 扩展可以独立于Agent进行创建，但应该作为Agent配置的一部分提供。Agent在运行时使用模型和示例来决定哪个扩展（如果有的话）适合解决用户的查询。这突出了扩展的一个关键优势，即它们的内置示例类型，允许Agent为任务动态选择最合适的扩展。 图5.Agent、扩展和API之间的一对多关系 请像软件开发人员在为用户解决问题时决定使用哪些 API 一样考虑这个问题。如果用户想要预订航班，开发人员可能会使用 Google Flights API。如果用户想知道离他们所在位置最近的咖啡店在哪里，开发人员可能会使用 Google Maps API。同样，Agent&#x2F;Model堆栈使用一组已知的扩展来决定哪个最适合用户的查询。如果你想看到扩展的实际效果，可以在 Gemini 应用程序上试用它们，方法是转到设置&gt;扩展，然后启用你想要测试的任何扩展。例如，你可以启用 Google Flights 扩展，然后问 Gemini：“给我显示下周五从奥斯汀飞往苏黎世的航班。 扩展示例为了简化扩展的使用，谷歌提供了一些现成的扩展，可以快速导入到你的项目中，并以最少的配置使用。例如，片段 1 中的代码解释器扩展允许你从自然语言描述中生成并运行 Python 代码。 123456789101112131415161718192021import vertexai import pprint PROJECT_ID = &quot;YOUR_PROJECT_ID&quot; REGION = &quot;us-central1&quot; vertexai.init(project=PROJECT_ID, location=REGION) from vertexai.preview.extensions import Extension extension_code_interpreter = Extension.from_hub(&quot;code_interpreter&quot;) CODE_QUERY = &quot;&quot;&quot;Write a python method to invert a binary tree in O(n) time.&quot;&quot;&quot; response = extension_code_interpreter.execute( operation_params = &#123;&quot;query&quot;: CODE_QUERY&#125;, operation_id = &quot;generate_and_execute&quot;, )print(&quot;Generated Code:&quot;) pprint.pprint(&#123;response[&#x27;generated_code&#x27;]&#125;) 123456789101112131415161718192021222324252627282930313233343536373839# The above snippet will generate the following code.Generated Code: class TreeNode: def __init__(self, val=0, left=None, right=None): self.val = val self.left = left self.right = rightdef invert_binary_tree(root): &quot;&quot;&quot; Inverts a binary tree Args: root: The root of the binary tree. Returns:. The root of the inverted binary tree. &quot;&quot;&quot; if not root: return None # Swap the left and right children recursively return root root.left, root.right = invert_binary_tree(root.right),invert_binary_tree(root.left) return root # Example usage: # Construct a sample binary tree root = TreeNode(4)root.left = TreeNode(2) root.right = TreeNode(7) root.left.left = TreeNode(1)root.left.right = TreeNode(3) root.right.left = TreeNode(6) root.right.right = TreeNode(9)# Invert the binary tree inverted_root = invert_binary_tree(root) 片段 1.Code Interpreter Extension 可以生成和运行 Python 代码 总之，扩展为智能体提供了一种以多种方式感知、交互和影响外部世界的方法。这些扩展的选择和调用是由示例的使用来指导的，所有这些示例都是作为扩展配置的一部分来定义的。 函数在软件工程领域，函数被定义为独立的代码模块，用于完成特定任务，并可根据需要重复使用。当软件开发人员编写程序时，他们通常会创建许多函数来执行各种任务。他们还会定义何时调用函数 A 与函数 B 的逻辑，以及预期的输入和输出。 在智能体的世界中，函数的工作方式非常相似，但我们可以用模型替换软件开发人员。模型可以获取一组已知函数，并根据函数的规范决定何时使用每个函数以及该函数需要哪些参数。函数与扩展在一些方面有所不同，最显著的是： 一个模型输出一个函数及其参数，但不进行实时的 API 调用。 函数在客户端执行，而扩展在Agent端执行。 再次以我们的谷歌航班示例为例，函数的简单设置可能看起来像图 7 中的示例。 图 7.函数如何与外部 API 交互？ 请注意，这里的主要区别在于函数和Agent都不直接与谷歌航班 API 进行交互。那么 API 调用实际上是如何发生的呢？ 使用函数时，调用 API 从Agent转回客户端应用程序，如下图 8 和图 9 所示。这为开发人员提供了对应用程序中数据流的更精细控制。开发人员选择使用函数而不是扩展有很多原因，但一些常见的场景是： API 调用需要在Agent架构之外进行（例如，中间件系统、前端框架等）。 安全或身份验证限制导致Agent无法直接调用 API（例如，API 未暴露在互联网上，或者Agent无法访问）。 时间安排或操作顺序限制，导致Agent无法进行实时API 调用。（即批量操作、人工审查环节等） 在处理 API 响应数据时，需要额外的数据转换逻辑，然而 Agent 却无法实现这一点。比如，实际应用场景需要限制API返回的数据量，API本身又不支持通过传参过滤。通过在客户端通过使用函数的方式，能够为开发人员提供一种额外的机制来完成上述数据转换逻辑。 开发人员希望在Agent迭代开发中不需要部署API（即函数调用可以像 API 的 “存根” 一样）。 虽然如图 8 所示，这两种方法在内部架构上的差异很细微，但函数调用所提供的额外控制以及对外部基础设施的解耦依赖使其成为开发人员的一个有吸引力的选择。 图 8. 描述客户端与Agent端如何控制扩展和函数的调用 场景案例一个模型可以用来调用函数，以便为最终用户处理复杂的客户端执行流程，在这种情况下，Agent开发人员可能不希望语言模型管理 API 执行（就像扩展的情况一样）。让我们考虑以下场景，其中一个Agent正在被训练为旅行礼宾员，与想要预订度假旅行的用户进行交互。目标是让Agent生成一个城市列表，我们可以在中间件应用程序中使用该列表为用户的旅行计划下载图像、数据等。用户可能会说这样的话： *我想和家人一起去滑雪旅行，但我不知道去哪里。 在模型的典型提示中，输出可能如下所示： *当然，这里有一份你可以考虑进行家庭滑雪旅行的城市列表： 美国科罗拉多州克雷斯特德比特。 惠斯勒，不列颠哥伦比亚省，加拿大 瑞士采尔马特 虽然上述输出包含我们需要的数据（城市名称），但格式不太适合解析。通过函数调用，我们可以教导模型以结构化的风格（如 JSON）格式化此输出，这种格式对于另一个系统解析来说更加方便。给定来自用户的相同输入提示，函数的示例 JSON 输出可能如片段 5 所示。 1234567function_call &#123; name: &quot;display_cities&quot; args: &#123; &quot;cities&quot;: [&quot;Crested Butte&quot;, &quot;Whistler&quot;, &quot;Zermatt&quot;], &quot;preferences&quot;: &quot;skiing&quot; &#125; &#125; 片段 5. 用于显示城市列表和用户偏好的示例函数调用的payload数据。 此 JSON payload数据由模型生成，然后发送到我们的客户端服务器，以便我们对其进行任何我们想做的操作。在这种特定情况下，我们将调用 Google Places API，获取模型提供的城市并查找图像，然后将它们作为格式化的丰富内容提供回我们的用户。请考虑图 9 中的此序列图，它逐步详细地展示了上述交互。 图 9. 显示函数调用生命周期的序列图 图 9 中示例的结果是，利用该模型来 “填补空白”，为客户端 UI 调用 Google Places API 提供所需的参数。客户端 UI 使用模型在返回的函数中提供的参数来管理实际的 API 调用。这只是函数调用的一个用例，但还有许多其他场景需要考虑，例如： 你希望语言模型为你的代码推荐一个函数，但你不想在代码中包含凭证信息。由于函数调用不会运行该函数，因此你无需在包含函数信息的代码中包含凭证信息。 你正在运行可能需要几秒钟以上时间的异步操作。这些场景与函数调用配合得很好，因为它是一个异步操作。 你希望在与生成函数调用及其参数的系统不同的设备上运行函数。 关于函数需要记住的一个关键要点是，它们旨在为开发人员提供对 API 调用的执行以及整个应用程序中的数据整体流程的更多控制。在图 9 的示例中，开发人员选择不将 API 信息返回给Agent，因为这与Agent未来可能采取的行动无关。然而，根据应用程序的架构，将外部 API 调用数据返回给Agent以影响未来的推理、逻辑和行动选择可能是有意义的。最终，由应用程序开发人员来选择什么对特定的应用程序是正确的。 函数示例代码为了从我们的滑雪度假场景中获得上述输出，让我们构建出每个组件，使其与我们的 gemini-1.5-flash-001 模型一起工作。 首先，我们将把 display_cities 函数定义为一个简单的 Python 方法。 1234567891011def display_cities(cities: list[str], preferences: Optional[str] = None): &quot;&quot;&quot;Provides a list of cities based on the user&#x27;s search query and preferences. Args: preferences (str): The user&#x27;s preferences for the search, like skiing, beach, restaurants, bbq, etc. cities (list[str]): The list of cities being recommended to the user. Returns: list[str]: The list of cities being recommended to the user. &quot;&quot;&quot; return cities 片段 6. 将显示城市列表的函数的示例 python 方法。 接下来，我们将实例化我们的模型，构建 Tool，然后将用户的查询和工具传递给模型。执行下面的代码将产生代码片段底部所示的输出。 12345678910111213141516from vertexai.generative_models import GenerativeModel, Tool, FunctionDeclaration model = GenerativeModel(&quot;gemini-1.5-flash-001&quot;) display_cities_function = FunctionDeclaration.from_func(display_cities) tool = Tool(function_declarations=[display_cities_function]) message = &quot;I’d like to take a ski trip with my family but I’m not sure where to go.&quot; res = model.generate_content(message, tools=[tool]) print(f&quot;Function Name: &#123;res.candidates[0].content.parts[0].function_call.name&#125;&quot;) print(f&quot;Function Args: &#123;res.candidates[0].content.parts[0].function_call.args&#125;&quot;) &gt; Function Name: display_cities &gt; Function Args: &#123;&#x27;preferences&#x27;: &#x27;skiing&#x27;, &#x27;cities&#x27;: [&#x27;Aspen&#x27;, &#x27;Vail&#x27;, &#x27;Park City&#x27;]&#125; 片段 7. 构建工具，将用户查询发送到模型并允许进行函数调用。总之，函数提供了一个直接的框架，使应用程序开发人员能够对数据流和系统执行进行精细控制，同时有效地利用Agent&#x2F;Model进行关键输入生成。开发人员可以根据特定的应用程序架构要求，通过返回外部数据有选择地决定是否让代理 “参与其中”，或者省略它。 数据存储想象一个语言模型就像一个巨大的图书馆，里面存放着它的训练数据。但与不断获取新书籍的图书馆不同，这个语言模型保持静态，只拥有最初训练时的知识。这带来了一个挑战，因为现实世界的知识在不断演变。数据存储通过提供对更动态和最新信息的访问来解决这一限制，并确保模型的响应始终基于真实性和相关性。 考虑一个常见的场景，开发者可能需要向模型提供少量额外的数据，也许是以电子表格或 PDF 的形式。 图 10.Agent 如何与结构化和非结构化数据交互？ 数据存储允许开发人员以其原始格式向Agent提供额外数据，消除了耗时的数据转换、模型再训练或微调的需要。数据存储将传入的文档转换为一组向量数据库嵌入，Agent可以使用这些嵌入来提取其补充下一步行动或对用户响应所需的信息。 实现和应用在生成式人工智能体Agent的背景下，数据存储通常被实现为一个向量数据库，开发人员希望Agent在运行时能够访问它。虽然我们在这里不会深入介绍向量数据库，但需要理解的关键一点是，它们以向量嵌入的形式存储数据，向量嵌入是一种高维向量或所提供数据的数学表示形式。近年来，语言模型中数据存储使用的最丰富的例子之一是检索增强(RAG)的实现。 基于检索增强（RAG）的应用程序。这些应用程序试图通过让模型访问各种格式的数据来扩展模型知识的广度和深度，使其超越基础训练数据。 网站内容 PDF、Word Docs、CSV、电子表格等格式的结构化数据。 HTML、PDF、TXT 等格式的非结构化数据。 图 12. Agent和数据存储之间的一对多关系，可以表示各种类型的预索引数据 每个用户请求和Agent响应循环的底层过程通常如图 13 所示进行建模。 用户查询被发送到embedding model以生成查询的embedding向量。 使用像 SCaNN 这样的匹配算法将查询embedding与向量数据库的内容进行匹配。 从向量数据库中检索匹配的内容以文本格式发送回Agent。 Agent接收用户查询和检索到的内容，然后构建响应或行动。 向用户发送最终响应 图 13. 基于检索增强生成（RAG）的应用程序中用户请求和智能体响应的生命周期 最终结果是一个应用程序，它允许Agent通过向量搜索将用户的查询与已知的数据存储进行匹配，检索原始内容，并将其提供给编排层和模型进行进一步处理。下一个动作可能是向用户提供最终答案，或者执行额外的向量搜索以进一步细化结果。 与实现带有 ReAct 推理 &#x2F; 规划的检索增强生成（RAG）的智能体进行的示例交互可以在图 14 中看到。 图 14.带有 ReAct 推理 &#x2F; 规划的基于 RAG 的示例应用程序。 工具回顾总而言之，扩展、函数和数据存储构成了几种不同的工具类型，可供Agent在运行时使用。每个都有自己的用途，它们可以一起使用，也可以由Agent开发人员自行决定单独使用。 扩展 函数调用 数据存储 执行 Agent 客户端 Agent 场景 1. 开发人员希望智能体能够控制与 API 的交互。2. 在利用原生的预构建扩展（例如，Vertex 搜索、代码解释器等）时，这很有用。3. 多跳转规划和 API 调用（即智能体的下一个操作取决于前一个操作 &#x2F; API 调用的输出结果）。 1. 安全或认证方面的限制导致智能体无法直接调用 API。2. 时间限制或操作顺序限制使得智能体无法实时进行 API 调用。（例如，批量操作、人工介入审查等情况。）3. API 未暴露在互联网上，或者谷歌系统无法访问该 API。 开发人员希望使用以下任意一种数据类型来实现检索增强生成（RAG）：1. 来自预先索引的域名和网址的网站内容。2. 诸如 PDF、Word 文档、CSV、电子表格等格式的结构化数据。3. 关系型 &#x2F; 非关系型数据库。4. 诸如 HTML、PDF、TXT 等格式的非结构化数据。 通过有针对性的学习提高模型性能有效使用模型的一个关键方面是它们在生成输出时选择正确工具的能力，尤其是在生产中大规模使用工具时。虽然一般训练有助于模型发展这种技能，但现实世界的场景往往需要训练数据之外的知识。可以把这想象成基本烹饪技能和掌握特定菜系之间的区别。两者都需要基础烹饪知识，但后者需要有针对性的学习才能获得更微妙的结果。 为了帮助模型获得这种特定类型的知识，有几种方法存在： 上下文学习：这种方法在推理时为通用模型提供提示、工具和少量示例，使其能够 “即时” 学习如何以及何时使用这些工具来完成特定任务。ReAct 框架是自然语言中这种方法的一个例子。 基于检索的上下文学习：这种技术通过从外部存储器中检索最相关的信息、工具和相关示例，动态地填充模型提示。一个例子是 Vertex AI 扩展中的 “示例存储” 或前面提到的基于检索增强生成（RAG）架构的数据存储。 基于微调的学习：这种方法涉及在推理之前使用更大的特定示例数据集来训练模型。这有助于模型在接收任何用户查询之前了解何时以及如何应用某些工具。 为了对每种有针对性的学习方法提供更多见解，让我们再次回顾我们的烹饪类比。 想象一下，一位厨师从顾客那里收到了一份特定的食谱（提示）、一些关键食材（相关工具）和一些示例菜肴（少量示例）。基于这些有限的信息以及厨师对烹饪的一般知识，他们需要当场想出如何准备与食谱和顾客偏好最接近的菜肴。这就是情境学习。 现在让我们想象一下，我们的厨师在一个厨房里，这个厨房有一个储备充足的食品储藏室（外部数据存储），里面装满了各种食材和烹饪书（示例和工具）。现在，厨师能够从食品储藏室中动态地选择食材和烹饪书，并更好地适应顾客的食谱和偏好。这使得厨师能够利用现有知识和新知识创造出更有见地、更精致的菜肴。这就是基于检索的上下文学习。 最后，让我们想象一下，我们把厨师送回学校去学习一种新的菜系或一组菜系（在特定示例的更大数据集上进行预训练）。这使得厨师能够以更深刻的理解来处理未来未见过的顾客菜谱。如果我们希望厨师在特定菜系（知识领域）中表现出色，这种方法是完美的。这是基于微调的学习。 这些方法中的每一种在速度、成本和延迟方面都有独特的优势和劣势。然而，通过在智能体框架中结合这些技术，我们可以利用各种优势并最小化它们的弱点，从而实现更强大和适应性更强的解决方案。 智能体（Agent） 快速入门 LangChain为了提供一个真实世界中可执行的智能体示例，我们将使用 LangChain 和 LangGraph 库构建一个快速原型。这些流行的开源库允许用户通过 “链接” 一系列逻辑、推理和工具调用序列来构建客户智能体，以回答用户的查询。我们将使用 gemini-1.5-flash-001 模型和一些简单的工具来回答用户的多阶段查询，如代码片段 8 所示。 我们正在使用的工具是 SerpAPI（用于谷歌搜索）和谷歌地点 API。在执行了代码片段 8 中的程序后，你可以在代码片段 9 中看到示例输出。 12345678910111213141516171819202122232425262728293031323334from langgraph.prebuilt import create_react_agent from langchain_core.tools import tool from langchain_community.utilities import SerpAPIWrapper from langchain_community.tools import GooglePlacesTool os.environ[&quot;SERPAPI_API_KEY&quot;] = &quot;XXXXX&quot; os.environ[&quot;GPLACES_API_KEY&quot;] = &quot;XXXXX&quot; @tool def search(query: str): &quot;&quot;&quot;Use the SerpAPI to run a Google Search.&quot;&quot;&quot; search = SerpAPIWrapper() return search.run(query) @tool def places(query: str): &quot;&quot;&quot;Use the Google Places API to run a Google Places Query.&quot;&quot;&quot; places = GooglePlacesTool() return places.run(query) model = ChatVertexAI(model=&quot;gemini-1.5-flash-001&quot;) tools = [search, places] query = &quot;Who did the Texas Longhorns play in football last week? What is the address of the other team&#x27;s stadium?&quot; agent = create_react_agent(model, tools) input = &#123;&quot;messages&quot;: [(&quot;human&quot;, query)]&#125; for s in agent.stream(input, stream_mode=&quot;values&quot;): message = s[&quot;messages&quot;][-1] if isinstance(message, tuple): print(message) else: message.pretty_print() 片段 8. 基于 LangChain 和 LangGraph 的带工具的示例Agent。 123456789101112131415161718192021=============================== Human Message ================================ Who did the Texas Longhorns play in football last week? What is the address of the other team&#x27;s stadium? ================================= Ai Message ================================= Tool Calls: search Args: query: Texas Longhorns football schedule ================================ Tool Message ================================ Name: search &#123;...Results: &quot;NCAA Division I Football, Georgia, Date...&quot;&#125; ================================= Ai Message ================================= The Texas Longhorns played the Georgia Bulldogs last week. Tool Calls: places Args: query: Georgia Bulldogs stadium ================================ Tool Message ================================ Name: places &#123;...Sanford Stadium Address: 100 Sanford...&#125; ================================= Ai Message ================================= The address of the Georgia Bulldogs stadium is 100 Sanford Dr, Athens, GA 30602, USA. 片段 9. 代码段 8 中程序的输出 虽然这是一个相当简单的智能体示例，但它展示了模型、编排和工具的基本组成部分共同发挥作用以实现特定目标。在最后一部分，我们将探讨这些组件如何在谷歌规模的托管产品（如 Vertex AI 智能体和生成式剧本）中协同工作。 使用 Vertex AI 代理的生产应用程序虽然本白皮书探讨了智能体的核心组成部分，但构建生产级应用程序需要将它们与其他工具（如用户界面、评估框架和持续改进机制）集成。谷歌的 Vertex AI 平台通过提供一个完全托管的环境简化了这一过程，涵盖了前面提到的所有基本要素。通过自然语言界面，开发人员可以快速定义其智能体的关键要素 —— 目标、任务指令、工具、用于任务委派的子智能体以及示例 —— 以轻松构建所需的系统行为。此外，该平台还配备了一组开发工具，可用于测试、评估、测量智能体性能、调试以及提高所开发智能体的整体质量。这使开发人员能够专注于构建和完善他们的智能体，而基础设施、部署和维护的复杂性则由平台本身管理。 在图 15 中，我们提供了一个在 Vertex AI 平台上构建的代理的示例架构，该架构使用了各种功能，例如 Vertex Agent Builder、Vertex Extensions、Vertex Function Calling 和 Vertex Example Store 等等。该架构包括了生产就绪应用程序所需的许多不同组件。 图 15. 基于 Vertex AI 平台构建的端到端Agent架构示例 您可以从我们的官方文档中尝试此预构建Agent架构的示例。 总结在这份白皮书中，我们讨论了生成式人工智能体的基础构建模块、它们的组成以及以认知架构的形式实现它们的有效方法。这份白皮书的一些关键要点包括： 智能体通过利用工具来访问实时信息、建议实际行动以及自主规划和执行复杂任务，从而扩展语言模型的能力。智能体可以利用一个或多个语言模型来决定何时以及如何在状态之间转换，并使用外部工具来完成许多对于模型自身来说难以或不可能完成的复杂任务。 在智能体运作的核心是编排层，这是一种认知架构，用于构建推理、规划、决策并指导其行动。各种推理技术，如 ReAct、思维链和思维树，为编排层提供了一个框架，以接收信息、进行内部推理并生成明智的决策或响应。 工具，如扩展、函数和数据存储，是智能体通向外部世界的关键，使它们能够与外部系统交互并访问超出其训练数据的知识。扩展在智能体和外部 API 之间提供了一座桥梁，能够执行 API 调用并检索实时信息。函数通过分工为开发人员提供更细致的控制，允许智能体生成可在客户端执行的函数参数。数据存储为智能体提供对结构化或非结构化数据的访问，实现数据驱动的应用程序。 Agent的未来有着令人兴奋的进步，我们才刚刚开始触及可能实现的事物的表面。随着工具变得更加复杂，推理能力得到增强，代理将有能力解决日益复杂的问题。 此外，“智能体链接” 的战略方法将继续获得发展动力。 结合专业的智能体 —— 每个智能体在特定领域或任务中表现出色 —— 我们可以创建一种 “智能体专家混合” 方法，能够在各个行业和问题领域中提供卓越的结果。 重要的是要记住，构建复杂的智能体架构需要采用迭代方法。实验和改进是找到特定业务案例和组织需求解决方案的关键。由于支撑其架构的基础模型具有生成性，因此没有两个智能体是完全相同的。然而，通过利用这些基础组件各自的优势，我们可以创建具有影响力的应用程序，扩展语言模型的能力并带来实际价值。 尾注 ran, I., Cao, Y. 等人，2022 年，“ReAct：在语言模型中协同推理和行动”。可在：https://arxiv.org/pdf/2210.03629 获取。 Wei, J., Wang, X. 等人，2023 年，《思维链提示在大型语言模型中引发推理》。可在：https://arxiv.org/pdf/2201.11903.pdf 获得。 Wang, X. 等人，2022，《自洽性提高语言模型中的思维链推理》。可在以下网址获取：https://arxiv.org/pdf/2203.11171。 Diao, S. 等人，2023，“使用思维链进行主动提示的大型语言模型”。可在以下网址获取：https://arxiv.org/pdf/2302.12246.pdf。 Zhang, H. 等人，2023，《语言模型中的多模态思维链推理》。可在：https://arxiv.org/pdf/2302.00923 获得。 Yao, S. 等人，2023 年，《思维树：使用大型语言模型进行深思熟虑的问题解决》。可在：https://arxiv.org/pdf/2305.10601 获得。 Long， X.，2023 年，“大型语言模型引导的思想树”。网址：https://arxiv.org/abs/2305.08291。 Google。“Google Gemini 应用程序”。可在以下网址获取：http://gemini.google.com。 Swagger。“OpenAPI 规范”。可在以下网址获取：https://swagger.io/specification/。 Xie， M.，2022 年，“情境学习如何运作？理解与传统监督学习差异的框架”。网址：https://ai.stanford.edu/blog/understanding-incontext/。 谷歌研究。’ScaNN （可扩展最近邻）’。网址：https://github.com/google-research/google-research/tree/master/scann。 LangChain. ‘LangChain’. Available at: https://python.langchain.com/v0.2/docs/introduction/.","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://andy-whb-cn.github.io/tags/SpringBoot/"},{"name":"架构","slug":"架构","permalink":"https://andy-whb-cn.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"微服务","slug":"微服务","permalink":"https://andy-whb-cn.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Java","slug":"Java","permalink":"https://andy-whb-cn.github.io/tags/Java/"},{"name":"脚本","slug":"脚本","permalink":"https://andy-whb-cn.github.io/tags/%E8%84%9A%E6%9C%AC/"},{"name":"Vue","slug":"Vue","permalink":"https://andy-whb-cn.github.io/tags/Vue/"},{"name":"前端","slug":"前端","permalink":"https://andy-whb-cn.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Flink","slug":"Flink","permalink":"https://andy-whb-cn.github.io/tags/Flink/"},{"name":"接口","slug":"接口","permalink":"https://andy-whb-cn.github.io/tags/%E6%8E%A5%E5%8F%A3/"},{"name":"java","slug":"java","permalink":"https://andy-whb-cn.github.io/tags/java/"},{"name":"安全","slug":"安全","permalink":"https://andy-whb-cn.github.io/tags/%E5%AE%89%E5%85%A8/"}]}